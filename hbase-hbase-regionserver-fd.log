2016年 12月 10日 土曜日 22:32:33 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-10 22:32:34,942 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-10 22:32:34,943 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-10 22:32:34,943 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-10 22:32:35,405 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-10 22:32:35,406 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2016-12-10 22:32:35,407 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=3
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-10 22:32:35,408 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-10 22:32:35,409 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-10 22:32:35,409 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-10 22:32:35,409 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-10 22:32:35,409 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-10 22:32:35,409 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-10 22:32:35,410 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2016-12-10 22:32:35,410 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-10 22:32:35,410 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-10 22:32:35,410 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-10 22:32:35,410 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-10 22:32:35,413 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-10 22:32:35,413 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-10 22:32:35,743 DEBUG [main] regionserver.HRegionServer: regionserver/fd/127.0.1.1:60020 HConnection server-to-server retries=350
2016-12-10 22:32:36,014 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-10 22:32:36,043 INFO  [main] ipc.RpcServer: regionserver/fd/127.0.1.1:60020: started 10 reader(s).
2016-12-10 22:32:36,194 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-10 22:32:36,324 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-10 22:32:36,324 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-10 22:32:36,494 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-10 22:32:36,510 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-10 22:32:36,564 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-10 22:32:36,640 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-10 22:32:36,645 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-10 22:32:36,645 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-10 22:32:36,667 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-10 22:32:36,667 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-10 22:32:37,176 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-10 22:32:37,195 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-10 22:32:37,206 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-10 22:32:37,206 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-10 22:32:37,206 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-10 22:32:37,206 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-10 22:32:37,206 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-10 22:32:37,206 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-10 22:32:37,208 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-10 22:32:37,208 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-10 22:32:37,208 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-10 22:32:37,208 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-10 22:32:37,208 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-10 22:32:37,208 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-10 22:32:37,208 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-10 22:32:37,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-10 22:32:37,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-10 22:32:37,210 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-10 22:32:37,236 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 22:32:37,241 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:46288, server: fd/192.168.1.70:2181
2016-12-10 22:32:37,271 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158e8e8f1a40004, negotiated timeout = 40000
2016-12-10 22:32:37,353 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x4356ba05 connecting to ZooKeeper ensemble=fd:2181
2016-12-10 22:32:37,354 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x4356ba05, quorum=fd:2181, baseZNode=/hbase
2016-12-10 22:32:37,356 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 22:32:37,356 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:46290, server: fd/192.168.1.70:2181
2016-12-10 22:32:37,368 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158e8e8f1a40005, negotiated timeout = 40000
2016-12-10 22:32:38,256 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-10 22:32:38,340 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@584c9e5b
2016-12-10 22:32:38,347 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 8036be00-036b-4ecd-8bec-043370acdc7d
2016-12-10 22:32:38,353 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-10 22:32:38,372 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-10 22:32:38,380 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-10 22:32:38,390 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-10 22:32:38,395 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-10 22:32:38,408 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481376750163 with port=60020, startcode=1481376756353
2016-12-10 22:32:38,768 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-10 22:32:38,768 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-10 22:32:38,769 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-10 22:32:38,769 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-10 22:32:38,769 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-10 22:32:38,803 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-10 22:32:38,814 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353
2016-12-10 22:32:39,035 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-10 22:32:39,055 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-10 22:32:39,570 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376759124
2016-12-10 22:32:39,599 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-10 22:32:39,612 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-10 22:32:39,613 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-10 22:32:39,613 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-10 22:32:39,613 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-10 22:32:39,613 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-10 22:32:39,621 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481376756353] other RSs: [fd,60020,1481376756353]
2016-12-10 22:32:39,670 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-10 22:32:39,680 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x38e753ad connecting to ZooKeeper ensemble=fd:2181
2016-12-10 22:32:39,680 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x38e753ad, quorum=fd:2181, baseZNode=/hbase
2016-12-10 22:32:39,681 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/127.0.1.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 22:32:39,691 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:49758, server: fd/127.0.1.1:2181
2016-12-10 22:32:39,702 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/127.0.1.1:2181, sessionid = 0x158e8e8f1a40006, negotiated timeout = 40000
2016-12-10 22:32:39,710 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-10 22:32:39,711 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-10 22:32:39,712 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-10 22:32:39,712 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-10 22:32:39,713 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-10 22:32:39,713 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-10 22:32:39,714 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-10 22:32:39,714 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-10 22:32:39,714 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-10 22:32:39,714 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-10 22:32:39,714 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-10 22:32:39,714 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-10 22:32:39,714 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-10 22:32:39,715 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-10 22:32:39,715 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-10 22:32:39,715 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-10 22:32:39,715 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-10 22:32:39,715 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-10 22:32:39,715 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-10 22:32:39,716 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-10 22:32:39,716 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-10 22:32:39,716 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-10 22:32:39,716 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-10 22:32:39,716 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-10 22:32:39,716 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-10 22:32:39,716 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-10 22:32:39,717 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-10 22:32:39,717 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-10 22:32:39,717 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-10 22:32:39,717 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-10 22:32:39,717 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-10 22:32:39,717 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-10 22:32:39,718 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-10 22:32:39,718 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-10 22:32:39,718 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-10 22:32:39,718 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-10 22:32:39,718 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-10 22:32:39,718 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-10 22:32:39,718 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-10 22:32:39,719 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-10 22:32:39,719 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-10 22:32:39,719 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-10 22:32:39,719 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-10 22:32:39,719 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-10 22:32:39,719 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-10 22:32:39,761 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-10 22:32:39,769 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481376756353, RpcServer on fd/127.0.1.1:60020, sessionid=0x158e8e8f1a40004
2016-12-10 22:32:39,769 INFO  [SplitLogWorker-fd,60020,1481376756353] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481376756353 starting
2016-12-10 22:32:39,774 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-10 22:32:39,774 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481376756353
2016-12-10 22:32:39,774 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481376756353'
2016-12-10 22:32:39,774 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-10 22:32:39,779 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-10 22:32:39,781 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-10 22:32:39,783 INFO  [SplitLogWorker-fd,60020,1481376756353] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x16a379bb connecting to ZooKeeper ensemble=fd:2181
2016-12-10 22:32:39,783 INFO  [SplitLogWorker-fd,60020,1481376756353] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x16a379bb, quorum=fd:2181, baseZNode=/hbase
2016-12-10 22:32:39,822 INFO  [SplitLogWorker-fd,60020,1481376756353-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-10 22:32:39,825 INFO  [SplitLogWorker-fd,60020,1481376756353-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:46300, server: fd/192.168.1.70:2181
2016-12-10 22:32:39,835 INFO  [SplitLogWorker-fd,60020,1481376756353-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158e8e8f1a40007, negotiated timeout = 40000
2016-12-10 22:32:39,863 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-10 22:32:40,028 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-10 22:32:41,502 INFO  [PriorityRpcServer.handler=0,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-10 22:32:41,522 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-10 22:32:41,542 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-10 22:32:41,542 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353
2016-12-10 22:32:41,544 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-10 22:32:41,607 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376761554.meta
2016-12-10 22:32:41,645 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-10 22:32:41,701 INFO  [RS_OPEN_META-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-10 22:32:41,701 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-10 22:32:41,707 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-10 22:32:41,711 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-10 22:32:41,718 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-10 22:32:41,718 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-10 22:32:41,818 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 22:32:41,834 DEBUG [StoreOpener-1588230740-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info
2016-12-10 22:32:41,848 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-10 22:32:41,848 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-10 22:32:41,856 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-10 22:32:41,873 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2016-12-10 22:32:41,873 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-10 22:32:41,876 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-10 22:32:41,878 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481376756353
2016-12-10 22:32:41,900 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-10 22:32:41,901 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-10 22:32:41,909 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-10 22:32:41,909 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481376756353
2016-12-10 22:32:41,909 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481376756353
2016-12-10 22:32:42,514 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-10 22:32:42,514 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-10 22:32:42,573 INFO  [PriorityRpcServer.handler=0,queue=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-10 22:32:42,589 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376761554.meta with entries=1, filesize=268; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376762515.meta
2016-12-10 22:32:42,657 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioning c6fa8b442e8dcd3a19adfedd7cd02854 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-10 22:32:42,677 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioned node c6fa8b442e8dcd3a19adfedd7cd02854 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-10 22:32:42,678 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => c6fa8b442e8dcd3a19adfedd7cd02854, NAME => 'hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.', STARTKEY => '', ENDKEY => ''}
2016-12-10 22:32:42,680 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-10 22:32:42,691 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Instantiated hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-10 22:32:42,717 INFO  [StoreOpener-c6fa8b442e8dcd3a19adfedd7cd02854-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 22:32:42,723 DEBUG [StoreOpener-c6fa8b442e8dcd3a19adfedd7cd02854-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854/info
2016-12-10 22:32:42,727 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-10 22:32:42,731 INFO  [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Onlined c6fa8b442e8dcd3a19adfedd7cd02854; next sequenceid=1
2016-12-10 22:32:42,731 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-10 22:32:42,733 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-10 22:32:42,810 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-10 22:32:42,811 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-10 22:32:42,814 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] catalog.MetaEditor: Updated row hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. with server=fd,60020,1481376756353
2016-12-10 22:32:42,814 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-10 22:32:42,816 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioning c6fa8b442e8dcd3a19adfedd7cd02854 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-10 22:32:42,834 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioned node c6fa8b442e8dcd3a19adfedd7cd02854 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-10 22:32:42,834 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Transitioned c6fa8b442e8dcd3a19adfedd7cd02854 to OPENED in zk on fd,60020,1481376756353
2016-12-10 22:32:42,835 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Opened hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. on fd,60020,1481376756353
2016-12-10 22:32:42,902 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376762515.meta with entries=1, filesize=464; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376762811.meta
2016-12-10 22:32:43,037 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-10 22:32:43,037 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2016-12-10 22:32:43,118 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376759124 with entries=2, filesize=303; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376763038
2016-12-10 22:37:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2016-12-10 22:42:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
2016-12-10 22:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=89, evicted=0, evictedPerRun=0.0
2016-12-10 22:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=119, evicted=0, evictedPerRun=0.0
2016-12-10 22:57:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=149, evicted=0, evictedPerRun=0.0
2016-12-10 23:00:30,710 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-10 23:00:30,711 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-10 23:00:30,728 INFO  [PriorityRpcServer.handler=4,queue=0,port=60020] regionserver.HRegionServer: Open crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-10 23:00:30,755 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioning c5a721cf7a7f1fdf4f62e37dd30be0f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-10 23:00:30,771 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioned node c5a721cf7a7f1fdf4f62e37dd30be0f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-10 23:00:30,772 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Opening region: {ENCODED => c5a721cf7a7f1fdf4f62e37dd30be0f3, NAME => 'crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.', STARTKEY => '', ENDKEY => ''}
2016-12-10 23:00:30,772 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table crawlId_webpage c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-10 23:00:30,778 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Instantiated crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-10 23:00:30,780 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376762811.meta with entries=1, filesize=276; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481378430711.meta
2016-12-10 23:00:30,796 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,799 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/f
2016-12-10 23:00:30,811 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,814 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/h
2016-12-10 23:00:30,828 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,831 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/il
2016-12-10 23:00:30,845 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,848 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/mk
2016-12-10 23:00:30,861 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,864 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/mtdt
2016-12-10 23:00:30,878 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,880 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/ol
2016-12-10 23:00:30,895 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,897 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/p
2016-12-10 23:00:30,911 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,913 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/s
2016-12-10 23:00:30,928 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-10 23:00:30,933 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/stm
2016-12-10 23:00:30,937 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-10 23:00:30,940 INFO  [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Onlined c5a721cf7a7f1fdf4f62e37dd30be0f3; next sequenceid=1
2016-12-10 23:00:30,940 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-10 23:00:30,943 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] regionserver.HRegionServer: Post open deploy tasks for region=crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-10 23:00:30,953 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-10 23:00:30,953 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-10 23:00:30,954 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] catalog.MetaEditor: Updated row crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3. with server=fd,60020,1481376756353
2016-12-10 23:00:30,955 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] regionserver.HRegionServer: Finished post open deploy task for crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-10 23:00:30,956 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioning c5a721cf7a7f1fdf4f62e37dd30be0f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-10 23:00:30,979 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158e8e8f1a40004, quorum=fd:2181, baseZNode=/hbase Transitioned node c5a721cf7a7f1fdf4f62e37dd30be0f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-10 23:00:30,979 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Transitioned c5a721cf7a7f1fdf4f62e37dd30be0f3 to OPENED in zk on fd,60020,1481376756353
2016-12-10 23:00:30,979 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Opened crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3. on fd,60020,1481376756353
2016-12-10 23:00:31,022 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481378430711.meta with entries=1, filesize=464; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481378430953.meta
2016-12-10 23:02:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=179, evicted=0, evictedPerRun=0.0
2016-12-10 23:07:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=209, evicted=0, evictedPerRun=0.0
2016-12-10 23:12:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=239, evicted=0, evictedPerRun=0.0
2016-12-10 23:17:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=269, evicted=0, evictedPerRun=0.0
2016-12-10 23:22:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=299, evicted=0, evictedPerRun=0.0
2016-12-10 23:27:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=329, evicted=0, evictedPerRun=0.0
2016-12-10 23:32:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=359, evicted=0, evictedPerRun=0.0
2016-12-10 23:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-10 23:32:43,188 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-10 23:32:43,244 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376763038 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481380363189
2016-12-10 23:32:43,244 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376763038
2016-12-10 23:32:49,687 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 22730
2016-12-10 23:32:49,690 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. after a delay of 5497
2016-12-10 23:32:55,190 INFO  [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854., current region memstore size 344
2016-12-10 23:32:55,309 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=4, memsize=344, hasBloomFilter=true, into tmp file hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854/.tmp/d44ba64dee834addb5937cb8513fc9d5
2016-12-10 23:32:55,402 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854/.tmp/d44ba64dee834addb5937cb8513fc9d5 as hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854/info/d44ba64dee834addb5937cb8513fc9d5
2016-12-10 23:32:55,426 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854/info/d44ba64dee834addb5937cb8513fc9d5, entries=2, sequenceid=4, filesize=1.0 K
2016-12-10 23:32:55,427 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~344/344, currentsize=0/0 for region hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. in 236ms, sequenceid=4, compaction requested=false
2016-12-10 23:32:59,686 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 18380
2016-12-10 23:33:09,686 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 13486
2016-12-10 23:33:12,419 INFO  [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.9 K
2016-12-10 23:33:12,475 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=6, memsize=1.9 K, hasBloomFilter=false, into tmp file hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/.tmp/a0c77bd9b3e240658717519260c57dc0
2016-12-10 23:33:12,495 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/.tmp/a0c77bd9b3e240658717519260c57dc0 as hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info/a0c77bd9b3e240658717519260c57dc0
2016-12-10 23:33:12,512 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info/a0c77bd9b3e240658717519260c57dc0, entries=8, sequenceid=6, filesize=1.8 K
2016-12-10 23:33:12,513 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.9 K/1976, currentsize=0/0 for region hbase:meta,,1.1588230740 in 94ms, sequenceid=6, compaction requested=false
2016-12-10 23:37:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=389, evicted=0, evictedPerRun=0.0
2016-12-10 23:42:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=1, hits=0, hitRatio=0, cachingAccesses=1, cachingHits=0, cachingHitsRatio=0,evictions=419, evicted=0, evictedPerRun=0.0
2016-12-10 23:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=2, hits=1, hitRatio=50.00%, , cachingAccesses=2, cachingHits=1, cachingHitsRatio=50.00%, evictions=449, evicted=0, evictedPerRun=0.0
2016-12-10 23:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=3, hits=2, hitRatio=66.67%, , cachingAccesses=3, cachingHits=2, cachingHitsRatio=66.67%, evictions=479, evicted=0, evictedPerRun=0.0
2016-12-10 23:57:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=4, hits=3, hitRatio=75.00%, , cachingAccesses=4, cachingHits=3, cachingHitsRatio=75.00%, evictions=509, evicted=0, evictedPerRun=0.0
2016-12-11 00:00:31,094 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 00:00:31,152 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481378430953.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481382031095.meta
2016-12-11 00:00:31,152 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376761554.meta
2016-12-11 00:00:31,152 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376762515.meta
2016-12-11 00:00:31,152 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376762811.meta
2016-12-11 00:00:31,152 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481378430711.meta
2016-12-11 00:00:31,152 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481378430953.meta
2016-12-11 00:02:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=5, hits=4, hitRatio=80.00%, , cachingAccesses=5, cachingHits=4, cachingHitsRatio=80.00%, evictions=539, evicted=0, evictedPerRun=0.0
2016-12-11 00:07:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=6, hits=5, hitRatio=83.33%, , cachingAccesses=6, cachingHits=5, cachingHitsRatio=83.33%, evictions=569, evicted=0, evictedPerRun=0.0
2016-12-11 00:12:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=7, hits=6, hitRatio=85.71%, , cachingAccesses=7, cachingHits=6, cachingHitsRatio=85.71%, evictions=599, evicted=0, evictedPerRun=0.0
2016-12-11 00:17:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=8, hits=7, hitRatio=87.50%, , cachingAccesses=8, cachingHits=7, cachingHitsRatio=87.50%, evictions=629, evicted=0, evictedPerRun=0.0
2016-12-11 00:22:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=9, hits=8, hitRatio=88.89%, , cachingAccesses=9, cachingHits=8, cachingHitsRatio=88.89%, evictions=659, evicted=0, evictedPerRun=0.0
2016-12-11 00:27:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=10, hits=9, hitRatio=90.00%, , cachingAccesses=10, cachingHits=9, cachingHitsRatio=90.00%, evictions=689, evicted=0, evictedPerRun=0.0
2016-12-11 00:32:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=11, hits=10, hitRatio=90.91%, , cachingAccesses=11, cachingHits=10, cachingHitsRatio=90.91%, evictions=719, evicted=0, evictedPerRun=0.0
2016-12-11 00:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 00:32:43,343 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 00:32:43,398 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481380363189 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481383963343
2016-12-11 00:32:43,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481376759124
2016-12-11 00:32:43,398 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481380363189
2016-12-11 00:37:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=12, hits=11, hitRatio=91.67%, , cachingAccesses=12, cachingHits=11, cachingHitsRatio=91.67%, evictions=749, evicted=0, evictedPerRun=0.0
2016-12-11 00:42:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=13, hits=12, hitRatio=92.31%, , cachingAccesses=13, cachingHits=12, cachingHitsRatio=92.31%, evictions=779, evicted=0, evictedPerRun=0.0
2016-12-11 00:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=14, hits=13, hitRatio=92.86%, , cachingAccesses=14, cachingHits=13, cachingHitsRatio=92.86%, evictions=809, evicted=0, evictedPerRun=0.0
2016-12-11 00:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=15, hits=14, hitRatio=93.33%, , cachingAccesses=15, cachingHits=14, cachingHitsRatio=93.33%, evictions=839, evicted=0, evictedPerRun=0.0
2016-12-11 00:57:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=16, hits=15, hitRatio=93.75%, , cachingAccesses=16, cachingHits=15, cachingHitsRatio=93.75%, evictions=869, evicted=0, evictedPerRun=0.0
2016-12-11 01:00:31,285 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 01:00:31,746 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481382031095.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481385631285.meta
2016-12-11 01:00:31,746 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481382031095.meta
2016-12-11 01:02:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=17, hits=16, hitRatio=94.12%, , cachingAccesses=17, cachingHits=16, cachingHitsRatio=94.12%, evictions=899, evicted=0, evictedPerRun=0.0
2016-12-11 01:07:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=18, hits=17, hitRatio=94.44%, , cachingAccesses=18, cachingHits=17, cachingHitsRatio=94.44%, evictions=929, evicted=0, evictedPerRun=0.0
2016-12-11 01:12:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=19, hits=18, hitRatio=94.74%, , cachingAccesses=19, cachingHits=18, cachingHitsRatio=94.74%, evictions=959, evicted=0, evictedPerRun=0.0
2016-12-11 01:17:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=20, hits=19, hitRatio=95.00%, , cachingAccesses=20, cachingHits=19, cachingHitsRatio=95.00%, evictions=989, evicted=0, evictedPerRun=0.0
2016-12-11 01:22:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=21, hits=20, hitRatio=95.24%, , cachingAccesses=21, cachingHits=20, cachingHitsRatio=95.24%, evictions=1019, evicted=0, evictedPerRun=0.0
2016-12-11 01:27:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=22, hits=21, hitRatio=95.45%, , cachingAccesses=22, cachingHits=21, cachingHitsRatio=95.45%, evictions=1049, evicted=0, evictedPerRun=0.0
2016-12-11 01:32:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=23, hits=22, hitRatio=95.65%, , cachingAccesses=23, cachingHits=22, cachingHitsRatio=95.65%, evictions=1079, evicted=0, evictedPerRun=0.0
2016-12-11 01:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 01:32:43,484 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 01:32:43,941 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481383963343 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481387563484
2016-12-11 01:32:43,941 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481383963343
2016-12-11 01:37:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=24, hits=23, hitRatio=95.83%, , cachingAccesses=24, cachingHits=23, cachingHitsRatio=95.83%, evictions=1109, evicted=0, evictedPerRun=0.0
2016-12-11 01:42:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=25, hits=24, hitRatio=96.00%, , cachingAccesses=25, cachingHits=24, cachingHitsRatio=96.00%, evictions=1139, evicted=0, evictedPerRun=0.0
2016-12-11 01:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=26, hits=25, hitRatio=96.15%, , cachingAccesses=26, cachingHits=25, cachingHitsRatio=96.15%, evictions=1169, evicted=0, evictedPerRun=0.0
2016-12-11 01:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=27, hits=26, hitRatio=96.30%, , cachingAccesses=27, cachingHits=26, cachingHitsRatio=96.30%, evictions=1199, evicted=0, evictedPerRun=0.0
2016-12-11 01:57:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=28, hits=27, hitRatio=96.43%, , cachingAccesses=28, cachingHits=27, cachingHitsRatio=96.43%, evictions=1229, evicted=0, evictedPerRun=0.0
2016-12-11 02:00:31,832 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 02:00:31,904 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481385631285.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481389231832.meta
2016-12-11 02:00:31,904 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481385631285.meta
2016-12-11 02:02:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=29, hits=28, hitRatio=96.55%, , cachingAccesses=29, cachingHits=28, cachingHitsRatio=96.55%, evictions=1259, evicted=0, evictedPerRun=0.0
2016-12-11 02:07:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=30, hits=29, hitRatio=96.67%, , cachingAccesses=30, cachingHits=29, cachingHitsRatio=96.67%, evictions=1289, evicted=0, evictedPerRun=0.0
2016-12-11 02:12:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=31, hits=30, hitRatio=96.77%, , cachingAccesses=31, cachingHits=30, cachingHitsRatio=96.77%, evictions=1319, evicted=0, evictedPerRun=0.0
2016-12-11 02:17:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=32, hits=31, hitRatio=96.88%, , cachingAccesses=32, cachingHits=31, cachingHitsRatio=96.88%, evictions=1349, evicted=0, evictedPerRun=0.0
2016-12-11 02:22:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=33, hits=32, hitRatio=96.97%, , cachingAccesses=33, cachingHits=32, cachingHitsRatio=96.97%, evictions=1379, evicted=0, evictedPerRun=0.0
2016-12-11 02:27:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=34, hits=33, hitRatio=97.06%, , cachingAccesses=34, cachingHits=33, cachingHitsRatio=97.06%, evictions=1409, evicted=0, evictedPerRun=0.0
2016-12-11 02:32:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=35, hits=34, hitRatio=97.14%, , cachingAccesses=35, cachingHits=34, cachingHitsRatio=97.14%, evictions=1439, evicted=0, evictedPerRun=0.0
2016-12-11 02:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 02:32:44,020 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 02:32:44,068 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481387563484 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481391164021
2016-12-11 02:32:44,068 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481387563484
2016-12-11 02:37:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=36, hits=35, hitRatio=97.22%, , cachingAccesses=36, cachingHits=35, cachingHitsRatio=97.22%, evictions=1469, evicted=0, evictedPerRun=0.0
2016-12-11 02:42:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=37, hits=36, hitRatio=97.30%, , cachingAccesses=37, cachingHits=36, cachingHitsRatio=97.30%, evictions=1499, evicted=0, evictedPerRun=0.0
2016-12-11 02:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=38, hits=37, hitRatio=97.37%, , cachingAccesses=38, cachingHits=37, cachingHitsRatio=97.37%, evictions=1529, evicted=0, evictedPerRun=0.0
2016-12-11 02:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=39, hits=38, hitRatio=97.44%, , cachingAccesses=39, cachingHits=38, cachingHitsRatio=97.44%, evictions=1559, evicted=0, evictedPerRun=0.0
2016-12-11 02:57:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=40, hits=39, hitRatio=97.50%, , cachingAccesses=40, cachingHits=39, cachingHitsRatio=97.50%, evictions=1589, evicted=0, evictedPerRun=0.0
2016-12-11 03:00:31,981 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 03:00:32,040 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481389231832.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481392831982.meta
2016-12-11 03:00:32,040 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481389231832.meta
2016-12-11 03:02:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=41, hits=40, hitRatio=97.56%, , cachingAccesses=41, cachingHits=40, cachingHitsRatio=97.56%, evictions=1619, evicted=0, evictedPerRun=0.0
2016-12-11 03:07:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=42, hits=41, hitRatio=97.62%, , cachingAccesses=42, cachingHits=41, cachingHitsRatio=97.62%, evictions=1649, evicted=0, evictedPerRun=0.0
2016-12-11 03:12:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=43, hits=42, hitRatio=97.67%, , cachingAccesses=43, cachingHits=42, cachingHitsRatio=97.67%, evictions=1679, evicted=0, evictedPerRun=0.0
2016-12-11 03:17:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=44, hits=43, hitRatio=97.73%, , cachingAccesses=44, cachingHits=43, cachingHitsRatio=97.73%, evictions=1709, evicted=0, evictedPerRun=0.0
2016-12-11 03:22:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=45, hits=44, hitRatio=97.78%, , cachingAccesses=45, cachingHits=44, cachingHitsRatio=97.78%, evictions=1739, evicted=0, evictedPerRun=0.0
2016-12-11 03:27:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=46, hits=45, hitRatio=97.83%, , cachingAccesses=46, cachingHits=45, cachingHitsRatio=97.83%, evictions=1769, evicted=0, evictedPerRun=0.0
2016-12-11 03:32:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=47, hits=46, hitRatio=97.87%, , cachingAccesses=47, cachingHits=46, cachingHitsRatio=97.87%, evictions=1799, evicted=0, evictedPerRun=0.0
2016-12-11 03:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 03:32:44,137 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 03:32:44,195 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481391164021 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481394764137
2016-12-11 03:32:44,195 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481391164021
2016-12-11 03:37:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=48, hits=47, hitRatio=97.92%, , cachingAccesses=48, cachingHits=47, cachingHitsRatio=97.92%, evictions=1829, evicted=0, evictedPerRun=0.0
2016-12-11 03:42:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=49, hits=48, hitRatio=97.96%, , cachingAccesses=49, cachingHits=48, cachingHitsRatio=97.96%, evictions=1859, evicted=0, evictedPerRun=0.0
2016-12-11 03:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=50, hits=49, hitRatio=98.00%, , cachingAccesses=50, cachingHits=49, cachingHitsRatio=98.00%, evictions=1889, evicted=0, evictedPerRun=0.0
2016-12-11 03:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=51, hits=50, hitRatio=98.04%, , cachingAccesses=51, cachingHits=50, cachingHitsRatio=98.04%, evictions=1919, evicted=0, evictedPerRun=0.0
2016-12-11 03:57:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=52, hits=51, hitRatio=98.08%, , cachingAccesses=52, cachingHits=51, cachingHitsRatio=98.08%, evictions=1949, evicted=0, evictedPerRun=0.0
2016-12-11 04:00:32,116 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 04:00:32,567 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481392831982.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481396432117.meta
2016-12-11 04:00:32,567 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481392831982.meta
2016-12-11 04:02:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=53, hits=52, hitRatio=98.11%, , cachingAccesses=53, cachingHits=52, cachingHitsRatio=98.11%, evictions=1979, evicted=0, evictedPerRun=0.0
2016-12-11 04:07:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=54, hits=53, hitRatio=98.15%, , cachingAccesses=54, cachingHits=53, cachingHitsRatio=98.15%, evictions=2009, evicted=0, evictedPerRun=0.0
2016-12-11 04:12:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=55, hits=54, hitRatio=98.18%, , cachingAccesses=55, cachingHits=54, cachingHitsRatio=98.18%, evictions=2039, evicted=0, evictedPerRun=0.0
2016-12-11 04:17:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=56, hits=55, hitRatio=98.21%, , cachingAccesses=56, cachingHits=55, cachingHitsRatio=98.21%, evictions=2069, evicted=0, evictedPerRun=0.0
2016-12-11 04:22:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=57, hits=56, hitRatio=98.25%, , cachingAccesses=57, cachingHits=56, cachingHitsRatio=98.25%, evictions=2099, evicted=0, evictedPerRun=0.0
2016-12-11 04:27:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=58, hits=57, hitRatio=98.28%, , cachingAccesses=58, cachingHits=57, cachingHitsRatio=98.28%, evictions=2129, evicted=0, evictedPerRun=0.0
2016-12-11 04:32:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=59, hits=58, hitRatio=98.31%, , cachingAccesses=59, cachingHits=58, cachingHitsRatio=98.31%, evictions=2159, evicted=0, evictedPerRun=0.0
2016-12-11 04:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 04:32:44,273 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 04:32:44,331 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481394764137 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481398364274
2016-12-11 04:32:44,331 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481394764137
2016-12-11 04:37:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=60, hits=59, hitRatio=98.33%, , cachingAccesses=60, cachingHits=59, cachingHitsRatio=98.33%, evictions=2189, evicted=0, evictedPerRun=0.0
2016-12-11 04:42:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=61, hits=60, hitRatio=98.36%, , cachingAccesses=61, cachingHits=60, cachingHitsRatio=98.36%, evictions=2219, evicted=0, evictedPerRun=0.0
2016-12-11 04:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=62, hits=61, hitRatio=98.39%, , cachingAccesses=62, cachingHits=61, cachingHitsRatio=98.39%, evictions=2249, evicted=0, evictedPerRun=0.0
2016-12-11 04:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=63, hits=62, hitRatio=98.41%, , cachingAccesses=63, cachingHits=62, cachingHitsRatio=98.41%, evictions=2279, evicted=0, evictedPerRun=0.0
2016-12-11 04:57:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=64, hits=63, hitRatio=98.44%, , cachingAccesses=64, cachingHits=63, cachingHitsRatio=98.44%, evictions=2309, evicted=0, evictedPerRun=0.0
2016-12-11 05:00:32,644 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 05:00:32,702 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481396432117.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481400032644.meta
2016-12-11 05:00:32,702 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481396432117.meta
2016-12-11 05:02:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=65, hits=64, hitRatio=98.46%, , cachingAccesses=65, cachingHits=64, cachingHitsRatio=98.46%, evictions=2339, evicted=0, evictedPerRun=0.0
2016-12-11 05:07:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=66, hits=65, hitRatio=98.48%, , cachingAccesses=66, cachingHits=65, cachingHitsRatio=98.48%, evictions=2369, evicted=0, evictedPerRun=0.0
2016-12-11 05:12:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=67, hits=66, hitRatio=98.51%, , cachingAccesses=67, cachingHits=66, cachingHitsRatio=98.51%, evictions=2399, evicted=0, evictedPerRun=0.0
2016-12-11 05:17:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=68, hits=67, hitRatio=98.53%, , cachingAccesses=68, cachingHits=67, cachingHitsRatio=98.53%, evictions=2429, evicted=0, evictedPerRun=0.0
2016-12-11 05:22:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=69, hits=68, hitRatio=98.55%, , cachingAccesses=69, cachingHits=68, cachingHitsRatio=98.55%, evictions=2459, evicted=0, evictedPerRun=0.0
2016-12-11 05:27:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=70, hits=69, hitRatio=98.57%, , cachingAccesses=70, cachingHits=69, cachingHitsRatio=98.57%, evictions=2489, evicted=0, evictedPerRun=0.0
2016-12-11 05:32:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=71, hits=70, hitRatio=98.59%, , cachingAccesses=71, cachingHits=70, cachingHitsRatio=98.59%, evictions=2519, evicted=0, evictedPerRun=0.0
2016-12-11 05:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 05:32:44,391 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 05:32:44,441 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481398364274 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481401964391
2016-12-11 05:32:44,441 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481398364274
2016-12-11 05:37:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=72, hits=71, hitRatio=98.61%, , cachingAccesses=72, cachingHits=71, cachingHitsRatio=98.61%, evictions=2549, evicted=0, evictedPerRun=0.0
2016-12-11 05:42:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=73, hits=72, hitRatio=98.63%, , cachingAccesses=73, cachingHits=72, cachingHitsRatio=98.63%, evictions=2579, evicted=0, evictedPerRun=0.0
2016-12-11 05:47:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=74, hits=73, hitRatio=98.65%, , cachingAccesses=74, cachingHits=73, cachingHitsRatio=98.65%, evictions=2609, evicted=0, evictedPerRun=0.0
2016-12-11 05:52:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=75, hits=74, hitRatio=98.67%, , cachingAccesses=75, cachingHits=74, cachingHitsRatio=98.67%, evictions=2639, evicted=0, evictedPerRun=0.0
2016-12-11 05:57:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=76, hits=75, hitRatio=98.68%, , cachingAccesses=76, cachingHits=75, cachingHitsRatio=98.68%, evictions=2669, evicted=0, evictedPerRun=0.0
2016-12-11 06:00:32,779 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 06:00:32,836 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481400032644.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481403632779.meta
2016-12-11 06:00:32,836 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481400032644.meta
2016-12-11 06:02:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=77, hits=76, hitRatio=98.70%, , cachingAccesses=77, cachingHits=76, cachingHitsRatio=98.70%, evictions=2699, evicted=0, evictedPerRun=0.0
2016-12-11 06:07:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=78, hits=77, hitRatio=98.72%, , cachingAccesses=78, cachingHits=77, cachingHitsRatio=98.72%, evictions=2729, evicted=0, evictedPerRun=0.0
2016-12-11 06:12:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=79, hits=78, hitRatio=98.73%, , cachingAccesses=79, cachingHits=78, cachingHitsRatio=98.73%, evictions=2759, evicted=0, evictedPerRun=0.0
2016-12-11 06:17:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=80, hits=79, hitRatio=98.75%, , cachingAccesses=80, cachingHits=79, cachingHitsRatio=98.75%, evictions=2789, evicted=0, evictedPerRun=0.0
2016-12-11 06:22:36,506 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=81, hits=80, hitRatio=98.77%, , cachingAccesses=81, cachingHits=80, cachingHitsRatio=98.77%, evictions=2819, evicted=0, evictedPerRun=0.0
2016-12-11 06:27:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=82, hits=81, hitRatio=98.78%, , cachingAccesses=82, cachingHits=81, cachingHitsRatio=98.78%, evictions=2849, evicted=0, evictedPerRun=0.0
2016-12-11 06:32:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=83, hits=82, hitRatio=98.80%, , cachingAccesses=83, cachingHits=82, cachingHitsRatio=98.80%, evictions=2879, evicted=0, evictedPerRun=0.0
2016-12-11 06:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 06:32:44,518 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 06:32:44,573 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481401964391 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481405564518
2016-12-11 06:32:44,573 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481401964391
2016-12-11 06:37:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=84, hits=83, hitRatio=98.81%, , cachingAccesses=84, cachingHits=83, cachingHitsRatio=98.81%, evictions=2909, evicted=0, evictedPerRun=0.0
2016-12-11 06:42:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=85, hits=84, hitRatio=98.82%, , cachingAccesses=85, cachingHits=84, cachingHitsRatio=98.82%, evictions=2939, evicted=0, evictedPerRun=0.0
2016-12-11 06:47:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=86, hits=85, hitRatio=98.84%, , cachingAccesses=86, cachingHits=85, cachingHitsRatio=98.84%, evictions=2969, evicted=0, evictedPerRun=0.0
2016-12-11 06:52:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=87, hits=86, hitRatio=98.85%, , cachingAccesses=87, cachingHits=86, cachingHitsRatio=98.85%, evictions=2999, evicted=0, evictedPerRun=0.0
2016-12-11 06:57:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=88, hits=87, hitRatio=98.86%, , cachingAccesses=88, cachingHits=87, cachingHitsRatio=98.86%, evictions=3029, evicted=0, evictedPerRun=0.0
2016-12-11 07:00:32,913 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 07:00:32,960 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481403632779.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481407232913.meta
2016-12-11 07:00:32,960 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481403632779.meta
2016-12-11 07:02:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=89, hits=88, hitRatio=98.88%, , cachingAccesses=89, cachingHits=88, cachingHitsRatio=98.88%, evictions=3059, evicted=0, evictedPerRun=0.0
2016-12-11 07:07:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=90, hits=89, hitRatio=98.89%, , cachingAccesses=90, cachingHits=89, cachingHitsRatio=98.89%, evictions=3089, evicted=0, evictedPerRun=0.0
2016-12-11 07:12:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=91, hits=90, hitRatio=98.90%, , cachingAccesses=91, cachingHits=90, cachingHitsRatio=98.90%, evictions=3119, evicted=0, evictedPerRun=0.0
2016-12-11 07:17:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=92, hits=91, hitRatio=98.91%, , cachingAccesses=92, cachingHits=91, cachingHitsRatio=98.91%, evictions=3149, evicted=0, evictedPerRun=0.0
2016-12-11 07:22:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=93, hits=92, hitRatio=98.92%, , cachingAccesses=93, cachingHits=92, cachingHitsRatio=98.92%, evictions=3179, evicted=0, evictedPerRun=0.0
2016-12-11 07:27:36,505 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=94, hits=93, hitRatio=98.94%, , cachingAccesses=94, cachingHits=93, cachingHitsRatio=98.94%, evictions=3209, evicted=0, evictedPerRun=0.0
2016-12-11 07:32:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=95, hits=94, hitRatio=98.95%, , cachingAccesses=95, cachingHits=94, cachingHitsRatio=98.95%, evictions=3239, evicted=0, evictedPerRun=0.0
2016-12-11 07:32:36,510 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-11 07:32:44,652 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-11 07:32:44,705 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481405564518 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481409164652
2016-12-11 07:32:44,705 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353/fd%2C60020%2C1481376756353.1481405564518
2016-12-11 07:37:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=96, hits=95, hitRatio=98.96%, , cachingAccesses=96, cachingHits=95, cachingHitsRatio=98.96%, evictions=3269, evicted=0, evictedPerRun=0.0
2016-12-11 07:42:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=97, hits=96, hitRatio=98.97%, , cachingAccesses=97, cachingHits=96, cachingHitsRatio=98.97%, evictions=3299, evicted=0, evictedPerRun=0.0
2016-12-11 07:47:36,504 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=98, hits=97, hitRatio=98.98%, , cachingAccesses=98, cachingHits=97, cachingHitsRatio=98.98%, evictions=3329, evicted=0, evictedPerRun=0.0
2016-12-11 07:49:02,604 WARN  [ResponseProcessor for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741871_1047] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741871_1047
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-11 07:49:02,604 WARN  [ResponseProcessor for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741870_1046] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741870_1046
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-11 07:49:18,865 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020. Trying to fail over immediately.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-11 07:49:18,867 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020 after 1 fail over attempts. Trying to fail over after sleeping for 646ms.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-11 07:49:19,515 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020 after 2 fail over attempts. Trying to fail over after sleeping for 2349ms.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-11 07:49:21,866 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020 after 3 fail over attempts. Trying to fail over after sleeping for 3783ms.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-11 07:49:25,652 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020 after 4 fail over attempts. Trying to fail over after sleeping for 5850ms.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor11.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016年 12月 11日 日曜日 07:49:27 JST Terminating regionserver
2016-12-11 07:49:27,094 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@663411de
2016-12-11 07:49:27,094 INFO  [Thread-10] regionserver.HRegionServer: STOPPED: Shutdown hook
2016-12-11 07:49:27,095 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2016-12-11 07:49:27,095 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2016-12-11 07:49:27,095 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2016-12-11 07:49:27,095 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2016-12-11 07:49:27,095 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2016-12-11 07:49:27,099 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2016-12-11 07:49:27,100 INFO  [SplitLogWorker-fd,60020,1481376756353] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2016-12-11 07:49:27,100 INFO  [SplitLogWorker-fd,60020,1481376756353] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481376756353 exiting
2016-12-11 07:49:27,108 INFO  [regionserver60020] mortbay.log: Stopped HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-11 07:49:27,210 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-11 07:49:27,210 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-11 07:49:27,211 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2016-12-11 07:49:27,211 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2016-12-11 07:49:27,211 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2016-12-11 07:49:27,210 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2016-12-11 07:49:27,210 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2016-12-11 07:49:27,214 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481376756353
2016-12-11 07:49:27,215 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@584c9e5b
2016-12-11 07:49:27,215 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Processing close of crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-11 07:49:27,215 DEBUG [RS_CLOSE_REGION-fd:60020-1] handler.CloseRegionHandler: Processing close of hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-11 07:49:27,216 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158e8e8f1a40005
2016-12-11 07:49:27,216 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Closing hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.: disabling compactions & flushes
2016-12-11 07:49:27,216 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Updates disabled for region hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-11 07:49:27,217 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closing crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.: disabling compactions & flushes
2016-12-11 07:49:27,217 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Updates disabled for region crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-11 07:49:27,218 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed f
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed h
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed il
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed mk
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed mtdt
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed ol
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed p
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed s
2016-12-11 07:49:27,219 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed stm
2016-12-11 07:49:27,223 INFO  [StoreCloserThread-hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.-1] regionserver.HStore: Closed info
2016-12-11 07:49:27,225 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158e8e8f1a40005 closed
2016-12-11 07:49:27,225 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-11 07:49:27,225 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2016-12-11 07:49:27,226 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2016-12-11 07:49:27,226 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2016-12-11 07:49:27,226 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2016-12-11 07:49:27,226 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 3 regions to close
2016-12-11 07:49:27,226 DEBUG [regionserver60020] regionserver.HRegionServer: {c5a721cf7a7f1fdf4f62e37dd30be0f3=crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3., 1588230740=hbase:meta,,1.1588230740, c6fa8b442e8dcd3a19adfedd7cd02854=hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.}
2016-12-11 07:49:27,228 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-11 07:49:27,228 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-11 07:49:27,228 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-11 07:49:27,230 INFO  [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Closed hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-11 07:49:27,230 INFO  [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closed crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-11 07:49:27,230 DEBUG [RS_CLOSE_REGION-fd:60020-1] handler.CloseRegionHandler: Closed hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-11 07:49:27,230 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Closed crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-11 07:49:27,231 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2016-12-11 07:49:27,232 DEBUG [RS_CLOSE_META-fd:60020-0] coprocessor.CoprocessorHost: Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2016-12-11 07:49:27,233 INFO  [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2016-12-11 07:49:27,233 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Closed hbase:meta,,1.1588230740
2016-12-11 07:49:27,426 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481376756353; all regions closed.
2016-12-11 07:49:27,427 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-11 07:49:27,427 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier exiting
2016-12-11 07:49:27,427 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,427 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 exiting
2016-12-11 07:49:27,428 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,428 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 exiting
2016-12-11 07:49:27,428 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,428 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 exiting
2016-12-11 07:49:27,428 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,428 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 exiting
2016-12-11 07:49:27,429 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,429 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 exiting
2016-12-11 07:49:27,430 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-11 07:49:27,430 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter exiting
2016-12-11 07:49:27,430 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353
2016-12-11 07:49:27,431 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-11 07:49:27,432 ERROR [regionserver60020] regionserver.HRegionServer: Metalog close and delete failed
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-11 07:49:27,433 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-11 07:49:27,433 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2016-12-11 07:49:27,433 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,433 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2016-12-11 07:49:27,434 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,434 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2016-12-11 07:49:27,434 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,434 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2016-12-11 07:49:27,434 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,434 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2016-12-11 07:49:27,435 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-11 07:49:27,435 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2016-12-11 07:49:27,436 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-11 07:49:27,436 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2016-12-11 07:49:27,436 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353
2016-12-11 07:49:27,436 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-11 07:49:27,437 ERROR [regionserver60020] regionserver.HRegionServer: Close and delete failed
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-11 07:49:27,437 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2016-12-11 07:49:27,437 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2016-12-11 07:49:30,217 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2016-12-11 07:49:30,232 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158e8e8f1a40006
2016-12-11 07:49:30,240 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158e8e8f1a40006 closed
2016-12-11 07:49:30,240 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-11 07:49:30,256 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158e8e8f1a40004 closed
2016-12-11 07:49:30,257 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481376756353; zookeeper connection closed.
2016-12-11 07:49:30,257 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-11 07:49:30,257 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2016-12-11 07:49:30,257 INFO  [Thread-10] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2016-12-11 07:49:30,259 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook finished.
2016年 12月 12日 月曜日 20:41:45 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-12 20:41:53,017 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-12 20:41:53,018 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-12 20:41:53,018 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-12 20:41:53,648 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-12 20:41:53,648 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-12 20:41:53,648 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-12 20:41:53,648 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-12 20:41:53,648 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-12 20:41:53,648 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:runlevel=2
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:RUNLEVEL=2
2016-12-12 20:41:53,649 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:UPSTART_INSTANCE=
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:PREVLEVEL=N
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-12 20:41:53,650 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:UPSTART_JOB=rc
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:TERM=linux
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=c8
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-12 20:41:53,651 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:previous=N
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:UPSTART_EVENTS=runlevel
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-12 20:41:53,652 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:XDG_SEAT=seat0
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/124
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-12 20:41:53,653 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-12 20:41:53,654 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-12 20:41:53,656 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-12 20:41:53,657 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-12 20:41:54,042 DEBUG [main] regionserver.HRegionServer: regionserver/fd/127.0.1.1:60020 HConnection server-to-server retries=350
2016-12-12 20:41:54,343 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-12 20:41:54,388 INFO  [main] ipc.RpcServer: regionserver/fd/127.0.1.1:60020: started 10 reader(s).
2016-12-12 20:41:54,540 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-12 20:41:54,704 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-12 20:41:54,704 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-12 20:41:54,911 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-12 20:41:54,932 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-12 20:41:55,008 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-12 20:41:55,092 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-12 20:41:55,097 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-12 20:41:55,097 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-12 20:41:55,122 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-12 20:41:55,122 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-12 20:41:55,830 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-12 20:41:55,849 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-12 20:41:55,858 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-12 20:41:55,858 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-12 20:41:55,859 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-12 20:41:55,859 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-12 20:41:55,859 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-12 20:41:55,859 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-12 20:41:55,860 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-12 20:41:55,861 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-12 20:41:55,862 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-12 20:41:55,901 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/127.0.1.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-12 20:41:55,907 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:38778, server: fd/127.0.1.1:2181
2016-12-12 20:41:55,929 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/127.0.1.1:2181, sessionid = 0x158f2d6c78a0002, negotiated timeout = 40000
2016-12-12 20:41:56,927 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-12 20:41:57,464 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x1b41da1 connecting to ZooKeeper ensemble=fd:2181
2016-12-12 20:41:57,464 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x1b41da1, quorum=fd:2181, baseZNode=/hbase
2016-12-12 20:41:57,467 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/127.0.1.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-12 20:41:57,468 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:38782, server: fd/127.0.1.1:2181
2016-12-12 20:41:57,476 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/127.0.1.1:2181, sessionid = 0x158f2d6c78a0004, negotiated timeout = 40000
2016-12-12 20:41:57,593 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@72e6d41c
2016-12-12 20:41:57,599 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 8036be00-036b-4ecd-8bec-043370acdc7d
2016-12-12 20:41:57,606 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-12 20:41:57,631 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-12 20:41:57,640 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-12 20:41:57,651 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-12 20:41:57,656 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-12 20:41:57,671 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:41:58,065 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:41:58,066 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:01,066 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:01,070 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:01,070 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:04,071 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:04,074 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:04,074 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:07,075 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:07,078 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:07,078 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:10,078 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:10,082 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:10,082 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:13,082 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:13,085 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:13,085 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:16,086 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:16,089 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:16,089 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:19,089 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:19,092 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:19,093 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:22,093 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:22,096 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:22,096 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:25,097 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:25,100 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:25,100 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:28,101 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:28,105 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-12 20:42:28,105 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-12 20:42:31,106 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481542914705 with port=60020, startcode=1481542914740
2016-12-12 20:42:31,138 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-12 20:42:31,138 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-12 20:42:31,138 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-12 20:42:31,139 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-12 20:42:31,139 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-12 20:42:31,184 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-12 20:42:31,195 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740
2016-12-12 20:42:31,347 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-12 20:42:31,366 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-12 20:42:31,994 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542951432
2016-12-12 20:42:32,020 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-12 20:42:32,031 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-12 20:42:32,032 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-12 20:42:32,032 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-12 20:42:32,032 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-12 20:42:32,032 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-12 20:42:32,040 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481542914740] other RSs: [fd,60020,1481542914740]
2016-12-12 20:42:32,087 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-12 20:42:32,097 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x29399739 connecting to ZooKeeper ensemble=fd:2181
2016-12-12 20:42:32,097 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x29399739, quorum=fd:2181, baseZNode=/hbase
2016-12-12 20:42:32,100 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/127.0.1.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-12 20:42:32,102 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:38802, server: fd/127.0.1.1:2181
2016-12-12 20:42:32,108 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/127.0.1.1:2181, sessionid = 0x158f2d6c78a0007, negotiated timeout = 40000
2016-12-12 20:42:32,116 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-12 20:42:32,117 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-12 20:42:32,117 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-12 20:42:32,118 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-12 20:42:32,118 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-12 20:42:32,119 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-12 20:42:32,119 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-12 20:42:32,120 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-12 20:42:32,120 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-12 20:42:32,120 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-12 20:42:32,120 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-12 20:42:32,121 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-12 20:42:32,121 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-12 20:42:32,121 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-12 20:42:32,121 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-12 20:42:32,121 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-12 20:42:32,122 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-12 20:42:32,122 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-12 20:42:32,122 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-12 20:42:32,122 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-12 20:42:32,122 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-12 20:42:32,122 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-12 20:42:32,123 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-12 20:42:32,123 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-12 20:42:32,123 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-12 20:42:32,123 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-12 20:42:32,123 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-12 20:42:32,123 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-12 20:42:32,123 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-12 20:42:32,124 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-12 20:42:32,124 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-12 20:42:32,124 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-12 20:42:32,125 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-12 20:42:32,125 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-12 20:42:32,125 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-12 20:42:32,125 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-12 20:42:32,125 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-12 20:42:32,125 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-12 20:42:32,126 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-12 20:42:32,126 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-12 20:42:32,126 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-12 20:42:32,126 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-12 20:42:32,126 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-12 20:42:32,126 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-12 20:42:32,126 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-12 20:42:32,168 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-12 20:42:32,176 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481542914740, RpcServer on fd/127.0.1.1:60020, sessionid=0x158f2d6c78a0002
2016-12-12 20:42:32,176 INFO  [SplitLogWorker-fd,60020,1481542914740] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481542914740 starting
2016-12-12 20:42:32,181 INFO  [SplitLogWorker-fd,60020,1481542914740] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x21deaa53 connecting to ZooKeeper ensemble=fd:2181
2016-12-12 20:42:32,181 INFO  [SplitLogWorker-fd,60020,1481542914740] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x21deaa53, quorum=fd:2181, baseZNode=/hbase
2016-12-12 20:42:32,182 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-12 20:42:32,182 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481542914740
2016-12-12 20:42:32,182 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481542914740'
2016-12-12 20:42:32,182 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-12 20:42:32,183 INFO  [SplitLogWorker-fd,60020,1481542914740-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-12 20:42:32,185 INFO  [SplitLogWorker-fd,60020,1481542914740-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:36836, server: fd/192.168.1.70:2181
2016-12-12 20:42:32,185 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-12 20:42:32,191 INFO  [SplitLogWorker-fd,60020,1481542914740-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f2d6c78a0008, negotiated timeout = 40000
2016-12-12 20:42:32,192 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-12 20:42:32,243 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-12 20:42:32,414 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-12 20:42:33,541 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-12 20:42:33,567 INFO  [SplitLogWorker-fd,60020,1481542914740] regionserver.SplitLogWorker: worker fd,60020,1481542914740 acquired task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481376756353-splitting%2Ffd%252C60020%252C1481376756353.1481407232913.meta
2016-12-12 20:42:33,630 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-12 20:42:33,653 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481407232913.meta, length=83
2016-12-12 20:42:33,653 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2016-12-12 20:42:33,661 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481407232913.meta
2016-12-12 20:42:33,715 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] util.FSHDFSUtils: recoverLease=false, attempt=0 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481407232913.meta after 54ms
2016-12-12 20:42:37,718 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=1 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481407232913.meta after 4057ms
2016-12-12 20:42:37,800 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-0-Writer-0,5,main]: starting
2016-12-12 20:42:37,800 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-0-Writer-1,5,main]: starting
2016-12-12 20:42:37,801 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-0-Writer-2,5,main]: starting
2016-12-12 20:42:37,816 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2016-12-12 20:42:37,816 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2016-12-12 20:42:37,817 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Split writers finished
2016-12-12 20:42:37,818 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481407232913.meta is corrupted = false progress failed = false
2016-12-12 20:42:37,841 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481376756353-splitting%2Ffd%252C60020%252C1481376756353.1481407232913.meta to final state DONE fd,60020,1481542914740
2016-12-12 20:42:37,841 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] handler.HLogSplitterHandler: worker fd,60020,1481542914740 done with task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481376756353-splitting%2Ffd%252C60020%252C1481376756353.1481407232913.meta in 4265ms
2016-12-12 20:42:37,916 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-12 20:42:38,124 INFO  [PriorityRpcServer.handler=1,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-12 20:42:38,142 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-12 20:42:38,189 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-12 20:42:38,190 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740
2016-12-12 20:42:38,191 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-12 20:42:38,248 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542958199.meta
2016-12-12 20:42:38,277 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-12 20:42:38,326 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-12 20:42:38,331 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-12 20:42:38,335 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-12 20:42:38,341 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-12 20:42:38,342 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-12 20:42:38,443 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:38,497 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-12 20:42:38,497 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-12 20:42:38,566 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info/a0c77bd9b3e240658717519260c57dc0, isReference=false, isBulkLoadResult=false, seqid=6, majorCompaction=false
2016-12-12 20:42:38,586 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-12 20:42:38,595 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=7
2016-12-12 20:42:38,595 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-12 20:42:38,598 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-12 20:42:38,600 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481542914740
2016-12-12 20:42:38,617 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-12 20:42:38,618 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-12 20:42:38,625 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-12 20:42:38,625 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481542914740
2016-12-12 20:42:38,625 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481542914740
2016-12-12 20:42:38,907 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-12 20:42:38,915 INFO  [SplitLogWorker-fd,60020,1481542914740] regionserver.SplitLogWorker: worker fd,60020,1481542914740 acquired task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481376756353-splitting%2Ffd%252C60020%252C1481376756353.1481409164652
2016-12-12 20:42:38,953 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-12 20:42:38,953 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481409164652, length=83
2016-12-12 20:42:38,953 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2016-12-12 20:42:38,957 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481409164652
2016-12-12 20:42:38,973 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] util.FSHDFSUtils: recoverLease=false, attempt=0 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481409164652 after 15ms
2016-12-12 20:42:42,977 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=1 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481409164652 after 4018ms
2016-12-12 20:42:42,995 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-1-Writer-0,5,main]: starting
2016-12-12 20:42:42,995 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-1-Writer-1,5,main]: starting
2016-12-12 20:42:42,998 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-1-Writer-2,5,main]: starting
2016-12-12 20:42:42,998 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2016-12-12 20:42:42,998 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2016-12-12 20:42:42,999 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Split writers finished
2016-12-12 20:42:42,999 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481376756353-splitting/fd%2C60020%2C1481376756353.1481409164652 is corrupted = false progress failed = false
2016-12-12 20:42:43,007 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481376756353-splitting%2Ffd%252C60020%252C1481376756353.1481409164652 to final state DONE fd,60020,1481542914740
2016-12-12 20:42:43,010 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] handler.HLogSplitterHandler: worker fd,60020,1481542914740 done with task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481376756353-splitting%2Ffd%252C60020%252C1481376756353.1481409164652 in 4092ms
2016-12-12 20:42:43,041 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-12 20:42:43,078 INFO  [PriorityRpcServer.handler=7,queue=0,port=60020] regionserver.HRegionServer: Open crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 20:42:43,103 INFO  [PriorityRpcServer.handler=7,queue=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 20:42:43,103 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioning c5a721cf7a7f1fdf4f62e37dd30be0f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-12 20:42:43,115 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioned node c5a721cf7a7f1fdf4f62e37dd30be0f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-12 20:42:43,116 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => c5a721cf7a7f1fdf4f62e37dd30be0f3, NAME => 'crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.', STARTKEY => '', ENDKEY => ''}
2016-12-12 20:42:43,118 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table crawlId_webpage c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-12 20:42:43,118 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioning c6fa8b442e8dcd3a19adfedd7cd02854 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-12 20:42:43,118 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Instantiated crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 20:42:43,128 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,132 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/f
2016-12-12 20:42:43,132 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioned node c6fa8b442e8dcd3a19adfedd7cd02854 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-12 20:42:43,133 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Opening region: {ENCODED => c6fa8b442e8dcd3a19adfedd7cd02854, NAME => 'hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.', STARTKEY => '', ENDKEY => ''}
2016-12-12 20:42:43,133 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-12 20:42:43,134 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Instantiated hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 20:42:43,140 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,148 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/h
2016-12-12 20:42:43,151 INFO  [StoreOpener-c6fa8b442e8dcd3a19adfedd7cd02854-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,151 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,154 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/il
2016-12-12 20:42:43,157 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,161 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/mk
2016-12-12 20:42:43,165 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,168 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/mtdt
2016-12-12 20:42:43,173 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,176 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/ol
2016-12-12 20:42:43,178 DEBUG [StoreOpener-c6fa8b442e8dcd3a19adfedd7cd02854-1] regionserver.HStore: loaded hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854/info/d44ba64dee834addb5937cb8513fc9d5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2016-12-12 20:42:43,181 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,182 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-12 20:42:43,183 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/p
2016-12-12 20:42:43,186 INFO  [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Onlined c6fa8b442e8dcd3a19adfedd7cd02854; next sequenceid=5
2016-12-12 20:42:43,187 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-12 20:42:43,187 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,189 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 20:42:43,190 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/s
2016-12-12 20:42:43,193 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-12 20:42:43,196 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/stm
2016-12-12 20:42:43,200 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-12 20:42:43,205 INFO  [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Onlined c5a721cf7a7f1fdf4f62e37dd30be0f3; next sequenceid=1
2016-12-12 20:42:43,205 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-12 20:42:43,207 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] regionserver.HRegionServer: Post open deploy tasks for region=crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 20:42:43,331 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-12 20:42:43,332 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-12 20:42:43,344 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] catalog.MetaEditor: Updated row crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3. with server=fd,60020,1481542914740
2016-12-12 20:42:43,345 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] regionserver.HRegionServer: Finished post open deploy task for crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 20:42:43,344 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] catalog.MetaEditor: Updated row hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. with server=fd,60020,1481542914740
2016-12-12 20:42:43,346 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 20:42:43,346 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioning c5a721cf7a7f1fdf4f62e37dd30be0f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-12 20:42:43,346 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioning c6fa8b442e8dcd3a19adfedd7cd02854 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-12 20:42:43,365 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioned node c5a721cf7a7f1fdf4f62e37dd30be0f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-12 20:42:43,365 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Transitioned c5a721cf7a7f1fdf4f62e37dd30be0f3 to OPENED in zk on fd,60020,1481542914740
2016-12-12 20:42:43,366 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Opened crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3. on fd,60020,1481542914740
2016-12-12 20:42:43,382 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f2d6c78a0002, quorum=fd:2181, baseZNode=/hbase Transitioned node c6fa8b442e8dcd3a19adfedd7cd02854 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-12 20:42:43,382 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Transitioned c6fa8b442e8dcd3a19adfedd7cd02854 to OPENED in zk on fd,60020,1481542914740
2016-12-12 20:42:43,382 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Opened hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. on fd,60020,1481542914740
2016-12-12 20:42:43,429 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542958199.meta with entries=2, filesize=837; new WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542963333.meta
2016-12-12 20:46:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=14, hits=11, hitRatio=78.57%, , cachingAccesses=14, cachingHits=11, cachingHitsRatio=78.57%, evictions=29, evicted=0, evictedPerRun=0.0
2016-12-12 20:51:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=15, hits=12, hitRatio=80.00%, , cachingAccesses=15, cachingHits=12, cachingHitsRatio=80.00%, evictions=59, evicted=0, evictedPerRun=0.0
2016-12-12 20:56:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=16, hits=13, hitRatio=81.25%, , cachingAccesses=16, cachingHits=13, cachingHitsRatio=81.25%, evictions=89, evicted=0, evictedPerRun=0.0
2016-12-12 21:01:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=17, hits=14, hitRatio=82.35%, , cachingAccesses=17, cachingHits=14, cachingHitsRatio=82.35%, evictions=119, evicted=0, evictedPerRun=0.0
2016-12-12 21:06:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=18, hits=15, hitRatio=83.33%, , cachingAccesses=18, cachingHits=15, cachingHitsRatio=83.33%, evictions=149, evicted=0, evictedPerRun=0.0
2016-12-12 21:11:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=19, hits=16, hitRatio=84.21%, , cachingAccesses=19, cachingHits=16, cachingHitsRatio=84.21%, evictions=179, evicted=0, evictedPerRun=0.0
2016-12-12 21:16:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=20, hits=17, hitRatio=85.00%, , cachingAccesses=20, cachingHits=17, cachingHitsRatio=85.00%, evictions=209, evicted=0, evictedPerRun=0.0
2016-12-12 21:21:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=21, hits=18, hitRatio=85.71%, , cachingAccesses=21, cachingHits=18, cachingHitsRatio=85.71%, evictions=239, evicted=0, evictedPerRun=0.0
2016-12-12 21:26:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=22, hits=19, hitRatio=86.36%, , cachingAccesses=22, cachingHits=19, cachingHitsRatio=86.36%, evictions=269, evicted=0, evictedPerRun=0.0
2016-12-12 21:31:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=23, hits=20, hitRatio=86.96%, , cachingAccesses=23, cachingHits=20, cachingHitsRatio=86.96%, evictions=299, evicted=0, evictedPerRun=0.0
2016-12-12 21:36:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=24, hits=21, hitRatio=87.50%, , cachingAccesses=24, cachingHits=21, cachingHitsRatio=87.50%, evictions=329, evicted=0, evictedPerRun=0.0
2016-12-12 21:41:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=25, hits=22, hitRatio=88.00%, , cachingAccesses=25, cachingHits=22, cachingHitsRatio=88.00%, evictions=359, evicted=0, evictedPerRun=0.0
2016-12-12 21:41:54,932 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-12 21:42:32,106 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-12 21:42:32,176 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542951432 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481546552107
2016-12-12 21:42:32,177 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542951432
2016-12-12 21:42:43,507 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-12 21:42:43,568 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542963333.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481546563507.meta
2016-12-12 21:42:43,568 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542963333.meta
2016-12-12 21:42:52,106 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 22730
2016-12-12 21:43:02,105 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 5497
2016-12-12 21:43:12,105 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer: regionserver60020.periodicFlusher requesting flush for region hbase:meta,,1.1588230740 after a delay of 18380
2016-12-12 21:43:14,841 INFO  [MemStoreFlusher.0] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.4 K
2016-12-12 21:43:14,932 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=10, memsize=1.4 K, hasBloomFilter=false, into tmp file hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/.tmp/1b150c61dc3947b9bda2af53d3fd1db4
2016-12-12 21:43:14,994 DEBUG [MemStoreFlusher.0] regionserver.HRegionFileSystem: Committing store file hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/.tmp/1b150c61dc3947b9bda2af53d3fd1db4 as hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info/1b150c61dc3947b9bda2af53d3fd1db4
2016-12-12 21:43:15,020 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info/1b150c61dc3947b9bda2af53d3fd1db4, entries=6, sequenceid=10, filesize=1.5 K
2016-12-12 21:43:15,022 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.4 K/1424, currentsize=0/0 for region hbase:meta,,1.1588230740 in 180ms, sequenceid=10, compaction requested=false
2016-12-12 21:46:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=26, hits=23, hitRatio=88.46%, , cachingAccesses=26, cachingHits=23, cachingHitsRatio=88.46%, evictions=389, evicted=0, evictedPerRun=0.0
2016-12-12 21:51:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=28, hits=24, hitRatio=85.71%, , cachingAccesses=28, cachingHits=24, cachingHitsRatio=85.71%, evictions=419, evicted=0, evictedPerRun=0.0
2016-12-12 21:56:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=30, hits=26, hitRatio=86.67%, , cachingAccesses=30, cachingHits=26, cachingHitsRatio=86.67%, evictions=449, evicted=0, evictedPerRun=0.0
2016-12-12 22:01:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=32, hits=28, hitRatio=87.50%, , cachingAccesses=32, cachingHits=28, cachingHitsRatio=87.50%, evictions=479, evicted=0, evictedPerRun=0.0
2016-12-12 22:06:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=34, hits=30, hitRatio=88.24%, , cachingAccesses=34, cachingHits=30, cachingHitsRatio=88.24%, evictions=509, evicted=0, evictedPerRun=0.0
2016-12-12 22:11:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=36, hits=32, hitRatio=88.89%, , cachingAccesses=36, cachingHits=32, cachingHitsRatio=88.89%, evictions=539, evicted=0, evictedPerRun=0.0
2016-12-12 22:16:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=38, hits=34, hitRatio=89.47%, , cachingAccesses=38, cachingHits=34, cachingHitsRatio=89.47%, evictions=569, evicted=0, evictedPerRun=0.0
2016-12-12 22:21:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=40, hits=36, hitRatio=90.00%, , cachingAccesses=40, cachingHits=36, cachingHitsRatio=90.00%, evictions=599, evicted=0, evictedPerRun=0.0
2016-12-12 22:26:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=42, hits=38, hitRatio=90.48%, , cachingAccesses=42, cachingHits=38, cachingHitsRatio=90.48%, evictions=629, evicted=0, evictedPerRun=0.0
2016-12-12 22:31:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=44, hits=40, hitRatio=90.91%, , cachingAccesses=44, cachingHits=40, cachingHitsRatio=90.91%, evictions=659, evicted=0, evictedPerRun=0.0
2016-12-12 22:36:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=46, hits=42, hitRatio=91.30%, , cachingAccesses=46, cachingHits=42, cachingHitsRatio=91.30%, evictions=689, evicted=0, evictedPerRun=0.0
2016-12-12 22:41:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=48, hits=44, hitRatio=91.67%, , cachingAccesses=48, cachingHits=44, cachingHitsRatio=91.67%, evictions=719, evicted=0, evictedPerRun=0.0
2016-12-12 22:41:54,931 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-12 22:42:32,272 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-12 22:42:32,336 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481546552107 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481550152272
2016-12-12 22:42:32,336 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481546552107
2016-12-12 22:42:43,651 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-12 22:42:43,711 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481546563507.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481550163651.meta
2016-12-12 22:42:43,711 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481542958199.meta
2016-12-12 22:42:43,711 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481546563507.meta
2016-12-12 22:46:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=50, hits=46, hitRatio=92.00%, , cachingAccesses=50, cachingHits=46, cachingHitsRatio=92.00%, evictions=749, evicted=0, evictedPerRun=0.0
2016-12-12 22:51:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=52, hits=48, hitRatio=92.31%, , cachingAccesses=52, cachingHits=48, cachingHitsRatio=92.31%, evictions=779, evicted=0, evictedPerRun=0.0
2016-12-12 22:56:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=54, hits=50, hitRatio=92.59%, , cachingAccesses=54, cachingHits=50, cachingHitsRatio=92.59%, evictions=809, evicted=0, evictedPerRun=0.0
2016-12-12 23:01:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=56, hits=52, hitRatio=92.86%, , cachingAccesses=56, cachingHits=52, cachingHitsRatio=92.86%, evictions=839, evicted=0, evictedPerRun=0.0
2016-12-12 23:06:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=58, hits=54, hitRatio=93.10%, , cachingAccesses=58, cachingHits=54, cachingHitsRatio=93.10%, evictions=869, evicted=0, evictedPerRun=0.0
2016-12-12 23:11:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=60, hits=56, hitRatio=93.33%, , cachingAccesses=60, cachingHits=56, cachingHitsRatio=93.33%, evictions=899, evicted=0, evictedPerRun=0.0
2016-12-12 23:16:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=62, hits=58, hitRatio=93.55%, , cachingAccesses=62, cachingHits=58, cachingHitsRatio=93.55%, evictions=929, evicted=0, evictedPerRun=0.0
2016-12-12 23:21:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=64, hits=60, hitRatio=93.75%, , cachingAccesses=64, cachingHits=60, cachingHitsRatio=93.75%, evictions=959, evicted=0, evictedPerRun=0.0
2016-12-12 23:26:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=66, hits=62, hitRatio=93.94%, , cachingAccesses=66, cachingHits=62, cachingHitsRatio=93.94%, evictions=989, evicted=0, evictedPerRun=0.0
2016-12-12 23:31:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=68, hits=64, hitRatio=94.12%, , cachingAccesses=68, cachingHits=64, cachingHitsRatio=94.12%, evictions=1019, evicted=0, evictedPerRun=0.0
2016-12-12 23:36:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=70, hits=66, hitRatio=94.29%, , cachingAccesses=70, cachingHits=66, cachingHitsRatio=94.29%, evictions=1049, evicted=0, evictedPerRun=0.0
2016-12-12 23:41:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=72, hits=68, hitRatio=94.44%, , cachingAccesses=72, cachingHits=68, cachingHitsRatio=94.44%, evictions=1079, evicted=0, evictedPerRun=0.0
2016-12-12 23:41:54,932 INFO  [MobFileCache #0] mob.MobFileCache: MobFileCache Statistics, access: 0, miss: 0, hit: 0, hit ratio: 0%, evicted files: 0
2016-12-12 23:42:32,411 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-12 23:42:32,471 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481550152272 with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481553752411
2016-12-12 23:42:32,471 DEBUG [regionserver60020.logRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481550152272
2016-12-12 23:42:43,795 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: Hlog roll period 3600000ms elapsed
2016-12-12 23:42:43,854 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481550163651.meta with entries=0, filesize=91; new WAL /hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481553763795.meta
2016-12-12 23:42:43,854 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: log file is ready for archiving hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740/fd%2C60020%2C1481542914740.1481550163651.meta
2016-12-12 23:46:54,924 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=74, hits=70, hitRatio=94.59%, , cachingAccesses=74, cachingHits=70, cachingHitsRatio=94.59%, evictions=1109, evicted=0, evictedPerRun=0.0
2016-12-12 23:51:54,923 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=76, hits=72, hitRatio=94.74%, , cachingAccesses=76, cachingHits=72, cachingHitsRatio=94.74%, evictions=1139, evicted=0, evictedPerRun=0.0
2016-12-12 23:53:44,179 WARN  [ResponseProcessor for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741881_1059] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741881_1059
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-12 23:53:44,179 WARN  [ResponseProcessor for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741880_1058] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741880_1058
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-12 23:54:05,215 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020. Trying to fail over immediately.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-12 23:54:05,217 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020 after 1 fail over attempts. Trying to fail over after sleeping for 1182ms.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-12 23:54:06,401 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020 after 2 fail over attempts. Trying to fail over after sleeping for 2903ms.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016年 12月 12日 月曜日 23:54:08 JST Terminating regionserver
2016-12-12 23:54:08,655 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@b91d8c4
2016-12-12 23:54:08,656 INFO  [Thread-10] regionserver.HRegionServer: STOPPED: Shutdown hook
2016-12-12 23:54:08,656 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2016-12-12 23:54:08,656 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2016-12-12 23:54:08,658 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2016-12-12 23:54:08,658 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2016-12-12 23:54:08,660 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2016-12-12 23:54:08,660 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2016-12-12 23:54:08,667 INFO  [SplitLogWorker-fd,60020,1481542914740] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2016-12-12 23:54:08,667 INFO  [SplitLogWorker-fd,60020,1481542914740] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481542914740 exiting
2016-12-12 23:54:08,670 INFO  [regionserver60020] mortbay.log: Stopped HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-12 23:54:08,771 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2016-12-12 23:54:08,771 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2016-12-12 23:54:08,773 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-12 23:54:08,773 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-12 23:54:08,773 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2016-12-12 23:54:08,773 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2016-12-12 23:54:08,774 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2016-12-12 23:54:08,776 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481542914740
2016-12-12 23:54:08,778 DEBUG [RS_CLOSE_REGION-fd:60020-1] handler.CloseRegionHandler: Processing close of hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 23:54:08,778 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Processing close of crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 23:54:08,779 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@72e6d41c
2016-12-12 23:54:08,780 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Closing hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.: disabling compactions & flushes
2016-12-12 23:54:08,780 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Updates disabled for region hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 23:54:08,780 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closing crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.: disabling compactions & flushes
2016-12-12 23:54:08,781 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Updates disabled for region crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 23:54:08,781 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f2d6c78a0004
2016-12-12 23:54:08,782 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed f
2016-12-12 23:54:08,782 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed h
2016-12-12 23:54:08,782 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed il
2016-12-12 23:54:08,782 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed mk
2016-12-12 23:54:08,783 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed mtdt
2016-12-12 23:54:08,783 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed ol
2016-12-12 23:54:08,783 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed p
2016-12-12 23:54:08,783 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed s
2016-12-12 23:54:08,783 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed stm
2016-12-12 23:54:08,784 INFO  [StoreCloserThread-hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.-1] regionserver.HStore: Closed info
2016-12-12 23:54:08,787 INFO  [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closed crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 23:54:08,787 INFO  [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Closed hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 23:54:08,787 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Closed crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-12 23:54:08,787 DEBUG [RS_CLOSE_REGION-fd:60020-1] handler.CloseRegionHandler: Closed hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-12 23:54:08,809 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f2d6c78a0004 closed
2016-12-12 23:54:08,809 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-12 23:54:08,810 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2016-12-12 23:54:08,810 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2016-12-12 23:54:08,810 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2016-12-12 23:54:08,810 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2016-12-12 23:54:08,810 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 1 regions to close
2016-12-12 23:54:08,810 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740}
2016-12-12 23:54:08,811 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-12 23:54:08,811 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-12 23:54:08,811 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-12 23:54:08,813 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2016-12-12 23:54:08,814 DEBUG [RS_CLOSE_META-fd:60020-0] coprocessor.CoprocessorHost: Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2016-12-12 23:54:08,815 INFO  [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2016-12-12 23:54:08,815 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Closed hbase:meta,,1.1588230740
2016-12-12 23:54:09,011 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481542914740; all regions closed.
2016-12-12 23:54:09,011 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-12 23:54:09,011 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier exiting
2016-12-12 23:54:09,012 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,012 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 exiting
2016-12-12 23:54:09,012 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,012 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 exiting
2016-12-12 23:54:09,013 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,013 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 exiting
2016-12-12 23:54:09,013 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,013 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 exiting
2016-12-12 23:54:09,013 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,013 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 exiting
2016-12-12 23:54:09,014 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-12 23:54:09,014 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter exiting
2016-12-12 23:54:09,014 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740
2016-12-12 23:54:09,015 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-12 23:54:09,016 ERROR [regionserver60020] regionserver.HRegionServer: Metalog close and delete failed
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-12 23:54:09,016 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-12 23:54:09,016 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2016-12-12 23:54:09,017 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,017 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2016-12-12 23:54:09,018 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,018 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2016-12-12 23:54:09,019 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,019 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2016-12-12 23:54:09,020 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,020 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2016-12-12 23:54:09,021 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-12 23:54:09,021 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2016-12-12 23:54:09,022 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-12 23:54:09,022 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2016-12-12 23:54:09,022 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740
2016-12-12 23:54:09,023 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-12 23:54:09,024 ERROR [regionserver60020] regionserver.HRegionServer: Close and delete failed
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-12 23:54:09,024 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2016-12-12 23:54:09,024 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2016-12-12 23:54:09,306 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/127.0.1.1:8020 after 3 fail over attempts. Trying to fail over after sleeping for 3982ms.
java.net.ConnectException: Call From fd/127.0.1.1 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-12 23:54:12,247 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2016-12-12 23:54:12,247 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2016-12-12 23:54:12,247 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2016-12-12 23:54:12,273 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f2d6c78a0007
2016-12-12 23:54:12,281 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f2d6c78a0007 closed
2016-12-12 23:54:12,281 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-12 23:54:12,323 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f2d6c78a0002 closed
2016-12-12 23:54:12,323 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-12 23:54:12,323 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481542914740; zookeeper connection closed.
2016-12-12 23:54:12,323 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2016-12-12 23:54:12,324 INFO  [Thread-10] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2016-12-12 23:54:12,326 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook finished.
2016年 12月 13日 火曜日 21:32:51 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-13 21:32:53,624 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-13 21:32:53,625 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-13 21:32:53,625 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-13 21:32:54,073 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:runlevel=2
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-13 21:32:54,074 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:RUNLEVEL=2
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-13 21:32:54,075 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:UPSTART_INSTANCE=
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:PREVLEVEL=N
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:UPSTART_JOB=rc
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-13 21:32:54,076 INFO  [main] util.ServerCommandLine: env:TERM=linux
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=c8
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:previous=N
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-13 21:32:54,077 INFO  [main] util.ServerCommandLine: env:UPSTART_EVENTS=runlevel
2016-12-13 21:32:54,078 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-13 21:32:54,078 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-13 21:32:54,078 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-13 21:32:54,078 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-13 21:32:54,078 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-13 21:32:54,078 INFO  [main] util.ServerCommandLine: env:XDG_SEAT=seat0
2016-12-13 21:32:54,079 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-13 21:32:54,079 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-13 21:32:54,079 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/124
2016-12-13 21:32:54,079 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-13 21:32:54,079 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-13 21:32:54,079 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-13 21:32:54,079 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-13 21:32:54,082 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-13 21:32:54,083 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-13 21:32:54,411 DEBUG [main] regionserver.HRegionServer: regionserver/fd/127.0.1.1:60020 HConnection server-to-server retries=350
2016-12-13 21:32:54,675 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-13 21:32:54,706 INFO  [main] ipc.RpcServer: regionserver/fd/127.0.1.1:60020: started 10 reader(s).
2016-12-13 21:32:54,843 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-13 21:32:54,974 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-13 21:32:54,974 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-13 21:32:55,141 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-13 21:32:55,160 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-13 21:32:55,235 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-13 21:32:55,335 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-13 21:32:55,340 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-13 21:32:55,340 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-13 21:32:55,364 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-13 21:32:55,364 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-13 21:32:55,851 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 21:32:55,869 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 21:32:55,878 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-13 21:32:55,879 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-13 21:32:55,879 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-13 21:32:55,879 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-13 21:32:55,879 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-13 21:32:55,879 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-13 21:32:55,880 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 21:32:55,880 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-13 21:32:55,880 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-13 21:32:55,881 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-13 21:32:55,881 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-13 21:32:55,881 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-13 21:32:55,881 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-13 21:32:55,881 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-13 21:32:55,881 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-13 21:32:55,882 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-13 21:32:55,906 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/127.0.1.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 21:32:55,912 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:33244, server: fd/127.0.1.1:2181
2016-12-13 21:32:55,928 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/127.0.1.1:2181, sessionid = 0x158f82be0b90003, negotiated timeout = 40000
2016-12-13 21:32:57,108 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x235d0087 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 21:32:57,109 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x235d0087, quorum=fd:2181, baseZNode=/hbase
2016-12-13 21:32:57,113 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 21:32:57,113 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:52424, server: fd/192.168.1.70:2181
2016-12-13 21:32:57,134 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f82be0b90004, negotiated timeout = 40000
2016-12-13 21:32:57,248 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-13 21:32:57,263 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@32f22c51
2016-12-13 21:32:57,271 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 8036be00-036b-4ecd-8bec-043370acdc7d
2016-12-13 21:32:57,277 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-13 21:32:57,310 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-13 21:32:57,324 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-13 21:32:57,333 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-13 21:32:57,339 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-13 21:32:57,354 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481632373122 with port=60020, startcode=1481632375004
2016-12-13 21:32:57,789 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-13 21:32:57,789 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-13 21:33:00,790 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481632373122 with port=60020, startcode=1481632375004
2016-12-13 21:33:00,794 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-13 21:33:00,794 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-13 21:33:03,794 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481632373122 with port=60020, startcode=1481632375004
2016-12-13 21:33:03,798 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-13 21:33:03,798 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-13 21:33:06,798 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481632373122 with port=60020, startcode=1481632375004
2016-12-13 21:33:06,801 DEBUG [regionserver60020] regionserver.HRegionServer: Master is not running yet
2016-12-13 21:33:06,801 WARN  [regionserver60020] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
2016-12-13 21:33:09,802 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481632373122 with port=60020, startcode=1481632375004
2016-12-13 21:33:09,834 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-13 21:33:09,834 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-13 21:33:09,834 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 21:33:09,835 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-13 21:33:09,835 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-13 21:33:09,907 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-13 21:33:09,923 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481632375004
2016-12-13 21:33:10,071 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-13 21:33:10,088 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 21:33:10,693 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481632375004/fd%2C60020%2C1481632375004.1481632390165
2016-12-13 21:33:10,719 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-13 21:33:10,731 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 21:33:10,731 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 21:33:10,732 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 21:33:10,732 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 21:33:10,732 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-13 21:33:10,740 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481632375004] other RSs: [fd,60020,1481632375004]
2016-12-13 21:33:10,790 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 21:33:10,801 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x7256c1e3 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 21:33:10,801 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x7256c1e3, quorum=fd:2181, baseZNode=/hbase
2016-12-13 21:33:10,803 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/127.0.1.1:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 21:33:10,804 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /127.0.0.1:33262, server: fd/127.0.1.1:2181
2016-12-13 21:33:10,824 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/127.0.1.1:2181, sessionid = 0x158f82be0b90007, negotiated timeout = 40000
2016-12-13 21:33:10,833 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-13 21:33:10,833 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-13 21:33:10,833 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-13 21:33:10,834 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-13 21:33:10,834 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-13 21:33:10,834 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-13 21:33:10,835 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-13 21:33:10,835 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-13 21:33:10,835 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-13 21:33:10,835 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-13 21:33:10,836 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-13 21:33:10,836 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-13 21:33:10,836 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-13 21:33:10,836 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-13 21:33:10,836 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-13 21:33:10,836 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-13 21:33:10,836 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-13 21:33:10,837 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-13 21:33:10,837 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-13 21:33:10,837 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-13 21:33:10,837 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-13 21:33:10,837 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-13 21:33:10,837 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-13 21:33:10,838 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-13 21:33:10,838 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-13 21:33:10,838 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-13 21:33:10,838 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-13 21:33:10,838 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-13 21:33:10,838 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-13 21:33:10,839 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-13 21:33:10,839 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-13 21:33:10,839 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-13 21:33:10,839 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-13 21:33:10,839 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-13 21:33:10,839 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-13 21:33:10,840 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-13 21:33:10,840 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-13 21:33:10,840 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-13 21:33:10,840 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-13 21:33:10,840 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-13 21:33:10,840 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-13 21:33:10,840 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-13 21:33:10,841 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-13 21:33:10,841 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-13 21:33:10,841 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-13 21:33:10,883 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 21:33:10,891 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481632375004, RpcServer on fd/127.0.1.1:60020, sessionid=0x158f82be0b90003
2016-12-13 21:33:10,891 INFO  [SplitLogWorker-fd,60020,1481632375004] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481632375004 starting
2016-12-13 21:33:10,895 INFO  [SplitLogWorker-fd,60020,1481632375004] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2e9880e6 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 21:33:10,895 INFO  [SplitLogWorker-fd,60020,1481632375004] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x2e9880e6, quorum=fd:2181, baseZNode=/hbase
2016-12-13 21:33:10,897 INFO  [SplitLogWorker-fd,60020,1481632375004-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 21:33:10,899 INFO  [SplitLogWorker-fd,60020,1481632375004-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:52442, server: fd/192.168.1.70:2181
2016-12-13 21:33:10,901 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-13 21:33:10,901 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481632375004
2016-12-13 21:33:10,901 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481632375004'
2016-12-13 21:33:10,901 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-13 21:33:10,907 INFO  [SplitLogWorker-fd,60020,1481632375004-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f82be0b90008, negotiated timeout = 40000
2016-12-13 21:33:10,908 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-13 21:33:10,909 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-13 21:33:10,977 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-13 21:33:11,138 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-13 21:33:13,149 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-13 21:33:13,174 INFO  [SplitLogWorker-fd,60020,1481632375004] regionserver.SplitLogWorker: worker fd,60020,1481632375004 acquired task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481542914740-splitting%2Ffd%252C60020%252C1481542914740.1481553763795.meta
2016-12-13 21:33:13,236 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 21:33:13,253 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Splitting hlog: hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553763795.meta, length=83
2016-12-13 21:33:13,253 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: DistributedLogReplay = false
2016-12-13 21:33:13,260 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] util.FSHDFSUtils: Recovering lease on dfs file hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553763795.meta
2016-12-13 21:33:13,299 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] util.FSHDFSUtils: recoverLease=false, attempt=0 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553763795.meta after 39ms
2016-12-13 21:33:17,302 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] util.FSHDFSUtils: recoverLease=true, attempt=1 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553763795.meta after 4042ms
2016-12-13 21:33:17,383 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-0-Writer-0,5,main]: starting
2016-12-13 21:33:17,384 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-0-Writer-2,5,main]: starting
2016-12-13 21:33:17,384 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-0-Writer-1,5,main]: starting
2016-12-13 21:33:17,400 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Finishing writing output logs and closing down.
2016-12-13 21:33:17,400 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Waiting for split writer threads to finish
2016-12-13 21:33:17,401 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Split writers finished
2016-12-13 21:33:17,402 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553763795.meta is corrupted = false progress failed = false
2016-12-13 21:33:17,424 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481542914740-splitting%2Ffd%252C60020%252C1481542914740.1481553763795.meta to final state DONE fd,60020,1481632375004
2016-12-13 21:33:17,424 INFO  [RS_LOG_REPLAY_OPS-fd:60020-0] handler.HLogSplitterHandler: worker fd,60020,1481632375004 done with task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481542914740-splitting%2Ffd%252C60020%252C1481542914740.1481553763795.meta in 4240ms
2016-12-13 21:33:17,523 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-13 21:33:17,724 INFO  [PriorityRpcServer.handler=1,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-13 21:33:17,741 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 21:33:17,757 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 21:33:17,757 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481632375004
2016-12-13 21:33:17,758 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 21:33:17,814 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481632375004/fd%2C60020%2C1481632375004.1481632397765.meta
2016-12-13 21:33:17,843 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-13 21:33:17,904 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-13 21:33:17,909 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-13 21:33:17,921 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-13 21:33:17,927 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-13 21:33:17,927 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-13 21:33:18,047 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:18,098 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-13 21:33:18,098 INFO  [StoreFileOpenerThread-info-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-13 21:33:18,162 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info/1b150c61dc3947b9bda2af53d3fd1db4, isReference=false, isBulkLoadResult=false, seqid=10, majorCompaction=false
2016-12-13 21:33:18,183 DEBUG [StoreOpener-1588230740-1] regionserver.HStore: loaded hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info/a0c77bd9b3e240658717519260c57dc0, isReference=false, isBulkLoadResult=false, seqid=6, majorCompaction=false
2016-12-13 21:33:18,196 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-13 21:33:18,205 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=11
2016-12-13 21:33:18,205 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-13 21:33:18,208 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-13 21:33:18,209 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481632375004
2016-12-13 21:33:18,254 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-13 21:33:18,255 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 21:33:18,273 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 21:33:18,273 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481632375004
2016-12-13 21:33:18,273 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481632375004
2016-12-13 21:33:18,540 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-13 21:33:18,557 INFO  [SplitLogWorker-fd,60020,1481632375004] regionserver.SplitLogWorker: worker fd,60020,1481632375004 acquired task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481542914740-splitting%2Ffd%252C60020%252C1481542914740.1481553752411
2016-12-13 21:33:18,595 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 21:33:18,595 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Splitting hlog: hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553752411, length=83
2016-12-13 21:33:18,595 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: DistributedLogReplay = false
2016-12-13 21:33:18,607 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] util.FSHDFSUtils: Recovering lease on dfs file hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553752411
2016-12-13 21:33:18,631 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] util.FSHDFSUtils: recoverLease=false, attempt=0 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553752411 after 23ms
2016-12-13 21:33:22,634 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] util.FSHDFSUtils: recoverLease=true, attempt=1 on file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553752411 after 4026ms
2016-12-13 21:33:22,652 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1-Writer-0] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-1-Writer-0,5,main]: starting
2016-12-13 21:33:22,652 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1-Writer-1] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-1-Writer-1,5,main]: starting
2016-12-13 21:33:22,653 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1-Writer-2] wal.HLogSplitter: Writer thread Thread[RS_LOG_REPLAY_OPS-fd:60020-1-Writer-2,5,main]: starting
2016-12-13 21:33:22,653 DEBUG [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Finishing writing output logs and closing down.
2016-12-13 21:33:22,653 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Waiting for split writer threads to finish
2016-12-13 21:33:22,654 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Split writers finished
2016-12-13 21:33:22,654 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] wal.HLogSplitter: Processed 0 edits across 0 regions; log file=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481542914740-splitting/fd%2C60020%2C1481542914740.1481553752411 is corrupted = false progress failed = false
2016-12-13 21:33:22,665 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] handler.HLogSplitterHandler: successfully transitioned task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481542914740-splitting%2Ffd%252C60020%252C1481542914740.1481553752411 to final state DONE fd,60020,1481632375004
2016-12-13 21:33:22,665 INFO  [RS_LOG_REPLAY_OPS-fd:60020-1] handler.HLogSplitterHandler: worker fd,60020,1481632375004 done with task /hbase/splitWAL/WALs%2Ffd%2C60020%2C1481542914740-splitting%2Ffd%252C60020%252C1481542914740.1481553752411 in 4107ms
2016-12-13 21:33:22,715 DEBUG [regionserver60020-EventThread] regionserver.SplitLogWorker: tasks arrived or departed
2016-12-13 21:33:22,772 INFO  [PriorityRpcServer.handler=7,queue=0,port=60020] regionserver.HRegionServer: Open crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:33:22,798 INFO  [PriorityRpcServer.handler=7,queue=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:33:22,799 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioning c5a721cf7a7f1fdf4f62e37dd30be0f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 21:33:22,807 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioned node c5a721cf7a7f1fdf4f62e37dd30be0f3 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 21:33:22,807 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => c5a721cf7a7f1fdf4f62e37dd30be0f3, NAME => 'crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.', STARTKEY => '', ENDKEY => ''}
2016-12-13 21:33:22,809 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table crawlId_webpage c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-13 21:33:22,810 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Instantiated crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:33:22,812 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioning c6fa8b442e8dcd3a19adfedd7cd02854 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 21:33:22,820 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,823 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioned node c6fa8b442e8dcd3a19adfedd7cd02854 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 21:33:22,823 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/f
2016-12-13 21:33:22,824 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Opening region: {ENCODED => c6fa8b442e8dcd3a19adfedd7cd02854, NAME => 'hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.', STARTKEY => '', ENDKEY => ''}
2016-12-13 21:33:22,824 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-13 21:33:22,825 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Instantiated hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:33:22,832 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,833 INFO  [StoreOpener-c6fa8b442e8dcd3a19adfedd7cd02854-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,835 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/h
2016-12-13 21:33:22,838 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,841 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/il
2016-12-13 21:33:22,844 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,848 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/mk
2016-12-13 21:33:22,851 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,854 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/mtdt
2016-12-13 21:33:22,856 DEBUG [StoreOpener-c6fa8b442e8dcd3a19adfedd7cd02854-1] regionserver.HStore: loaded hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854/info/d44ba64dee834addb5937cb8513fc9d5, isReference=false, isBulkLoadResult=false, seqid=4, majorCompaction=false
2016-12-13 21:33:22,859 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,860 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/namespace/c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-13 21:33:22,861 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/ol
2016-12-13 21:33:22,864 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,864 INFO  [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Onlined c6fa8b442e8dcd3a19adfedd7cd02854; next sequenceid=5
2016-12-13 21:33:22,865 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node c6fa8b442e8dcd3a19adfedd7cd02854
2016-12-13 21:33:22,867 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:33:22,867 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/p
2016-12-13 21:33:22,873 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,876 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/s
2016-12-13 21:33:22,880 INFO  [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 21:33:22,882 DEBUG [StoreOpener-c5a721cf7a7f1fdf4f62e37dd30be0f3-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3/stm
2016-12-13 21:33:22,886 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-13 21:33:22,891 INFO  [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Onlined c5a721cf7a7f1fdf4f62e37dd30be0f3; next sequenceid=1
2016-12-13 21:33:22,891 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node c5a721cf7a7f1fdf4f62e37dd30be0f3
2016-12-13 21:33:22,893 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] regionserver.HRegionServer: Post open deploy tasks for region=crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:33:23,014 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 21:33:23,015 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 21:33:23,029 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] catalog.MetaEditor: Updated row hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. with server=fd,60020,1481632375004
2016-12-13 21:33:23,030 INFO  [PostOpenDeployTasks:c6fa8b442e8dcd3a19adfedd7cd02854] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:33:23,030 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] catalog.MetaEditor: Updated row crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3. with server=fd,60020,1481632375004
2016-12-13 21:33:23,030 INFO  [PostOpenDeployTasks:c5a721cf7a7f1fdf4f62e37dd30be0f3] regionserver.HRegionServer: Finished post open deploy task for crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:33:23,031 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioning c6fa8b442e8dcd3a19adfedd7cd02854 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 21:33:23,031 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioning c5a721cf7a7f1fdf4f62e37dd30be0f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 21:33:23,057 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioned node c6fa8b442e8dcd3a19adfedd7cd02854 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 21:33:23,057 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f82be0b90003, quorum=fd:2181, baseZNode=/hbase Transitioned node c5a721cf7a7f1fdf4f62e37dd30be0f3 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 21:33:23,057 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Transitioned c6fa8b442e8dcd3a19adfedd7cd02854 to OPENED in zk on fd,60020,1481632375004
2016-12-13 21:33:23,057 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Opened hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854. on fd,60020,1481632375004
2016-12-13 21:33:23,057 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Transitioned c5a721cf7a7f1fdf4f62e37dd30be0f3 to OPENED in zk on fd,60020,1481632375004
2016-12-13 21:33:23,057 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Opened crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3. on fd,60020,1481632375004
2016-12-13 21:33:23,141 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481632375004/fd%2C60020%2C1481632375004.1481632397765.meta with entries=2, filesize=837; new WAL /hbase/WALs/fd,60020,1481632375004/fd%2C60020%2C1481632375004.1481632403016.meta
2016-12-13 21:37:55,155 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=23, hits=19, hitRatio=82.61%, , cachingAccesses=23, cachingHits=19, cachingHitsRatio=82.61%, evictions=29, evicted=0, evictedPerRun=0.0
2016-12-13 21:42:52,645 WARN  [ResponseProcessor for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741884_1064] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741884_1064
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-13 21:42:52,645 WARN  [ResponseProcessor for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741882_1060] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-2086386599-127.0.1.1-1481376638776:blk_1073741882_1060
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-13 21:42:55,154 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.24 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=25, hits=21, hitRatio=84.00%, , cachingAccesses=25, cachingHits=21, cachingHitsRatio=84.00%, evictions=59, evicted=0, evictedPerRun=0.0
2016年 12月 13日 火曜日 21:44:04 JST Terminating regionserver
2016-12-13 21:44:04,963 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@4cc76301
2016-12-13 21:44:04,964 INFO  [Thread-10] regionserver.HRegionServer: STOPPED: Shutdown hook
2016-12-13 21:44:04,964 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2016-12-13 21:44:04,964 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2016-12-13 21:44:04,966 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2016-12-13 21:44:04,966 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2016-12-13 21:44:04,971 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2016-12-13 21:44:04,972 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2016-12-13 21:44:04,972 INFO  [SplitLogWorker-fd,60020,1481632375004] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2016-12-13 21:44:04,973 INFO  [SplitLogWorker-fd,60020,1481632375004] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481632375004 exiting
2016-12-13 21:44:04,980 INFO  [regionserver60020] mortbay.log: Stopped HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 21:44:05,083 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2016-12-13 21:44:05,084 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2016-12-13 21:44:05,083 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2016-12-13 21:44:05,084 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2016-12-13 21:44:05,085 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 21:44:05,085 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2016-12-13 21:44:05,085 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 21:44:05,089 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481632375004
2016-12-13 21:44:05,089 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Processing close of crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:44:05,089 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@32f22c51
2016-12-13 21:44:05,092 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closing crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.: disabling compactions & flushes
2016-12-13 21:44:05,092 DEBUG [RS_CLOSE_REGION-fd:60020-1] handler.CloseRegionHandler: Processing close of hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:44:05,092 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f82be0b90004
2016-12-13 21:44:05,093 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Closing hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.: disabling compactions & flushes
2016-12-13 21:44:05,093 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Updates disabled for region crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:44:05,093 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Updates disabled for region hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed f
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed h
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed il
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed mk
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed mtdt
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed ol
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed p
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed s
2016-12-13 21:44:05,096 INFO  [StoreCloserThread-crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.-1] regionserver.HStore: Closed stm
2016-12-13 21:44:05,105 INFO  [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closed crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:44:05,105 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Closed crawlId_webpage,,1481378430509.c5a721cf7a7f1fdf4f62e37dd30be0f3.
2016-12-13 21:44:05,110 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f82be0b90004 closed
2016-12-13 21:44:05,110 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 21:44:05,111 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2016-12-13 21:44:05,111 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2016-12-13 21:44:05,111 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2016-12-13 21:44:05,111 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2016-12-13 21:44:05,112 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 2 regions to close
2016-12-13 21:44:05,112 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740, c6fa8b442e8dcd3a19adfedd7cd02854=hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.}
2016-12-13 21:44:05,113 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-13 21:44:05,113 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-13 21:44:05,113 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-13 21:44:05,114 INFO  [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.4 K
2016-12-13 21:44:05,141 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=0
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:05,141 INFO  [StoreCloserThread-hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.-1] regionserver.HStore: Closed info
2016-12-13 21:44:05,144 INFO  [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Closed hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:44:05,145 DEBUG [RS_CLOSE_REGION-fd:60020-1] handler.CloseRegionHandler: Closed hbase:namespace,,1481376762133.c6fa8b442e8dcd3a19adfedd7cd02854.
2016-12-13 21:44:06,114 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 1 regions to close
2016-12-13 21:44:06,114 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740}
2016-12-13 21:44:06,151 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=1
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:07,160 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=2
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:08,169 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=3
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:09,179 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=4
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:10,189 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=5
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:10,746 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2016-12-13 21:44:10,750 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2016-12-13 21:44:10,751 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2016-12-13 21:44:11,198 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=6
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:12,205 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=7
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:13,213 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=8
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:14,223 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HStore: Failed flushing store file, retrying num=9
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:14,226 FATAL [RS_CLOSE_META-fd:60020-0] regionserver.HRegionServer: ABORTING region server fd,60020,1481632375004: Unrecoverable exception while closing region hbase:meta,,1.1588230740, still finishing close
org.apache.hadoop.hbase.DroppedSnapshotException: region: hbase:meta,,1
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1804)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	... 8 more
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:14,227 FATAL [RS_CLOSE_META-fd:60020-0] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: [org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint]
2016-12-13 21:44:14,239 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HRegionServer: Unable to report fatal error to master
com.google.protobuf.ServiceException: java.net.ConnectException: Connection refused
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1678)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.reportRSFatalError(RegionServerStatusProtos.java:5426)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.abort(HRegionServer.java:1894)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:159)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupConnection(RpcClient.java:578)
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:868)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	... 8 more
2016-12-13 21:44:14,240 ERROR [RS_CLOSE_META-fd:60020-0] executor.EventHandler: Caught throwable while processing event M_RS_CLOSE_META
java.lang.RuntimeException: org.apache.hadoop.hbase.DroppedSnapshotException: region: hbase:meta,,1
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:161)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.DroppedSnapshotException: region: hbase:meta,,1
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1804)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	... 4 more
Caused by: org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2689)
	at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2658)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:831)
	at org.apache.hadoop.hdfs.DistributedFileSystem$16.doCall(DistributedFileSystem.java:827)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:827)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:820)
	at org.apache.hadoop.fs.FilterFileSystem.mkdirs(FilterFileSystem.java:282)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:604)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	... 8 more
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=WRITE, inode="/":hdfs:hadoop:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkFsPermission(DefaultAuthorizationProvider.java:257)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:238)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.check(DefaultAuthorizationProvider.java:216)
	at org.apache.hadoop.hdfs.server.namenode.DefaultAuthorizationProvider.checkPermission(DefaultAuthorizationProvider.java:145)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:138)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6348)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6330)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6282)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:4146)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:4116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:4089)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:821)
	at org.apache.hadoop.hdfs.server.namenode.AuthorizationProviderProxyClientProtocol.mkdirs(AuthorizationProviderProxyClientProtocol.java:297)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:594)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:587)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1026)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1678)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:531)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.mkdirs(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor15.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.mkdirs(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2687)
	... 22 more
2016-12-13 21:44:14,322 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-13 21:44:14,322 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-13 21:44:14,322 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-13 21:44:14,322 FATAL [RS_CLOSE_META-fd:60020-0] regionserver.HRegionServer: ABORTING region server fd,60020,1481632375004: Unrecoverable exception while closing region hbase:meta,,1.1588230740, still finishing close
java.io.IOException: Aborting flush because server is abortted...
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1679)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-12-13 21:44:14,322 FATAL [RS_CLOSE_META-fd:60020-0] regionserver.HRegionServer: RegionServer abort: loaded coprocessors are: [org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint]
2016-12-13 21:44:14,323 WARN  [RS_CLOSE_META-fd:60020-0] regionserver.HRegionServer: Unable to report fatal error to master
com.google.protobuf.ServiceException: org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: fd/127.0.1.1:60000
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1678)
	at org.apache.hadoop.hbase.ipc.RpcClient$BlockingRpcChannelImplementation.callBlockingMethod(RpcClient.java:1719)
	at org.apache.hadoop.hbase.protobuf.generated.RegionServerStatusProtos$RegionServerStatusService$BlockingStub.reportRSFatalError(RegionServerStatusProtos.java:5426)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.abort(HRegionServer.java:1894)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:159)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.hadoop.hbase.ipc.RpcClient$FailedServerException: This server is in the failed servers list: fd/127.0.1.1:60000
	at org.apache.hadoop.hbase.ipc.RpcClient$Connection.setupIOstreams(RpcClient.java:853)
	at org.apache.hadoop.hbase.ipc.RpcClient.getConnection(RpcClient.java:1543)
	at org.apache.hadoop.hbase.ipc.RpcClient.call(RpcClient.java:1442)
	at org.apache.hadoop.hbase.ipc.RpcClient.callBlockingMethod(RpcClient.java:1661)
	... 8 more
2016-12-13 21:44:14,323 ERROR [RS_CLOSE_META-fd:60020-0] executor.EventHandler: Caught throwable while processing event M_RS_CLOSE_META
java.lang.RuntimeException: java.io.IOException: Aborting flush because server is abortted...
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:161)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Aborting flush because server is abortted...
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1679)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	... 4 more
2016-12-13 21:44:14,522 INFO  [regionserver60020] regionserver.HRegionServer: We were exiting though online regions are not empty, because some regions failed closing
2016-12-13 21:44:14,522 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481632375004; all regions closed.
2016-12-13 21:44:14,522 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 21:44:14,522 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier exiting
2016-12-13 21:44:14,524 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,524 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 exiting
2016-12-13 21:44:14,525 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,525 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 exiting
2016-12-13 21:44:14,525 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,525 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 exiting
2016-12-13 21:44:14,526 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,526 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 exiting
2016-12-13 21:44:14,526 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,526 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 exiting
2016-12-13 21:44:14,527 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 21:44:14,527 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter exiting
2016-12-13 21:44:14,527 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481632375004
2016-12-13 21:44:14,528 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 21:44:14,530 ERROR [regionserver60020] regionserver.HRegionServer: Metalog close and delete failed
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 21:44:14,530 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 21:44:14,530 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2016-12-13 21:44:14,531 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,531 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2016-12-13 21:44:14,531 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,531 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2016-12-13 21:44:14,531 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,531 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2016-12-13 21:44:14,532 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,532 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2016-12-13 21:44:14,532 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 21:44:14,532 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2016-12-13 21:44:14,533 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 21:44:14,533 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2016-12-13 21:44:14,533 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481632375004
2016-12-13 21:44:14,533 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 21:44:14,534 ERROR [regionserver60020] regionserver.HRegionServer: Close and delete failed
java.io.IOException: All datanodes 127.0.0.1:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 21:44:14,534 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2016-12-13 21:44:14,534 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2016-12-13 21:44:14,551 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f82be0b90007
2016-12-13 21:44:14,559 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f82be0b90007 closed
2016-12-13 21:44:14,559 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 21:44:14,576 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f82be0b90003 closed
2016-12-13 21:44:14,576 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 21:44:14,576 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481632375004; zookeeper connection closed.
2016-12-13 21:44:14,576 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2016-12-13 21:44:14,577 ERROR [main] regionserver.HRegionServerCommandLine: Region server exiting
java.lang.RuntimeException: HRegionServer Aborted
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.start(HRegionServerCommandLine.java:66)
	at org.apache.hadoop.hbase.regionserver.HRegionServerCommandLine.run(HRegionServerCommandLine.java:85)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:126)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.main(HRegionServer.java:2473)
2016-12-13 21:44:14,577 INFO  [Thread-10] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2016-12-13 21:44:14,579 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook finished.
2016年 12月 13日 火曜日 22:09:45 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-13 22:09:47,361 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-13 22:09:47,362 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-13 22:09:47,362 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-13 22:09:47,817 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-13 22:09:47,818 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-13 22:09:47,819 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=4
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-13 22:09:47,820 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-13 22:09:47,821 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-13 22:09:47,821 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-13 22:09:47,821 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-13 22:09:47,821 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-13 22:09:47,821 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-13 22:09:47,821 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-13 22:09:47,822 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-13 22:09:47,822 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-13 22:09:47,822 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2016-12-13 22:09:47,822 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-13 22:09:47,822 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-13 22:09:47,822 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-13 22:09:47,822 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-13 22:09:47,825 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-13 22:09:47,826 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-13 22:09:48,156 DEBUG [main] regionserver.HRegionServer: regionserver/fd/192.168.1.70:60020 HConnection server-to-server retries=350
2016-12-13 22:09:48,426 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-13 22:09:48,456 INFO  [main] ipc.RpcServer: regionserver/fd/192.168.1.70:60020: started 10 reader(s).
2016-12-13 22:09:48,588 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-13 22:09:48,715 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-13 22:09:48,715 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-13 22:09:48,892 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-13 22:09:48,908 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-13 22:09:48,963 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-13 22:09:49,045 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-13 22:09:49,051 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-13 22:09:49,051 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-13 22:09:49,074 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-13 22:09:49,074 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-13 22:09:49,547 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 22:09:49,564 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:09:49,577 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-13 22:09:49,577 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-13 22:09:49,577 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-13 22:09:49,577 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-13 22:09:49,577 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-13 22:09:49,578 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-13 22:09:49,580 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-13 22:09:49,582 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:09:49,602 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:09:49,603 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44700, server: fd/192.168.1.70:2181
2016-12-13 22:09:49,624 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c0004, negotiated timeout = 40000
2016-12-13 22:09:49,719 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2eaa0427 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:09:49,719 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x2eaa0427, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:09:49,721 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:09:49,721 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44702, server: fd/192.168.1.70:2181
2016-12-13 22:09:49,731 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c0005, negotiated timeout = 40000
2016-12-13 22:09:50,555 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-13 22:09:50,576 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6de7cf3b
2016-12-13 22:09:50,582 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 333a9cec-86d1-404b-95ef-44a29a5eab9a
2016-12-13 22:09:50,587 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-13 22:09:50,609 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-13 22:09:50,617 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-13 22:09:50,626 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-13 22:09:50,631 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-13 22:09:50,645 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481634583073 with port=60020, startcode=1481634588745
2016-12-13 22:09:51,285 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-13 22:09:51,285 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-13 22:09:51,286 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:09:51,286 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-13 22:09:51,286 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-13 22:09:51,333 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-13 22:09:51,346 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481634588745
2016-12-13 22:09:51,532 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-13 22:09:51,587 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 22:09:52,029 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481634588745/fd%2C60020%2C1481634588745.1481634591658
2016-12-13 22:09:52,058 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-13 22:09:52,070 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 22:09:52,070 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 22:09:52,070 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 22:09:52,070 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 22:09:52,071 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-13 22:09:52,079 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481634588745] other RSs: [fd,60020,1481634588745]
2016-12-13 22:09:52,129 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:09:52,138 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x76050bd9 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:09:52,139 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x76050bd9, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:09:52,143 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:09:52,144 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44708, server: fd/192.168.1.70:2181
2016-12-13 22:09:52,154 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c0006, negotiated timeout = 40000
2016-12-13 22:09:52,163 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-13 22:09:52,163 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-13 22:09:52,164 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-13 22:09:52,164 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-13 22:09:52,165 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-13 22:09:52,165 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-13 22:09:52,165 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-13 22:09:52,166 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-13 22:09:52,166 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-13 22:09:52,166 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-13 22:09:52,166 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-13 22:09:52,167 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-13 22:09:52,167 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-13 22:09:52,167 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-13 22:09:52,167 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-13 22:09:52,167 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-13 22:09:52,167 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-13 22:09:52,167 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-13 22:09:52,168 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-13 22:09:52,168 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-13 22:09:52,168 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-13 22:09:52,168 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-13 22:09:52,168 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-13 22:09:52,168 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-13 22:09:52,169 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-13 22:09:52,169 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-13 22:09:52,169 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-13 22:09:52,169 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-13 22:09:52,169 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-13 22:09:52,169 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-13 22:09:52,170 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-13 22:09:52,170 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-13 22:09:52,170 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-13 22:09:52,170 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-13 22:09:52,170 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-13 22:09:52,170 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-13 22:09:52,171 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-13 22:09:52,171 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-13 22:09:52,171 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-13 22:09:52,171 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-13 22:09:52,171 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-13 22:09:52,171 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-13 22:09:52,171 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-13 22:09:52,172 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-13 22:09:52,172 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-13 22:09:52,216 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:09:52,224 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481634588745, RpcServer on fd/192.168.1.70:60020, sessionid=0x158f84cf36c0004
2016-12-13 22:09:52,224 INFO  [SplitLogWorker-fd,60020,1481634588745] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481634588745 starting
2016-12-13 22:09:52,228 INFO  [SplitLogWorker-fd,60020,1481634588745] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x66a9a050 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:09:52,228 INFO  [SplitLogWorker-fd,60020,1481634588745] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x66a9a050, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:09:52,229 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-13 22:09:52,229 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481634588745
2016-12-13 22:09:52,229 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481634588745'
2016-12-13 22:09:52,229 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-13 22:09:52,230 INFO  [SplitLogWorker-fd,60020,1481634588745-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:09:52,231 INFO  [SplitLogWorker-fd,60020,1481634588745-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44710, server: fd/192.168.1.70:2181
2016-12-13 22:09:52,231 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-13 22:09:52,238 INFO  [SplitLogWorker-fd,60020,1481634588745-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c0007, negotiated timeout = 40000
2016-12-13 22:09:52,238 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-13 22:09:52,292 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-13 22:09:52,509 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-13 22:09:53,202 INFO  [PriorityRpcServer.handler=1,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-13 22:09:53,227 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c0004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:09:53,254 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c0004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:09:53,254 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481634588745
2016-12-13 22:09:53,255 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 22:09:53,300 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481634588745/fd%2C60020%2C1481634588745.1481634593262.meta
2016-12-13 22:09:53,331 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-13 22:09:53,382 INFO  [RS_OPEN_META-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:09:53,383 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-13 22:09:53,388 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-13 22:09:53,392 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-13 22:09:53,399 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-13 22:09:53,399 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-13 22:09:53,521 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:09:53,540 DEBUG [StoreOpener-1588230740-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info
2016-12-13 22:09:53,555 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-13 22:09:53,556 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-13 22:09:53,562 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-13 22:09:53,570 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2016-12-13 22:09:53,571 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c0004, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-13 22:09:53,575 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-13 22:09:53,576 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481634588745
2016-12-13 22:09:53,590 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-13 22:09:53,596 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c0004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:09:53,604 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c0004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:09:53,604 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481634588745
2016-12-13 22:09:53,604 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481634588745
2016-12-13 22:09:55,568 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:09:58,570 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:01,572 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:04,574 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:07,575 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:10,577 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:13,579 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:16,582 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:19,584 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:22,585 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:25,587 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:28,589 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:31,591 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:34,592 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:37,594 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:40,595 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:43,597 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:46,599 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:49,601 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:52,602 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:55,604 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:10:58,606 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:01,607 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:04,609 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:07,611 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:10,612 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:13,614 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:16,615 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:19,617 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:22,618 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:25,620 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:28,622 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:31,623 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:34,625 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:37,627 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:40,628 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:43,630 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:46,632 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:49,634 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:52,635 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:55,637 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:11:58,639 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:01,640 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:04,642 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:07,643 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:10,645 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:13,646 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:16,647 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:19,649 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:22,650 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:25,652 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:28,654 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:31,655 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:34,657 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:37,659 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:40,660 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:43,661 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:46,663 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:49,665 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:52,667 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:55,668 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:12:58,670 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:01,672 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:04,673 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:07,675 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:10,677 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:13,678 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:16,679 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:19,680 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:22,681 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:25,683 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:28,685 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:31,686 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:34,688 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:37,690 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:40,691 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:43,692 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:46,694 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:49,696 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:52,697 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:55,699 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:13:58,700 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:01,702 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:04,704 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:07,705 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:10,707 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:13,708 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:16,710 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:19,711 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:22,712 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:25,714 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:28,716 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:31,717 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:34,719 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:37,720 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:40,722 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:43,723 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:46,725 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:48,903 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2016-12-13 22:14:49,726 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:52,728 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:55,729 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:14:58,731 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:01,732 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:04,734 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:07,735 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:10,736 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:13,738 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:16,739 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:19,741 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:22,742 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:25,744 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:28,745 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:31,747 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:34,749 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:37,750 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:40,752 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:43,753 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:46,754 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:49,756 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:52,757 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:55,759 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:15:58,760 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:01,762 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:04,763 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:07,765 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:10,767 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:13,768 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:16,770 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:19,771 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:22,772 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:25,774 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:28,775 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:31,776 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:34,778 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:37,779 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:40,780 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:43,782 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:46,783 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:49,784 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:52,786 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:55,787 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:16:58,788 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:01,790 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:04,791 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:07,793 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:10,794 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:13,796 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:16,797 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:19,799 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:22,800 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:25,802 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:28,803 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:31,804 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:34,806 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:37,807 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:40,808 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:43,810 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:46,811 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:49,813 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:52,814 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:55,816 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:17:58,817 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:01,819 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:04,820 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:07,821 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:10,823 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:13,824 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:16,826 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:19,827 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:22,828 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:25,830 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:28,831 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:31,833 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:34,834 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:37,835 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:40,837 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:43,838 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:46,839 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:49,841 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:52,842 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:55,843 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:18:58,845 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:01,846 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:04,848 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:07,849 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:10,851 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:13,852 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:16,853 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:19,855 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:22,856 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:25,857 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:28,859 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:31,860 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:34,862 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:37,863 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:40,865 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:43,866 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:46,867 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:48,902 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
2016-12-13 22:19:49,869 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:52,870 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:55,871 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:19:58,873 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:01,876 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:04,877 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:07,878 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:10,880 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:13,881 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:16,883 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:19,884 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:22,886 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:25,887 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:28,889 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:31,890 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:34,892 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:37,894 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:40,895 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:43,896 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:46,897 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:49,899 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:52,900 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:55,902 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:20:58,903 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:01,904 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:04,906 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:07,907 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:10,909 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:13,910 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:16,911 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:19,912 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:22,914 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:25,915 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:28,917 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:31,918 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:34,919 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:37,921 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:40,922 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:43,924 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:46,925 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:49,926 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:52,928 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:55,929 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:21:58,931 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:01,932 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:04,934 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:07,935 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:10,936 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:13,937 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:16,939 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:19,940 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:22,941 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:25,942 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:28,944 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:31,945 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:34,946 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:37,948 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:40,949 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:43,950 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:46,951 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:49,953 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:52,954 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:55,955 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:22:58,957 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:01,958 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:04,959 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:07,961 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:10,962 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:13,963 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:16,964 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:19,965 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:22,967 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:25,968 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:28,969 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:31,970 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:34,971 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:37,973 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:40,974 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:43,976 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:46,977 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:49,978 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:52,979 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:55,981 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:23:58,982 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:01,984 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:04,985 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:07,986 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:10,987 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:13,989 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:16,990 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:19,991 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:22,992 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:25,994 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:28,995 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:31,997 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:34,998 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:38,000 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:41,001 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:44,002 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:47,003 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:48,902 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=89, evicted=0, evictedPerRun=0.0
2016-12-13 22:24:50,005 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:53,006 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:56,007 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:24:59,008 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:02,010 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:05,011 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:08,012 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:11,014 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:14,015 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:17,016 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:20,017 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:23,018 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:26,020 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:29,021 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:32,023 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:35,024 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:38,025 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:41,027 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:44,028 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:47,029 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:50,030 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:53,032 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:56,033 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:25:59,034 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:02,036 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:05,037 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:08,039 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:11,040 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:14,041 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:17,042 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:20,043 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:23,045 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:26,046 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:29,047 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:32,049 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:35,050 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:38,051 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:41,052 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:44,053 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:47,055 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:50,056 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:53,057 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:56,059 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:26:59,060 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:02,061 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:05,063 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:08,064 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:11,065 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:14,066 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:17,068 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:20,069 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:23,070 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:26,071 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:29,073 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:32,074 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:35,075 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:38,077 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:41,078 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:44,079 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:47,081 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:50,082 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:53,083 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:56,084 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:27:59,086 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:02,087 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:05,089 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:08,090 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:11,091 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:14,093 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:17,094 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:20,095 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:23,096 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:26,098 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:29,099 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:32,101 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:35,102 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:38,104 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:41,105 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:44,106 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:47,108 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:50,109 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:53,110 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:56,111 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:28:59,112 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:02,114 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:05,115 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:08,116 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:11,118 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:14,119 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:17,120 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:20,121 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:23,122 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:26,123 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:29,125 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:32,126 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:35,127 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:38,129 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:41,130 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:44,131 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:47,132 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:48,902 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=119, evicted=0, evictedPerRun=0.0
2016-12-13 22:29:50,133 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:53,135 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:56,136 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:29:59,137 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:02,139 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:05,140 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:08,141 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:11,143 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:14,144 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:17,145 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:20,146 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:23,148 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:26,149 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:29,150 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:32,152 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:35,153 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:38,154 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:41,156 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:44,157 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:47,158 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:50,160 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:53,161 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:56,162 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:30:59,163 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:02,165 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:05,166 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:08,167 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:11,168 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:14,170 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:17,171 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:20,172 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:23,173 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:26,175 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:29,176 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:32,178 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:35,179 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:38,180 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:41,182 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:44,183 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:47,184 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:50,185 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:53,187 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:56,188 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:31:59,190 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:02,191 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:05,192 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:08,194 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:11,195 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:14,196 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:17,197 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:20,199 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:23,200 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:26,201 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:29,203 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:32,204 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:35,206 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 22:32:35,611 INFO  [regionserver60020-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/fd,60020,1481634588745 znode expired, triggering replicatorRemoved event
2016-12-13 22:32:41,206 INFO  [regionserver60020] regionserver.HRegionServer: Closing user regions
2016-12-13 22:32:44,207 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 1588230740
2016-12-13 22:32:47,208 INFO  [regionserver60020] regionserver.HRegionServer: STOPPED: Stopped; only catalog regions remaining online
2016-12-13 22:32:47,208 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2016-12-13 22:32:47,209 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2016-12-13 22:32:47,210 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2016-12-13 22:32:47,210 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2016-12-13 22:32:47,210 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2016-12-13 22:32:47,218 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2016-12-13 22:32:47,218 INFO  [SplitLogWorker-fd,60020,1481634588745] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2016-12-13 22:32:47,218 INFO  [SplitLogWorker-fd,60020,1481634588745] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481634588745 exiting
2016-12-13 22:32:47,224 INFO  [regionserver60020] mortbay.log: Stopped HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 22:32:47,327 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2016-12-13 22:32:47,327 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2016-12-13 22:32:47,327 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 22:32:47,327 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 22:32:47,329 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2016-12-13 22:32:47,329 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2016-12-13 22:32:47,329 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2016-12-13 22:32:47,329 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481634588745
2016-12-13 22:32:47,329 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6de7cf3b
2016-12-13 22:32:47,330 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f84cf36c0005
2016-12-13 22:32:47,342 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f84cf36c0005 closed
2016-12-13 22:32:47,343 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 22:32:47,343 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2016-12-13 22:32:47,343 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2016-12-13 22:32:47,343 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2016-12-13 22:32:47,343 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2016-12-13 22:32:47,345 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 1 regions to close
2016-12-13 22:32:47,345 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740}
2016-12-13 22:32:47,347 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-13 22:32:47,348 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-13 22:32:47,348 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-13 22:32:47,350 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2016-12-13 22:32:47,351 DEBUG [RS_CLOSE_META-fd:60020-0] coprocessor.CoprocessorHost: Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2016-12-13 22:32:47,353 INFO  [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2016-12-13 22:32:47,353 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Closed hbase:meta,,1.1588230740
2016-12-13 22:32:47,546 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481634588745; all regions closed.
2016-12-13 22:32:47,547 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 22:32:47,548 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier exiting
2016-12-13 22:32:47,548 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,548 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 exiting
2016-12-13 22:32:47,549 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,549 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 exiting
2016-12-13 22:32:47,550 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,550 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 exiting
2016-12-13 22:32:47,551 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,551 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 exiting
2016-12-13 22:32:47,551 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,551 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 exiting
2016-12-13 22:32:47,553 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 22:32:47,553 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter exiting
2016-12-13 22:32:47,553 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481634588745
2016-12-13 22:32:47,577 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 22:32:47,577 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2016-12-13 22:32:47,578 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,578 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2016-12-13 22:32:47,578 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,578 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2016-12-13 22:32:47,579 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,579 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2016-12-13 22:32:47,579 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,579 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2016-12-13 22:32:47,579 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 22:32:47,579 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2016-12-13 22:32:47,580 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 22:32:47,580 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2016-12-13 22:32:47,580 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481634588745
2016-12-13 22:32:47,631 DEBUG [regionserver60020] wal.FSHLog: Moved 2 WAL file(s) to /hbase/oldWALs
2016-12-13 22:32:47,639 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2016-12-13 22:32:47,639 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2016-12-13 22:32:52,098 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2016-12-13 22:32:52,098 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2016-12-13 22:32:52,101 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2016-12-13 22:32:52,103 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f84cf36c0006
2016-12-13 22:32:52,117 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f84cf36c0006 closed
2016-12-13 22:32:52,117 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 22:32:52,125 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/rs/fd,60020,1481634588745 already deleted, retry=false
2016-12-13 22:32:52,126 WARN  [regionserver60020] regionserver.HRegionServer: Failed deleting my ephemeral node
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /hbase/rs/fd,60020,1481634588745
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.delete(RecoverableZooKeeper.java:179)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1289)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1278)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.deleteMyEphemeralNode(HRegionServer.java:1340)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1054)
	at java.lang.Thread.run(Thread.java:745)
2016-12-13 22:32:52,134 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f84cf36c0004 closed
2016-12-13 22:32:52,134 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481634588745; zookeeper connection closed.
2016-12-13 22:32:52,134 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2016-12-13 22:32:52,134 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 22:32:52,138 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@1d2bd371
2016-12-13 22:32:52,138 INFO  [Thread-10] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2016-12-13 22:32:52,140 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook finished.
2016年 12月 13日 火曜日 22:33:26 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-13 22:33:27,777 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-13 22:33:27,778 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-13 22:33:27,778 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-13 22:33:28,215 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-13 22:33:28,216 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-13 22:33:28,217 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=5
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-13 22:33:28,218 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-13 22:33:28,219 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-13 22:33:28,220 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-13 22:33:28,223 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-13 22:33:28,223 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-13 22:33:28,522 DEBUG [main] regionserver.HRegionServer: regionserver/fd/192.168.1.70:60020 HConnection server-to-server retries=350
2016-12-13 22:33:28,778 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-13 22:33:28,808 INFO  [main] ipc.RpcServer: regionserver/fd/192.168.1.70:60020: started 10 reader(s).
2016-12-13 22:33:28,941 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-13 22:33:29,069 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-13 22:33:29,069 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-13 22:33:29,237 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-13 22:33:29,252 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-13 22:33:29,305 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-13 22:33:29,380 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-13 22:33:29,386 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-13 22:33:29,387 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-13 22:33:29,410 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-13 22:33:29,410 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-13 22:33:29,931 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 22:33:29,948 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:33:29,958 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-13 22:33:29,959 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-13 22:33:29,959 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-13 22:33:29,959 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-13 22:33:29,959 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-13 22:33:29,959 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-13 22:33:29,961 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 22:33:29,961 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-13 22:33:29,961 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-13 22:33:29,961 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-13 22:33:29,962 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-13 22:33:29,962 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-13 22:33:29,962 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-13 22:33:29,962 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-13 22:33:29,962 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-13 22:33:29,963 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:33:29,987 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:33:29,988 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44852, server: fd/192.168.1.70:2181
2016-12-13 22:33:30,037 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c000e, negotiated timeout = 40000
2016-12-13 22:33:30,122 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x418349be connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:33:30,123 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x418349be, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:33:30,124 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:33:30,125 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44854, server: fd/192.168.1.70:2181
2016-12-13 22:33:30,142 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c000f, negotiated timeout = 40000
2016-12-13 22:33:30,939 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-13 22:33:30,959 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3981ddf4
2016-12-13 22:33:30,965 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 333a9cec-86d1-404b-95ef-44a29a5eab9a
2016-12-13 22:33:30,971 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-13 22:33:30,987 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-13 22:33:30,995 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-13 22:33:31,004 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-13 22:33:31,009 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-13 22:33:31,021 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481636003153 with port=60020, startcode=1481636009099
2016-12-13 22:33:31,459 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-13 22:33:31,460 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-13 22:33:31,460 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:33:31,460 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-13 22:33:31,460 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-13 22:33:31,515 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-13 22:33:31,526 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481636009099
2016-12-13 22:33:31,722 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-13 22:33:31,740 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 22:33:32,241 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636011872
2016-12-13 22:33:32,268 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-13 22:33:32,280 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 22:33:32,280 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 22:33:32,281 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 22:33:32,281 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 22:33:32,281 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-13 22:33:32,289 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481636009099] other RSs: [fd,60020,1481636009099]
2016-12-13 22:33:32,336 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:33:32,347 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x59cbbd73 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:33:32,347 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x59cbbd73, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:33:32,349 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:33:32,351 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44860, server: fd/192.168.1.70:2181
2016-12-13 22:33:32,358 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c0010, negotiated timeout = 40000
2016-12-13 22:33:32,368 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-13 22:33:32,368 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-13 22:33:32,369 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-13 22:33:32,369 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-13 22:33:32,370 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-13 22:33:32,370 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-13 22:33:32,370 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-13 22:33:32,371 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-13 22:33:32,371 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-13 22:33:32,371 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-13 22:33:32,371 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-13 22:33:32,372 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-13 22:33:32,372 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-13 22:33:32,372 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-13 22:33:32,372 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-13 22:33:32,372 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-13 22:33:32,372 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-13 22:33:32,372 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-13 22:33:32,373 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-13 22:33:32,373 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-13 22:33:32,373 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-13 22:33:32,373 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-13 22:33:32,374 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-13 22:33:32,374 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-13 22:33:32,374 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-13 22:33:32,374 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-13 22:33:32,374 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-13 22:33:32,374 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-13 22:33:32,375 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-13 22:33:32,375 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-13 22:33:32,375 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-13 22:33:32,375 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-13 22:33:32,375 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-13 22:33:32,375 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-13 22:33:32,376 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-13 22:33:32,376 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-13 22:33:32,376 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-13 22:33:32,376 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-13 22:33:32,376 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-13 22:33:32,376 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-13 22:33:32,376 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-13 22:33:32,377 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-13 22:33:32,377 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-13 22:33:32,377 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-13 22:33:32,377 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-13 22:33:32,421 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:33:32,429 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481636009099, RpcServer on fd/192.168.1.70:60020, sessionid=0x158f84cf36c000e
2016-12-13 22:33:32,429 INFO  [SplitLogWorker-fd,60020,1481636009099] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481636009099 starting
2016-12-13 22:33:32,434 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-13 22:33:32,434 INFO  [SplitLogWorker-fd,60020,1481636009099] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x42787eb8 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 22:33:32,434 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481636009099
2016-12-13 22:33:32,434 INFO  [SplitLogWorker-fd,60020,1481636009099] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x42787eb8, quorum=fd:2181, baseZNode=/hbase
2016-12-13 22:33:32,434 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481636009099'
2016-12-13 22:33:32,435 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-13 22:33:32,436 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 22:33:32,438 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-13 22:33:32,439 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44862, server: fd/192.168.1.70:2181
2016-12-13 22:33:32,440 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-13 22:33:32,451 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f84cf36c0011, negotiated timeout = 40000
2016-12-13 22:33:32,502 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-13 22:33:32,676 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-13 22:33:34,142 INFO  [PriorityRpcServer.handler=0,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-13 22:33:34,159 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:33:34,183 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:33:34,183 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481636009099
2016-12-13 22:33:34,185 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 22:33:34,237 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636014191.meta
2016-12-13 22:33:34,269 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-13 22:33:34,322 INFO  [RS_OPEN_META-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 22:33:34,322 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-13 22:33:34,327 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-13 22:33:34,331 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-13 22:33:34,338 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-13 22:33:34,338 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-13 22:33:34,440 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:33:34,459 DEBUG [StoreOpener-1588230740-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info
2016-12-13 22:33:34,472 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-13 22:33:34,472 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-13 22:33:34,479 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-13 22:33:34,487 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2016-12-13 22:33:34,487 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-13 22:33:34,490 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-13 22:33:34,492 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481636009099
2016-12-13 22:33:34,510 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-13 22:33:34,511 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:33:34,524 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:33:34,524 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481636009099
2016-12-13 22:33:34,525 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481636009099
2016-12-13 22:33:35,303 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 22:33:35,304 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 22:33:35,357 INFO  [PriorityRpcServer.handler=0,queue=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.
2016-12-13 22:33:35,369 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636014191.meta with entries=1, filesize=268; new WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636015305.meta
2016-12-13 22:33:35,444 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioning f1e6e95b9011f061c670ff6bfc26bdeb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:33:35,467 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioned node f1e6e95b9011f061c670ff6bfc26bdeb from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:33:35,468 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => f1e6e95b9011f061c670ff6bfc26bdeb, NAME => 'hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.', STARTKEY => '', ENDKEY => ''}
2016-12-13 22:33:35,469 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace f1e6e95b9011f061c670ff6bfc26bdeb
2016-12-13 22:33:35,470 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Instantiated hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.
2016-12-13 22:33:35,489 INFO  [StoreOpener-f1e6e95b9011f061c670ff6bfc26bdeb-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:33:35,493 DEBUG [StoreOpener-f1e6e95b9011f061c670ff6bfc26bdeb-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/namespace/f1e6e95b9011f061c670ff6bfc26bdeb/info
2016-12-13 22:33:35,498 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/namespace/f1e6e95b9011f061c670ff6bfc26bdeb
2016-12-13 22:33:35,503 INFO  [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Onlined f1e6e95b9011f061c670ff6bfc26bdeb; next sequenceid=1
2016-12-13 22:33:35,503 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node f1e6e95b9011f061c670ff6bfc26bdeb
2016-12-13 22:33:35,508 INFO  [PostOpenDeployTasks:f1e6e95b9011f061c670ff6bfc26bdeb] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.
2016-12-13 22:33:35,588 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 22:33:35,588 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 22:33:35,596 INFO  [PostOpenDeployTasks:f1e6e95b9011f061c670ff6bfc26bdeb] catalog.MetaEditor: Updated row hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb. with server=fd,60020,1481636009099
2016-12-13 22:33:35,596 INFO  [PostOpenDeployTasks:f1e6e95b9011f061c670ff6bfc26bdeb] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.
2016-12-13 22:33:35,597 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioning f1e6e95b9011f061c670ff6bfc26bdeb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:33:35,608 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioned node f1e6e95b9011f061c670ff6bfc26bdeb from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:33:35,608 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Transitioned f1e6e95b9011f061c670ff6bfc26bdeb to OPENED in zk on fd,60020,1481636009099
2016-12-13 22:33:35,609 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Opened hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb. on fd,60020,1481636009099
2016-12-13 22:33:35,640 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636015305.meta with entries=1, filesize=464; new WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636015589.meta
2016-12-13 22:33:35,849 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 22:33:35,849 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 22:33:35,908 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636011872 with entries=2, filesize=303; new WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636015851
2016-12-13 22:38:29,246 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2016-12-13 22:43:29,246 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
2016-12-13 22:44:57,934 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 22:44:57,934 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 22:44:57,960 INFO  [PriorityRpcServer.handler=5,queue=0,port=60020] regionserver.HRegionServer: Open crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 22:44:57,979 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioning 48243f0e5cf96c84390098ace7129fdd from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:44:58,003 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636015589.meta with entries=1, filesize=276; new WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636697934.meta
2016-12-13 22:44:58,011 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioned node 48243f0e5cf96c84390098ace7129fdd from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 22:44:58,012 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Opening region: {ENCODED => 48243f0e5cf96c84390098ace7129fdd, NAME => 'crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.', STARTKEY => '', ENDKEY => ''}
2016-12-13 22:44:58,012 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table crawlId_webpage 48243f0e5cf96c84390098ace7129fdd
2016-12-13 22:44:58,013 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Instantiated crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 22:44:58,035 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,037 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/f
2016-12-13 22:44:58,050 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,052 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/h
2016-12-13 22:44:58,058 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,063 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/il
2016-12-13 22:44:58,077 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,080 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/mk
2016-12-13 22:44:58,092 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,094 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/mtdt
2016-12-13 22:44:58,100 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,102 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/ol
2016-12-13 22:44:58,108 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,110 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/p
2016-12-13 22:44:58,117 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,119 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/s
2016-12-13 22:44:58,125 INFO  [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 22:44:58,127 DEBUG [StoreOpener-48243f0e5cf96c84390098ace7129fdd-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd/stm
2016-12-13 22:44:58,129 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/48243f0e5cf96c84390098ace7129fdd
2016-12-13 22:44:58,132 INFO  [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Onlined 48243f0e5cf96c84390098ace7129fdd; next sequenceid=1
2016-12-13 22:44:58,132 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 48243f0e5cf96c84390098ace7129fdd
2016-12-13 22:44:58,134 INFO  [PostOpenDeployTasks:48243f0e5cf96c84390098ace7129fdd] regionserver.HRegionServer: Post open deploy tasks for region=crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 22:44:58,143 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 22:44:58,143 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 22:44:58,144 INFO  [PostOpenDeployTasks:48243f0e5cf96c84390098ace7129fdd] catalog.MetaEditor: Updated row crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd. with server=fd,60020,1481636009099
2016-12-13 22:44:58,145 INFO  [PostOpenDeployTasks:48243f0e5cf96c84390098ace7129fdd] regionserver.HRegionServer: Finished post open deploy task for crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 22:44:58,146 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioning 48243f0e5cf96c84390098ace7129fdd from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:44:58,153 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f84cf36c000e, quorum=fd:2181, baseZNode=/hbase Transitioned node 48243f0e5cf96c84390098ace7129fdd from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 22:44:58,153 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Transitioned 48243f0e5cf96c84390098ace7129fdd to OPENED in zk on fd,60020,1481636009099
2016-12-13 22:44:58,153 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Opened crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd. on fd,60020,1481636009099
2016-12-13 22:44:58,194 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636697934.meta with entries=1, filesize=464; new WAL /hbase/WALs/fd,60020,1481636009099/fd%2C60020%2C1481636009099.1481636698144.meta
2016-12-13 22:48:29,246 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=89, evicted=0, evictedPerRun=0.0
2016-12-13 22:53:29,246 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=119, evicted=0, evictedPerRun=0.0
2016-12-13 22:58:29,246 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=149, evicted=0, evictedPerRun=0.0
2016-12-13 23:00:05,501 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@292c3bc5
2016-12-13 23:00:05,501 INFO  [Thread-10] regionserver.HRegionServer: STOPPED: Shutdown hook
2016-12-13 23:00:05,502 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2016-12-13 23:00:05,502 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2016-12-13 23:00:05,503 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2016-12-13 23:00:05,503 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2016-12-13 23:00:05,507 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2016-12-13 23:00:05,510 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2016-12-13 23:00:05,510 INFO  [SplitLogWorker-fd,60020,1481636009099] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2016-12-13 23:00:05,510 INFO  [SplitLogWorker-fd,60020,1481636009099] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481636009099 exiting
2016-12-13 23:00:05,523 INFO  [regionserver60020] mortbay.log: Stopped HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 23:00:05,624 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2016-12-13 23:00:05,625 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 23:00:05,625 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 23:00:05,624 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2016-12-13 23:00:05,625 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2016-12-13 23:00:05,625 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2016-12-13 23:00:05,625 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2016-12-13 23:00:05,628 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481636009099
2016-12-13 23:00:05,629 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@3981ddf4
2016-12-13 23:00:05,629 DEBUG [RS_CLOSE_REGION-fd:60020-1] handler.CloseRegionHandler: Processing close of hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.
2016-12-13 23:00:05,630 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f84cf36c000f
2016-12-13 23:00:05,630 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Processing close of crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 23:00:05,632 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closing crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.: disabling compactions & flushes
2016-12-13 23:00:05,632 DEBUG [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Updates disabled for region crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 23:00:05,633 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Closing hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.: disabling compactions & flushes
2016-12-13 23:00:05,633 DEBUG [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Updates disabled for region hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.
2016-12-13 23:00:05,634 INFO  [RS_CLOSE_REGION-fd:60020-1] regionserver.HRegion: Started memstore flush for hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb., current region memstore size 344
2016-12-13 23:00:05,634 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed f
2016-12-13 23:00:05,634 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed h
2016-12-13 23:00:05,635 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed il
2016-12-13 23:00:05,635 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed mk
2016-12-13 23:00:05,635 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed mtdt
2016-12-13 23:00:05,635 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed ol
2016-12-13 23:00:05,635 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed p
2016-12-13 23:00:05,635 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed s
2016-12-13 23:00:05,635 INFO  [StoreCloserThread-crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.-1] regionserver.HStore: Closed stm
2016-12-13 23:00:05,640 INFO  [RS_CLOSE_REGION-fd:60020-0] regionserver.HRegion: Closed crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 23:00:05,640 DEBUG [RS_CLOSE_REGION-fd:60020-0] handler.CloseRegionHandler: Closed crawlId_webpage,,1481636697740.48243f0e5cf96c84390098ace7129fdd.
2016-12-13 23:00:05,832 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f84cf36c0010, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:00:05,832 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f84cf36c0011, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:00:05,832 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f84cf36c000e, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:00:05,838 WARN  [ResponseProcessor for block BP-1748626615-192.168.1.70-1481633531634:blk_1073741838_1014] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-1748626615-192.168.1.70-1481633531634:blk_1073741838_1014
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-13 23:00:05,838 WARN  [ResponseProcessor for block BP-1748626615-192.168.1.70-1481633531634:blk_1073741844_1020] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-1748626615-192.168.1.70-1481633531634:blk_1073741844_1020
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-13 23:00:05,844 INFO  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020. Trying to fail over immediately.
java.io.IOException: Failed on local exception: java.io.IOException: Connection reset by peer; Host Details : local host is: "fd/192.168.1.70"; destination host is: "fd":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:764)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:512)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1055)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:950)
2016-12-13 23:00:05,847 INFO  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 1 fail over attempts. Trying to fail over after sleeping for 1112ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:05,933 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f84cf36c000f closed
2016-12-13 23:00:05,934 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2016-12-13 23:00:05,934 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2016-12-13 23:00:05,934 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2016-12-13 23:00:05,934 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2016-12-13 23:00:05,934 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 23:00:05,935 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 2 regions to close
2016-12-13 23:00:05,935 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740, f1e6e95b9011f061c670ff6bfc26bdeb=hbase:namespace,,1481636014732.f1e6e95b9011f061c670ff6bfc26bdeb.}
2016-12-13 23:00:05,936 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-13 23:00:05,937 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-13 23:00:05,937 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-13 23:00:05,937 INFO  [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Started memstore flush for hbase:meta,,1.1588230740, current region memstore size 1.9 K
2016-12-13 23:00:05,940 INFO  [RS_CLOSE_META-fd:60020-0] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020. Trying to fail over immediately.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:05,941 INFO  [RS_CLOSE_META-fd:60020-0] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 1 fail over attempts. Trying to fail over after sleeping for 1252ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:06,961 WARN  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: A failover has occurred since the start of this method invocation attempt.
2016-12-13 23:00:06,962 INFO  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 2 fail over attempts. Trying to fail over after sleeping for 1338ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:07,196 INFO  [RS_CLOSE_META-fd:60020-0] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 2 fail over attempts. Trying to fail over after sleeping for 2188ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:07,450 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:07,451 WARN  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:07,526 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:07,526 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0010 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:07,776 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:07,777 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c000e for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:08,301 WARN  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: A failover has occurred since the start of this method invocation attempt.
2016-12-13 23:00:08,303 INFO  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 3 fail over attempts. Trying to fail over after sleeping for 3129ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:08,689 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:08,697 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0010 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:09,259 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:09,259 WARN  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:09,386 INFO  [RS_CLOSE_META-fd:60020-0] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 3 fail over attempts. Trying to fail over after sleeping for 3363ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:09,798 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:09,798 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c000e for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:09,800 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:09,800 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0010 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:10,416 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:10,416 WARN  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:11,433 WARN  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: A failover has occurred since the start of this method invocation attempt.
2016-12-13 23:00:11,435 INFO  [RS_CLOSE_REGION-fd:60020-1] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 4 fail over attempts. Trying to fail over after sleeping for 9908ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:11,598 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:11,598 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c000e for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:11,621 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:11,621 WARN  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:11,861 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:11,862 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0010 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:12,315 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2016-12-13 23:00:12,316 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2016-12-13 23:00:12,316 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2016-12-13 23:00:12,751 INFO  [RS_CLOSE_META-fd:60020-0] retry.RetryInvocationHandler: Exception while invoking getFileInfo of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 4 fail over attempts. Trying to fail over after sleeping for 8368ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:744)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1912)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1089)
	at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1085)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:398)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at org.apache.hadoop.hbase.regionserver.StoreFile$WriterBuilder.build(StoreFile.java:603)
	at org.apache.hadoop.hbase.regionserver.HStore.createWriterInTmp(HStore.java:916)
	at org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:64)
	at org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:829)
	at org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1989)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1779)
	at org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:1662)
	at org.apache.hadoop.hbase.regionserver.HRegion.doClose(HRegion.java:1155)
	at org.apache.hadoop.hbase.regionserver.HRegion.close(HRegion.java:1087)
	at org.apache.hadoop.hbase.regionserver.handler.CloseRegionHandler.process(CloseRegionHandler.java:147)
	at org.apache.hadoop.hbase.executor.EventHandler.run(EventHandler.java:128)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 36 more
2016-12-13 23:00:12,761 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:12,761 WARN  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:12,931 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:12,932 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c000e for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:13,640 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:13,640 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0010 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:14,008 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:14,009 WARN  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:14,793 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:14,793 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0010 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:15,007 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:15,008 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c000e for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:00:15,687 INFO  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:00:15,687 WARN  [SplitLogWorker-fd,60020,1481636009099-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f84cf36c0011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016年 12月 13日 火曜日 23:07:55 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-13 23:07:56,920 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-13 23:07:56,921 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-13 23:07:56,921 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-13 23:07:57,435 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-13 23:07:57,436 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-13 23:07:57,437 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=2
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-13 23:07:57,438 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-13 23:07:57,439 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-13 23:07:57,440 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-13 23:07:57,443 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-13 23:07:57,443 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-13 23:07:57,756 DEBUG [main] regionserver.HRegionServer: regionserver/fd/192.168.1.70:60020 HConnection server-to-server retries=350
2016-12-13 23:07:58,039 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-13 23:07:58,072 INFO  [main] ipc.RpcServer: regionserver/fd/192.168.1.70:60020: started 10 reader(s).
2016-12-13 23:07:58,208 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-13 23:07:58,336 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-13 23:07:58,336 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-13 23:07:58,512 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-13 23:07:58,528 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-13 23:07:58,581 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-13 23:07:58,656 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-13 23:07:58,664 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-13 23:07:58,665 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-13 23:07:58,693 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-13 23:07:58,693 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-13 23:07:59,181 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 23:07:59,199 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:07:59,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-13 23:07:59,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-13 23:07:59,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-13 23:07:59,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-13 23:07:59,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-13 23:07:59,209 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-13 23:07:59,211 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-13 23:07:59,213 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:07:59,236 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:07:59,241 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:40916, server: fd/192.168.1.70:2181
2016-12-13 23:07:59,269 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f8827b600004, negotiated timeout = 40000
2016-12-13 23:07:59,352 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x4356ba05 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:07:59,352 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x4356ba05, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:07:59,354 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:07:59,354 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:40918, server: fd/192.168.1.70:2181
2016-12-13 23:07:59,367 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f8827b600005, negotiated timeout = 40000
2016-12-13 23:08:00,205 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-13 23:08:00,224 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@558eafed
2016-12-13 23:08:00,229 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : 87bdb030-c5e4-4dd3-bbd3-4ad676579899
2016-12-13 23:08:00,235 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-13 23:08:00,255 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-13 23:08:00,263 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-13 23:08:00,343 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-13 23:08:00,349 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-13 23:08:00,363 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481638072769 with port=60020, startcode=1481638078365
2016-12-13 23:08:00,781 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-13 23:08:00,782 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-13 23:08:00,782 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:08:00,782 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-13 23:08:00,782 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-13 23:08:00,821 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-13 23:08:00,833 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481638078365
2016-12-13 23:08:01,035 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-13 23:08:01,052 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 23:08:01,662 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481638078365/fd%2C60020%2C1481638078365.1481638081168
2016-12-13 23:08:01,689 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-13 23:08:01,700 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 23:08:01,700 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 23:08:01,701 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 23:08:01,701 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 23:08:01,701 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-13 23:08:01,710 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481638078365, fd,60020,1481636009099] other RSs: [fd,60020,1481638078365, fd,60020,1481636009099]
2016-12-13 23:08:01,761 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:08:01,770 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2107eb98 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:08:01,770 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x2107eb98, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:08:01,772 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:08:01,774 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:40926, server: fd/192.168.1.70:2181
2016-12-13 23:08:01,783 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f8827b600006, negotiated timeout = 40000
2016-12-13 23:08:01,793 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-13 23:08:01,793 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-13 23:08:01,794 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-13 23:08:01,795 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-13 23:08:01,795 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-13 23:08:01,795 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-13 23:08:01,796 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-13 23:08:01,796 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-13 23:08:01,796 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-13 23:08:01,796 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-13 23:08:01,797 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-13 23:08:01,797 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-13 23:08:01,797 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-13 23:08:01,797 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-13 23:08:01,797 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-13 23:08:01,798 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-13 23:08:01,798 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-13 23:08:01,798 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-13 23:08:01,798 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-13 23:08:01,798 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-13 23:08:01,798 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-13 23:08:01,799 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-13 23:08:01,799 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-13 23:08:01,799 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-13 23:08:01,799 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-13 23:08:01,799 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-13 23:08:01,799 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-13 23:08:01,800 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-13 23:08:01,800 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-13 23:08:01,800 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-13 23:08:01,800 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-13 23:08:01,800 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-13 23:08:01,800 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-13 23:08:01,800 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-13 23:08:01,801 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-13 23:08:01,801 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-13 23:08:01,801 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-13 23:08:01,801 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-13 23:08:01,801 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-13 23:08:01,801 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-13 23:08:01,802 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-13 23:08:01,802 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-13 23:08:01,802 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-13 23:08:01,802 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-13 23:08:01,802 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-13 23:08:01,845 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:08:01,855 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481638078365, RpcServer on fd/192.168.1.70:60020, sessionid=0x158f8827b600004
2016-12-13 23:08:01,855 INFO  [SplitLogWorker-fd,60020,1481638078365] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481638078365 starting
2016-12-13 23:08:01,859 INFO  [SplitLogWorker-fd,60020,1481638078365] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x57bd55ff connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:08:01,859 INFO  [SplitLogWorker-fd,60020,1481638078365] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x57bd55ff, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:08:01,860 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-13 23:08:01,860 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481638078365
2016-12-13 23:08:01,860 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481638078365'
2016-12-13 23:08:01,860 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-13 23:08:01,863 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-13 23:08:01,863 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:08:01,865 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-13 23:08:01,865 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:40928, server: fd/192.168.1.70:2181
2016-12-13 23:08:01,875 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f8827b600007, negotiated timeout = 40000
2016-12-13 23:08:01,937 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-13 23:08:02,124 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-13 23:08:02,818 INFO  [PriorityRpcServer.handler=1,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-13 23:08:02,836 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f8827b600004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:08:02,858 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f8827b600004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:08:02,858 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481638078365
2016-12-13 23:08:02,860 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 23:08:02,900 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481638078365/fd%2C60020%2C1481638078365.1481638082865.meta
2016-12-13 23:08:02,930 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-13 23:08:02,981 INFO  [RS_OPEN_META-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:08:02,981 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-13 23:08:02,986 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-13 23:08:02,990 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-13 23:08:02,997 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-13 23:08:02,997 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-13 23:08:03,097 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:08:03,114 DEBUG [StoreOpener-1588230740-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info
2016-12-13 23:08:03,127 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-13 23:08:03,127 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-13 23:08:03,134 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-13 23:08:03,148 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2016-12-13 23:08:03,148 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f8827b600004, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-13 23:08:03,152 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-13 23:08:03,153 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481638078365
2016-12-13 23:08:03,168 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-13 23:08:03,178 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f8827b600004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:08:03,191 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f8827b600004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:08:03,191 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481638078365
2016-12-13 23:08:03,191 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481638078365
2016-12-13 23:08:05,166 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:08,168 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:11,170 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:12,028 INFO  [regionserver60020-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/fd,60020,1481636009099 znode expired, triggering replicatorRemoved event
2016-12-13 23:08:14,172 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:15,576 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Atomically moving fd,60020,1481636009099's hlogs to my queue
2016-12-13 23:08:15,578 DEBUG [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl:  The multi list size is: 1
2016-12-13 23:08:15,608 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Atomically moved the dead regionserver logs. 
2016-12-13 23:08:17,174 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:20,175 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:23,177 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:26,179 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:29,180 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:32,182 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:35,183 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:38,185 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:41,186 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:44,188 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:47,189 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:50,191 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:53,192 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:56,194 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:08:59,196 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:02,197 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:05,199 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:08,200 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:11,202 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:14,204 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:17,205 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:20,207 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:23,208 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:26,210 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:29,211 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:32,213 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:35,215 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:38,216 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:41,218 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:44,220 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:47,221 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:50,223 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:53,224 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:56,226 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:09:59,228 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:02,229 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:05,231 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:08,232 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:11,234 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:14,235 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:17,237 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:20,238 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:23,240 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:26,241 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:29,243 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:32,244 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:35,246 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:38,248 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:41,249 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:44,251 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:47,252 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:50,254 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:53,256 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:56,257 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:10:59,259 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:02,260 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:05,261 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:08,263 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:11,264 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:14,266 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:17,267 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:20,269 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:23,270 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:26,272 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:29,274 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:32,275 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:35,277 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:38,278 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:41,280 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:44,281 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:47,283 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:50,284 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:53,286 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:56,287 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:11:59,289 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:02,290 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:05,291 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:08,293 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:11,294 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:14,296 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:17,297 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:20,298 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:23,300 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:26,301 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:29,302 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:32,303 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:35,305 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:38,306 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:41,307 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:44,309 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:47,310 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:50,311 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:53,312 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:56,314 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:12:58,523 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2016-12-13 23:12:59,315 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:02,317 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:05,318 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:08,320 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:11,321 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:14,323 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:17,325 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:20,326 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:23,327 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:26,329 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:29,330 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:32,332 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:35,333 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:38,335 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:41,336 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:44,338 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:47,339 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:50,340 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:53,342 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:56,343 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:13:59,345 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:02,346 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:05,347 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:08,350 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:11,351 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:14,353 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:17,354 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:20,356 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:23,357 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:26,358 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:29,360 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:32,361 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:35,363 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:38,364 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:41,365 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:44,367 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:47,368 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:50,369 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:53,371 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:56,372 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:14:59,373 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:02,375 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:05,376 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:08,378 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:11,379 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:14,381 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:17,382 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:20,384 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:23,385 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:26,387 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:29,388 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:32,389 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:35,391 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:38,392 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:41,393 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:44,395 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:47,396 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:50,398 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:53,399 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:56,401 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:15:59,402 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:02,403 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:05,405 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:08,407 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:11,408 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:14,410 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:17,411 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:20,413 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:23,414 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:26,415 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:29,417 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:32,418 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:35,419 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:38,421 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:41,422 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:44,424 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:47,425 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:50,426 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:53,427 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:56,429 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:16:59,430 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:02,432 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:05,433 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:08,434 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:11,436 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:14,438 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:17,439 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:20,441 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:17:22,919 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@6f2cfcc2
2016-12-13 23:17:22,919 INFO  [Thread-10] regionserver.HRegionServer: STOPPED: Shutdown hook
2016-12-13 23:17:22,919 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2016-12-13 23:17:22,919 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2016-12-13 23:17:22,930 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2016-12-13 23:17:22,930 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2016-12-13 23:17:22,920 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2016-12-13 23:17:22,931 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2016-12-13 23:17:22,931 INFO  [SplitLogWorker-fd,60020,1481638078365] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2016-12-13 23:17:22,931 INFO  [SplitLogWorker-fd,60020,1481638078365] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481638078365 exiting
2016-12-13 23:17:22,942 INFO  [regionserver60020] mortbay.log: Stopped HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 23:17:23,045 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2016-12-13 23:17:23,045 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 23:17:23,045 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2016-12-13 23:17:23,046 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2016-12-13 23:17:23,046 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2016-12-13 23:17:23,046 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2016-12-13 23:17:23,046 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 23:17:23,047 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481638078365
2016-12-13 23:17:23,047 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@558eafed
2016-12-13 23:17:23,047 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f8827b600005
2016-12-13 23:17:23,246 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f8827b600004, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:17:23,246 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f8827b600006, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:17:23,246 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f8827b600007, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:17:23,249 WARN  [ResponseProcessor for block BP-381957965-192.168.1.70-1481637958421:blk_1073741830_1006] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-381957965-192.168.1.70-1481637958421:blk_1073741830_1006
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-13 23:17:23,249 WARN  [ResponseProcessor for block BP-381957965-192.168.1.70-1481637958421:blk_1073741831_1007] hdfs.DFSClient: DFSOutputStream ResponseProcessor exception  for block BP-381957965-192.168.1.70-1481637958421:blk_1073741831_1007
java.io.EOFException: Premature EOF: no length prefix available
	at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2114)
	at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:176)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer$ResponseProcessor.run(DFSOutputStream.java:810)
2016-12-13 23:17:23,347 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f8827b600005 closed
2016-12-13 23:17:23,347 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2016-12-13 23:17:23,347 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2016-12-13 23:17:23,347 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2016-12-13 23:17:23,347 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2016-12-13 23:17:23,348 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 23:17:23,349 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 1 regions to close
2016-12-13 23:17:23,350 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740}
2016-12-13 23:17:23,350 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-13 23:17:23,351 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-13 23:17:23,351 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-13 23:17:23,353 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2016-12-13 23:17:23,354 DEBUG [RS_CLOSE_META-fd:60020-0] coprocessor.CoprocessorHost: Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2016-12-13 23:17:23,357 INFO  [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2016-12-13 23:17:23,357 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Closed hbase:meta,,1.1588230740
2016-12-13 23:17:23,550 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481638078365; all regions closed.
2016-12-13 23:17:23,551 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 23:17:23,551 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier exiting
2016-12-13 23:17:23,551 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,551 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 exiting
2016-12-13 23:17:23,551 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,551 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 exiting
2016-12-13 23:17:23,552 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,552 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 exiting
2016-12-13 23:17:23,552 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,552 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 exiting
2016-12-13 23:17:23,552 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,552 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 exiting
2016-12-13 23:17:23,554 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 23:17:23,554 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter exiting
2016-12-13 23:17:23,554 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481638078365
2016-12-13 23:17:23,555 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 192.168.1.70:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 23:17:23,557 ERROR [regionserver60020] regionserver.HRegionServer: Metalog close and delete failed
java.io.IOException: All datanodes 192.168.1.70:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 23:17:23,557 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 23:17:23,557 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2016-12-13 23:17:23,558 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,558 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2016-12-13 23:17:23,558 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,558 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2016-12-13 23:17:23,558 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,558 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2016-12-13 23:17:23,558 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,558 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2016-12-13 23:17:23,560 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:17:23,560 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2016-12-13 23:17:23,560 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 23:17:23,560 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2016-12-13 23:17:23,560 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481638078365
2016-12-13 23:17:23,560 ERROR [regionserver60020] wal.ProtobufLogWriter: Got IOException while writing trailer
java.io.IOException: All datanodes 192.168.1.70:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 23:17:23,561 ERROR [regionserver60020] regionserver.HRegionServer: Close and delete failed
java.io.IOException: All datanodes 192.168.1.70:50010 are bad. Aborting...
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1147)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:945)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:496)
2016-12-13 23:17:23,562 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2016-12-13 23:17:23,562 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2016-12-13 23:17:24,636 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:24,637 WARN  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600007 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:24,651 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:24,652 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600006 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:25,321 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:25,321 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600004 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:26,083 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:26,084 WARN  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600007 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:26,241 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:26,241 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600006 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:27,308 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:27,309 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600004 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:28,110 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:28,110 WARN  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600007 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:28,189 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:28,190 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600006 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:28,805 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:28,806 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600004 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:29,507 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:29,507 WARN  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600007 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:29,728 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:29,729 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600006 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:30,493 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:30,493 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600004 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:30,940 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:30,940 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600006 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:31,437 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:31,438 WARN  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600007 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:31,558 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020. Trying to fail over immediately.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-13 23:17:31,560 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 1 fail over attempts. Trying to fail over after sleeping for 825ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-13 23:17:31,711 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2016-12-13 23:17:31,716 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2016-12-13 23:17:31,717 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2016-12-13 23:17:31,931 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:31,932 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600004 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:32,033 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=fd:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/replication/rs/fd,60020,1481638078365
2016-12-13 23:17:32,033 INFO  [regionserver60020] util.RetryCounter: Sleeping 1000ms before retry #0...
2016-12-13 23:17:32,123 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:32,124 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600006 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:17:32,387 INFO  [LeaseRenewer:hbase@my-cluster:8020] retry.RetryInvocationHandler: Exception while invoking renewLease of class ClientNamenodeProtocolTranslatorPB over fd/192.168.1.70:8020 after 2 fail over attempts. Trying to fail over after sleeping for 2340ms.
java.net.ConnectException: Call From fd/192.168.1.70 to fd:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:783)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:730)
	at org.apache.hadoop.ipc.Client.call(Client.java:1409)
	at org.apache.hadoop.ipc.Client.call(Client.java:1364)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy15.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:563)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:191)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor14.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy17.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:845)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:493)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:606)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:367)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1382)
	... 21 more
2016-12-13 23:17:33,039 INFO  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:17:33,040 WARN  [SplitLogWorker-fd,60020,1481638078365-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f8827b600007 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016年 12月 13日 火曜日 23:28:09 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-13 23:28:11,154 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-13 23:28:11,156 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-13 23:28:11,156 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-13 23:28:11,635 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-13 23:28:11,636 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-13 23:28:11,637 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-13 23:28:11,638 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=3
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-13 23:28:11,639 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-13 23:28:11,640 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-13 23:28:11,640 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-13 23:28:11,640 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-13 23:28:11,640 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-13 23:28:11,640 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-13 23:28:11,640 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-13 23:28:11,640 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-13 23:28:11,641 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-13 23:28:11,644 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-13 23:28:11,645 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-13 23:28:11,946 DEBUG [main] regionserver.HRegionServer: regionserver/fd/192.168.1.70:60020 HConnection server-to-server retries=350
2016-12-13 23:28:12,204 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-13 23:28:12,234 INFO  [main] ipc.RpcServer: regionserver/fd/192.168.1.70:60020: started 10 reader(s).
2016-12-13 23:28:12,369 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-13 23:28:12,512 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-13 23:28:12,512 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-13 23:28:12,685 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-13 23:28:12,700 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-13 23:28:12,750 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-13 23:28:12,824 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-13 23:28:12,830 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-13 23:28:12,830 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-13 23:28:12,853 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-13 23:28:12,853 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-13 23:28:13,360 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 23:28:13,377 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:28:13,387 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-13 23:28:13,387 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-13 23:28:13,387 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-13 23:28:13,387 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-13 23:28:13,387 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-13 23:28:13,387 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-13 23:28:13,390 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-13 23:28:13,392 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:28:13,414 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:28:13,415 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44980, server: fd/192.168.1.70:2181
2016-12-13 23:28:13,440 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a20004, negotiated timeout = 40000
2016-12-13 23:28:13,536 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2eaa0427 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:28:13,536 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x2eaa0427, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:28:13,540 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:28:13,540 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44982, server: fd/192.168.1.70:2181
2016-12-13 23:28:13,546 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a20005, negotiated timeout = 40000
2016-12-13 23:28:14,365 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-13 23:28:14,384 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@50cdd959
2016-12-13 23:28:14,390 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : c16dd1dd-daa1-4e1e-9df3-e60222b8db4b
2016-12-13 23:28:14,397 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-13 23:28:14,417 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-13 23:28:14,425 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-13 23:28:14,433 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-13 23:28:14,438 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-13 23:28:14,473 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481639287024 with port=60020, startcode=1481639292541
2016-12-13 23:28:15,104 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-13 23:28:15,104 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-13 23:28:15,104 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:28:15,104 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-13 23:28:15,104 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-13 23:28:15,146 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-13 23:28:15,164 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481639292541
2016-12-13 23:28:15,394 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-13 23:28:15,414 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 23:28:15,946 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481639292541/fd%2C60020%2C1481639292541.1481639295483
2016-12-13 23:28:15,976 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-13 23:28:15,989 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 23:28:15,990 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 23:28:15,990 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 23:28:15,990 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 23:28:15,990 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-13 23:28:15,999 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481639292541, fd,60020,1481638078365] other RSs: [fd,60020,1481639292541]
2016-12-13 23:28:16,056 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:28:16,067 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x13388e09 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:28:16,067 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x13388e09, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:28:16,069 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:28:16,070 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44988, server: fd/192.168.1.70:2181
2016-12-13 23:28:16,080 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a20006, negotiated timeout = 40000
2016-12-13 23:28:16,089 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-13 23:28:16,089 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-13 23:28:16,090 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-13 23:28:16,090 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-13 23:28:16,091 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-13 23:28:16,091 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-13 23:28:16,091 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-13 23:28:16,091 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-13 23:28:16,092 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-13 23:28:16,092 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-13 23:28:16,092 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-13 23:28:16,092 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-13 23:28:16,092 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-13 23:28:16,092 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-13 23:28:16,093 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-13 23:28:16,093 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-13 23:28:16,093 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-13 23:28:16,093 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-13 23:28:16,093 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-13 23:28:16,093 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-13 23:28:16,094 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-13 23:28:16,094 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-13 23:28:16,094 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-13 23:28:16,094 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-13 23:28:16,094 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-13 23:28:16,094 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-13 23:28:16,094 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-13 23:28:16,095 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-13 23:28:16,095 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-13 23:28:16,095 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-13 23:28:16,095 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-13 23:28:16,095 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-13 23:28:16,095 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-13 23:28:16,096 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-13 23:28:16,096 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-13 23:28:16,096 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-13 23:28:16,096 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-13 23:28:16,097 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-13 23:28:16,097 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-13 23:28:16,097 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-13 23:28:16,097 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-13 23:28:16,097 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-13 23:28:16,098 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-13 23:28:16,098 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-13 23:28:16,098 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-13 23:28:16,143 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:28:16,151 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481639292541, RpcServer on fd/192.168.1.70:60020, sessionid=0x158f89029a20004
2016-12-13 23:28:16,151 INFO  [SplitLogWorker-fd,60020,1481639292541] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481639292541 starting
2016-12-13 23:28:16,154 INFO  [SplitLogWorker-fd,60020,1481639292541] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x51073172 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:28:16,155 INFO  [SplitLogWorker-fd,60020,1481639292541] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x51073172, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:28:16,155 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-13 23:28:16,155 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481639292541
2016-12-13 23:28:16,155 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481639292541'
2016-12-13 23:28:16,156 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-13 23:28:16,157 INFO  [SplitLogWorker-fd,60020,1481639292541-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:28:16,158 INFO  [SplitLogWorker-fd,60020,1481639292541-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:44990, server: fd/192.168.1.70:2181
2016-12-13 23:28:16,159 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-13 23:28:16,171 INFO  [SplitLogWorker-fd,60020,1481639292541-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a20007, negotiated timeout = 40000
2016-12-13 23:28:16,172 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-13 23:28:16,236 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-13 23:28:16,420 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-13 23:28:17,004 INFO  [PriorityRpcServer.handler=1,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-13 23:28:17,023 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a20004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:28:17,054 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a20004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:28:17,054 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481639292541
2016-12-13 23:28:17,055 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 23:28:17,099 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481639292541/fd%2C60020%2C1481639292541.1481639297063.meta
2016-12-13 23:28:17,130 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-13 23:28:17,182 INFO  [RS_OPEN_META-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:28:17,182 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-13 23:28:17,188 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-13 23:28:17,192 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-13 23:28:17,198 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-13 23:28:17,199 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-13 23:28:17,301 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:28:17,317 DEBUG [StoreOpener-1588230740-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info
2016-12-13 23:28:17,329 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-13 23:28:17,330 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-13 23:28:17,336 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-13 23:28:17,343 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2016-12-13 23:28:17,344 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a20004, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-13 23:28:17,347 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-13 23:28:17,348 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481639292541
2016-12-13 23:28:17,364 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-13 23:28:17,365 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a20004, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:28:17,370 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a20004, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:28:17,370 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481639292541
2016-12-13 23:28:17,370 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481639292541
2016-12-13 23:28:18,625 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Atomically moving fd,60020,1481638078365's hlogs to my queue
2016-12-13 23:28:18,627 DEBUG [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl:  The multi list size is: 1
2016-12-13 23:28:18,647 INFO  [ReplicationExecutor-0] replication.ReplicationQueuesZKImpl: Atomically moved the dead regionserver logs. 
2016-12-13 23:28:19,465 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:22,466 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:25,468 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:28,470 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:31,472 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:34,475 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:37,477 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:40,478 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:43,480 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:46,482 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:49,484 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:52,485 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:55,487 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:28:58,488 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:01,490 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:04,492 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:07,493 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:10,495 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:13,497 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:16,498 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:19,500 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:22,502 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:25,503 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:28,505 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:31,507 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:34,509 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:37,510 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:40,512 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:43,514 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:46,515 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:49,517 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:52,518 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:55,520 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:29:58,522 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:01,523 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:04,525 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:07,527 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:10,528 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:13,530 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:16,532 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:19,533 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:22,535 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:25,536 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:28,538 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:31,539 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:34,541 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:37,542 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:40,544 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:43,545 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:46,547 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:49,548 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:52,550 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:55,551 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:30:58,553 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:01,555 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:04,556 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:07,558 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:10,559 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:13,561 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:16,562 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:19,564 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:22,566 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:25,567 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:28,569 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:31,571 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:34,572 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:37,574 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:40,575 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:43,577 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:46,578 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:49,580 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:52,581 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:55,583 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:31:58,585 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:01,586 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:04,588 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:07,589 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:10,591 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:13,593 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:16,594 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:19,596 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:22,597 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:25,599 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:28,601 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:31,602 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:34,604 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:37,605 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:40,607 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:43,608 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:46,609 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:49,611 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:52,612 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:55,614 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:32:58,615 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:01,617 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:04,618 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:07,620 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:10,622 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:12,695 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2016-12-13 23:33:13,623 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:16,624 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:19,626 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:22,627 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:25,629 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:28,630 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:31,632 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:34,633 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:37,635 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:40,636 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:43,638 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:46,640 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:49,641 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:52,643 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:55,644 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:33:58,646 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:01,647 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:04,648 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:07,650 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:10,651 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:13,653 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:16,654 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:19,656 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:22,657 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:25,659 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:28,660 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:31,662 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:34,664 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:37,665 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:40,667 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:43,668 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:46,669 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:49,670 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:52,672 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:55,673 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:34:58,675 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:01,676 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:04,677 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:07,679 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:10,680 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:13,681 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:16,683 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:19,684 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:22,685 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:25,687 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:28,688 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:31,690 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:34,691 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:37,692 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:40,694 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:43,695 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:46,697 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:49,698 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:52,699 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:55,701 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:35:58,702 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:01,704 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:04,705 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:07,707 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:10,708 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:13,710 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:16,711 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:19,712 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:22,713 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:25,715 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:28,716 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:31,718 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:34,719 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:37,721 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:40,722 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:43,723 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:46,724 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:49,726 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:52,727 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:55,729 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:36:58,731 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:01,732 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:04,734 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:07,735 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:10,736 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:13,737 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:16,739 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:19,740 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:22,742 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:25,743 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:28,744 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:31,746 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:34,747 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:37,748 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:40,749 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:43,751 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:46,752 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:49,753 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:52,755 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:55,756 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:37:58,758 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:01,759 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:04,761 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:07,762 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:10,764 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:12,695 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
2016-12-13 23:38:13,765 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:16,766 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:19,768 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:22,770 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:25,771 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:28,773 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:31,774 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:34,776 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:37,777 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:40,778 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:43,780 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:46,781 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:49,783 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:52,785 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:55,786 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:38:58,788 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:01,789 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:04,791 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:07,792 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:10,793 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:13,795 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:16,796 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:19,797 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:22,799 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:25,800 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:28,801 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:31,803 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:34,804 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:37,805 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:40,807 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:43,808 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:46,809 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:49,811 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:52,812 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:55,814 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:39:58,815 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:01,816 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:04,818 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:07,819 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:10,821 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:13,822 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:16,824 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:19,825 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:22,826 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:25,828 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:28,829 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:31,831 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:34,832 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:37,833 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:40,835 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:43,836 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:46,837 DEBUG [regionserver60020] regionserver.HRegionServer: No master found; retry
2016-12-13 23:40:46,906 INFO  [regionserver60020-EventThread] replication.ReplicationTrackerZKImpl: /hbase/rs/fd,60020,1481639292541 znode expired, triggering replicatorRemoved event
2016-12-13 23:40:52,838 INFO  [regionserver60020] regionserver.HRegionServer: Closing user regions
2016-12-13 23:40:55,839 DEBUG [regionserver60020] regionserver.HRegionServer: Waiting on 1588230740
2016-12-13 23:40:58,839 INFO  [regionserver60020] regionserver.HRegionServer: STOPPED: Stopped; only catalog regions remaining online
2016-12-13 23:40:58,839 INFO  [regionserver60020] ipc.RpcServer: Stopping server on 60020
2016-12-13 23:40:58,840 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: stopping
2016-12-13 23:40:58,840 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopped
2016-12-13 23:40:58,840 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: stopping
2016-12-13 23:40:58,840 INFO  [regionserver60020] regionserver.SplitLogWorker: Sending interrupt to stop the worker thread
2016-12-13 23:40:58,847 INFO  [regionserver60020] regionserver.HRegionServer: Stopping infoServer
2016-12-13 23:40:58,848 INFO  [SplitLogWorker-fd,60020,1481639292541] regionserver.SplitLogWorker: SplitLogWorker interrupted while waiting for task, exiting: java.lang.InterruptedException
2016-12-13 23:40:58,848 INFO  [SplitLogWorker-fd,60020,1481639292541] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481639292541 exiting
2016-12-13 23:40:58,865 INFO  [regionserver60020] mortbay.log: Stopped HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 23:40:58,966 INFO  [MemStoreFlusher.1] regionserver.MemStoreFlusher: MemStoreFlusher.1 exiting
2016-12-13 23:40:58,967 INFO  [regionserver60020] snapshot.RegionServerSnapshotManager: Stopping RegionServerSnapshotManager gracefully.
2016-12-13 23:40:58,967 INFO  [regionserver60020.compactionChecker] regionserver.HRegionServer$CompactionChecker: regionserver60020.compactionChecker exiting
2016-12-13 23:40:58,966 INFO  [MemStoreFlusher.0] regionserver.MemStoreFlusher: MemStoreFlusher.0 exiting
2016-12-13 23:40:58,968 INFO  [regionserver60020.logRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 23:40:58,968 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481639292541
2016-12-13 23:40:58,969 DEBUG [regionserver60020] catalog.CatalogTracker: Stopping catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@50cdd959
2016-12-13 23:40:58,968 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: LogRoller exiting.
2016-12-13 23:40:58,967 INFO  [regionserver60020.nonceCleaner] regionserver.ServerNonceManager$1: regionserver60020.nonceCleaner exiting
2016-12-13 23:40:58,969 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f89029a20005
2016-12-13 23:40:58,987 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f89029a20005 closed
2016-12-13 23:40:58,987 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 23:40:58,987 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Split Thread to finish...
2016-12-13 23:40:58,988 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Merge Thread to finish...
2016-12-13 23:40:58,988 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Large Compaction Thread to finish...
2016-12-13 23:40:58,988 INFO  [regionserver60020] regionserver.CompactSplitThread: Waiting for Small Compaction Thread to finish...
2016-12-13 23:40:58,990 INFO  [regionserver60020] regionserver.HRegionServer: Waiting on 1 regions to close
2016-12-13 23:40:58,990 DEBUG [regionserver60020] regionserver.HRegionServer: {1588230740=hbase:meta,,1.1588230740}
2016-12-13 23:40:58,991 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Processing close of hbase:meta,,1.1588230740
2016-12-13 23:40:58,992 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2016-12-13 23:40:58,992 DEBUG [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2016-12-13 23:40:58,994 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2016-12-13 23:40:58,994 DEBUG [RS_CLOSE_META-fd:60020-0] coprocessor.CoprocessorHost: Stop coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint
2016-12-13 23:40:58,996 INFO  [RS_CLOSE_META-fd:60020-0] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2016-12-13 23:40:58,996 DEBUG [RS_CLOSE_META-fd:60020-0] handler.CloseRegionHandler: Closed hbase:meta,,1.1588230740
2016-12-13 23:40:59,191 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481639292541; all regions closed.
2016-12-13 23:40:59,191 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 23:40:59,191 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncNotifier exiting
2016-12-13 23:40:59,192 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,192 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0 exiting
2016-12-13 23:40:59,193 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,193 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer1 exiting
2016-12-13 23:40:59,193 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,193 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer2 exiting
2016-12-13 23:40:59,194 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,194 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer3 exiting
2016-12-13 23:40:59,194 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,194 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer4 exiting
2016-12-13 23:40:59,194 DEBUG [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 23:40:59,194 INFO  [RS_OPEN_META-fd:60020-0-WAL.AsyncWriter] wal.FSHLog: RS_OPEN_META-fd:60020-0-WAL.AsyncWriter exiting
2016-12-13 23:40:59,194 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481639292541
2016-12-13 23:40:59,220 DEBUG [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier interrupted while waiting for  notification from AsyncSyncer thread
2016-12-13 23:40:59,220 INFO  [regionserver60020-WAL.AsyncNotifier] wal.FSHLog: regionserver60020-WAL.AsyncNotifier exiting
2016-12-13 23:40:59,221 DEBUG [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,221 INFO  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: regionserver60020-WAL.AsyncSyncer0 exiting
2016-12-13 23:40:59,221 DEBUG [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,221 INFO  [regionserver60020-WAL.AsyncSyncer1] wal.FSHLog: regionserver60020-WAL.AsyncSyncer1 exiting
2016-12-13 23:40:59,221 DEBUG [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,221 INFO  [regionserver60020-WAL.AsyncSyncer2] wal.FSHLog: regionserver60020-WAL.AsyncSyncer2 exiting
2016-12-13 23:40:59,222 DEBUG [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,222 INFO  [regionserver60020-WAL.AsyncSyncer3] wal.FSHLog: regionserver60020-WAL.AsyncSyncer3 exiting
2016-12-13 23:40:59,223 DEBUG [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 interrupted while waiting for notification from AsyncWriter thread
2016-12-13 23:40:59,223 INFO  [regionserver60020-WAL.AsyncSyncer4] wal.FSHLog: regionserver60020-WAL.AsyncSyncer4 exiting
2016-12-13 23:40:59,224 DEBUG [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter interrupted while waiting for newer writes added to local buffer
2016-12-13 23:40:59,224 INFO  [regionserver60020-WAL.AsyncWriter] wal.FSHLog: regionserver60020-WAL.AsyncWriter exiting
2016-12-13 23:40:59,224 DEBUG [regionserver60020] wal.FSHLog: Closing WAL writer in hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481639292541
2016-12-13 23:40:59,275 DEBUG [regionserver60020] wal.FSHLog: Moved 2 WAL file(s) to /hbase/oldWALs
2016-12-13 23:40:59,283 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closing leases
2016-12-13 23:40:59,283 INFO  [regionserver60020] regionserver.Leases: regionserver60020 closed leases
2016-12-13 23:41:06,009 INFO  [regionserver60020.periodicFlusher] regionserver.HRegionServer$PeriodicMemstoreFlusher: regionserver60020.periodicFlusher exiting
2016-12-13 23:41:06,010 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closing leases
2016-12-13 23:41:06,010 INFO  [regionserver60020.leaseChecker] regionserver.Leases: regionserver60020.leaseChecker closed leases
2016-12-13 23:41:06,011 INFO  [regionserver60020] client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x158f89029a20006
2016-12-13 23:41:06,028 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f89029a20006 closed
2016-12-13 23:41:06,029 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 23:41:06,037 WARN  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/rs/fd,60020,1481639292541 already deleted, retry=false
2016-12-13 23:41:06,038 WARN  [regionserver60020] regionserver.HRegionServer: Failed deleting my ephemeral node
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /hbase/rs/fd,60020,1481639292541
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.delete(ZooKeeper.java:873)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.delete(RecoverableZooKeeper.java:179)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1289)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.deleteNode(ZKUtil.java:1278)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.deleteMyEphemeralNode(HRegionServer.java:1340)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.run(HRegionServer.java:1054)
	at java.lang.Thread.run(Thread.java:745)
2016-12-13 23:41:06,045 INFO  [regionserver60020] zookeeper.ZooKeeper: Session: 0x158f89029a20004 closed
2016-12-13 23:41:06,045 INFO  [regionserver60020] regionserver.HRegionServer: stopping server fd,60020,1481639292541; zookeeper connection closed.
2016-12-13 23:41:06,045 INFO  [regionserver60020-EventThread] zookeeper.ClientCnxn: EventThread shut down
2016-12-13 23:41:06,045 INFO  [regionserver60020] regionserver.HRegionServer: regionserver60020 exiting
2016-12-13 23:41:06,048 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook starting; hbase.shutdown.hook=true; fsShutdownHook=org.apache.hadoop.fs.FileSystem$Cache$ClientFinalizer@3c4e6cb1
2016-12-13 23:41:06,048 INFO  [Thread-10] regionserver.ShutdownHook: Starting fs shutdown hook thread.
2016-12-13 23:41:06,049 INFO  [Thread-10] regionserver.ShutdownHook: Shutdown hook finished.
2016年 12月 13日 火曜日 23:42:13 JST Starting regionserver on fd
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64048
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64048
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-12-13 23:42:14,729 INFO  [main] util.VersionInfo: HBase 0.98.6-cdh5.3.10
2016-12-13 23:42:14,731 INFO  [main] util.VersionInfo: Subversion file:///data/jenkins/workspace/generic-package-ubuntu64-14-04/CDH5.3.10-Packaging-HBase-2016-04-12_18-26-48/hbase-0.98.6+cdh5.3.10+159-1.cdh5.3.10.p0.33~trusty -r Unknown
2016-12-13 23:42:14,731 INFO  [main] util.VersionInfo: Compiled by jenkins on Tue Apr 12 18:40:34 PDT 2016
2016-12-13 23:42:15,190 INFO  [main] util.ServerCommandLine: env:PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games
2016-12-13 23:42:15,190 INFO  [main] util.ServerCommandLine: env:LC_MEASUREMENT=ja_JP.UTF-8
2016-12-13 23:42:15,190 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF_DIR=/etc/hadoop/conf
2016-12-13 23:42:15,190 INFO  [main] util.ServerCommandLine: env:LC_TELEPHONE=ja_JP.UTF-8
2016-12-13 23:42:15,190 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-12-13 23:42:15,190 INFO  [main] util.ServerCommandLine: env:LC_TIME=ja_JP.UTF-8
2016-12-13 23:42:15,190 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xms3g -Xmx3g
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:MAIL=/var/mail/hbase
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=:/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME_WARN_SUPPRESS=true
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:LC_PAPER=ja_JP.UTF-8
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:JSVC_HOME=/usr/lib/bigtop-utils
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:PWD=/
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:HADOOP_PREFIX=/usr/lib/hadoop
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:LC_ADDRESS=ja_JP.UTF-8
2016-12-13 23:42:15,191 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:HADOOP_YARN_HOME=/usr/lib/hadoop-yarn
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-XX:+UseConcMarkSweepGC   -Xms3g -Xmx3g -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-regionserver-fd.log -Dhbase.home.dir=/usr/lib/hbase -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64 -Dhbase.security.logger=INFO,RFAS
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-regionserver.autorestart
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:SHLVL=4
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:LC_IDENTIFICATION=ja_JP.UTF-8
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-regionserver-fd.log
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:LC_MONETARY=ja_JP.UTF-8
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2016-12-13 23:42:15,192 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:XDG_SESSION_ID=5
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HADOOP_HDFS_HOME=/usr/lib/hadoop-hdfs
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HADOOP_COMMON_HOME=/usr/lib/hadoop
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:LC_NAME=ja_JP.UTF-8
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-regionserver.znode
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-regionserver-fd
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-12-13 23:42:15,193 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-12-13 23:42:15,194 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/*:/usr/lib/hadoop/.//*:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/*:/usr/lib/hadoop-hdfs/.//*:/usr/lib/hadoop-yarn/lib/*:/usr/lib/hadoop-yarn/.//*:/usr/lib/hadoop-mapreduce/lib/*:/usr/lib/hadoop-mapreduce/.//*
2016-12-13 23:42:15,194 INFO  [main] util.ServerCommandLine: env:LC_NUMERIC=ja_JP.UTF-8
2016-12-13 23:42:15,194 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-12-13 23:42:15,194 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_MODE=-nonblocking
2016-12-13 23:42:15,194 INFO  [main] util.ServerCommandLine: env:XDG_RUNTIME_DIR=/run/user/0
2016-12-13 23:42:15,194 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-12-13 23:42:15,194 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/lib/hbase
2016-12-13 23:42:15,195 INFO  [main] util.ServerCommandLine: env:HOME=/var/lib/hbase
2016-12-13 23:42:15,195 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-12-13 23:42:15,197 INFO  [main] util.ServerCommandLine: vmName=Java HotSpot(TM) 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=25.111-b14
2016-12-13 23:42:15,198 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_regionserver, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -XX:+UseConcMarkSweepGC, -Xms3g, -Xmx3g, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-regionserver-fd.log, -Dhbase.home.dir=/usr/lib/hbase, -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64, -Dhbase.security.logger=INFO,RFAS]
2016-12-13 23:42:15,496 DEBUG [main] regionserver.HRegionServer: regionserver/fd/192.168.1.70:60020 HConnection server-to-server retries=350
2016-12-13 23:42:15,748 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
2016-12-13 23:42:15,777 INFO  [main] ipc.RpcServer: regionserver/fd/192.168.1.70:60020: started 10 reader(s).
2016-12-13 23:42:15,914 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-12-13 23:42:16,045 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-12-13 23:42:16,046 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-12-13 23:42:16,235 INFO  [main] hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.2 G
2016-12-13 23:42:16,250 INFO  [main] mob.MobFileCache: MobFileCache is initialized, and the cache size is 1000
2016-12-13 23:42:16,302 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-12-13 23:42:16,388 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-12-13 23:42:16,394 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
2016-12-13 23:42:16,394 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-12-13 23:42:16,422 INFO  [main] http.HttpServer: Jetty bound to port 60030
2016-12-13 23:42:16,422 INFO  [main] mortbay.log: jetty-6.1.26.cloudera.4
2016-12-13 23:42:16,912 INFO  [main] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60030
2016-12-13 23:42:16,930 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:60020 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:42:16,939 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.10--1, built on 04/13/2016 01:34 GMT
2016-12-13 23:42:16,939 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:host.name=fd
2016-12-13 23:42:16,939 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_111
2016-12-13 23:42:16,940 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-12-13 23:42:16,940 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2016-12-13 23:42:16,940 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.class.path=/usr/lib/hbase/conf:/usr/lib/tools.jar:/usr/lib/hbase:/usr/lib/hbase/lib/activation-1.1.jar:/usr/lib/hbase/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hbase/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hbase/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hbase/lib/api-util-1.0.0-M20.jar:/usr/lib/hbase/lib/asm-3.2.jar:/usr/lib/hbase/lib/avro.jar:/usr/lib/hbase/lib/commons-beanutils-1.7.0.jar:/usr/lib/hbase/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hbase/lib/commons-cli-1.2.jar:/usr/lib/hbase/lib/commons-codec-1.7.jar:/usr/lib/hbase/lib/commons-collections-3.2.2.jar:/usr/lib/hbase/lib/commons-compress-1.4.1.jar:/usr/lib/hbase/lib/commons-configuration-1.6.jar:/usr/lib/hbase/lib/commons-daemon-1.0.3.jar:/usr/lib/hbase/lib/commons-digester-1.8.jar:/usr/lib/hbase/lib/commons-el-1.0.jar:/usr/lib/hbase/lib/commons-httpclient-3.1.jar:/usr/lib/hbase/lib/commons-io-2.4.jar:/usr/lib/hbase/lib/commons-lang-2.6.jar:/usr/lib/hbase/lib/commons-logging-1.1.1.jar:/usr/lib/hbase/lib/commons-math-2.1.jar:/usr/lib/hbase/lib/commons-math3-3.1.1.jar:/usr/lib/hbase/lib/commons-net-3.1.jar:/usr/lib/hbase/lib/core-3.1.1.jar:/usr/lib/hbase/lib/curator-client-2.6.0.jar:/usr/lib/hbase/lib/curator-framework-2.6.0.jar:/usr/lib/hbase/lib/curator-recipes-2.6.0.jar:/usr/lib/hbase/lib/findbugs-annotations-1.3.9-1.jar:/usr/lib/hbase/lib/gson-2.2.4.jar:/usr/lib/hbase/lib/guava-12.0.1.jar:/usr/lib/hbase/lib/hamcrest-core-1.3.jar:/usr/lib/hbase/lib/hbase-client-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-common-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-examples-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop2-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-hadoop-compat-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-it-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-prefix-tree-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-protocol-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-server-0.98.6-cdh5.3.10-tests.jar:/usr/lib/hbase/lib/hbase-shell-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-testing-util-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/hbase-thrift-0.98.6-cdh5.3.10.jar:/usr/lib/hbase/lib/high-scale-lib-1.1.1.jar:/usr/lib/hbase/lib/hsqldb-1.8.0.10.jar:/usr/lib/hbase/lib/htrace-core-2.04.jar:/usr/lib/hbase/lib/htrace-core.jar:/usr/lib/hbase/lib/httpclient-4.2.5.jar:/usr/lib/hbase/lib/httpcore-4.2.5.jar:/usr/lib/hbase/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hbase/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hbase/lib/jackson-xc-1.8.8.jar:/usr/lib/hbase/lib/jamon-runtime-2.3.1.jar:/usr/lib/hbase/lib/jasper-compiler-5.5.23.jar:/usr/lib/hbase/lib/jasper-runtime-5.5.23.jar:/usr/lib/hbase/lib/java-xmlbuilder-0.4.jar:/usr/lib/hbase/lib/jaxb-api-2.1.jar:/usr/lib/hbase/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hbase/lib/jersey-core-1.8.jar:/usr/lib/hbase/lib/jersey-json-1.8.jar:/usr/lib/hbase/lib/jersey-server-1.8.jar:/usr/lib/hbase/lib/jets3t-0.9.0.jar:/usr/lib/hbase/lib/jettison-1.3.1.jar:/usr/lib/hbase/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-sslengine-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hbase/lib/jruby-complete-1.6.8.jar:/usr/lib/hbase/lib/jsch-0.1.42.jar:/usr/lib/hbase/lib/jsp-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1-6.1.14.jar:/usr/lib/hbase/lib/jsp-api-2.1.jar:/usr/lib/hbase/lib/jsr305-1.3.9.jar:/usr/lib/hbase/lib/junit-4.11.jar:/usr/lib/hbase/lib/leveldbjni-all-1.8.jar:/usr/lib/hbase/lib/libthrift-0.9.2.jar:/usr/lib/hbase/lib/log4j-1.2.17.jar:/usr/lib/hbase/lib/metrics-core-2.2.0.jar:/usr/lib/hbase/lib/netty-3.6.6.Final.jar:/usr/lib/hbase/lib/paranamer-2.3.jar:/usr/lib/hbase/lib/protobuf-java-2.5.0.jar:/usr/lib/hbase/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hbase/lib/servlet-api-2.5.jar:/usr/lib/hbase/lib/slf4j-api-1.7.5.jar:/usr/lib/hbase/lib/slf4j-log4j12.jar:/usr/lib/hbase/lib/snappy-java-1.0.4.1.jar:/usr/lib/hbase/lib/xmlenc-0.52.jar:/usr/lib/hbase/lib/xz-1.0.jar:/usr/lib/hbase/lib/zookeeper.jar:/etc/hadoop/conf:/usr/lib/hadoop/lib/commons-el-1.0.jar:/usr/lib/hadoop/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop/lib/commons-io-2.4.jar:/usr/lib/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-storagegateway-1.9.40.jar:/usr/lib/hadoop/lib/junit-4.11.jar:/usr/lib/hadoop/lib/servlet-api-2.5.jar:/usr/lib/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticache-1.9.40.jar:/usr/lib/hadoop/lib/jets3t-0.9.0.jar:/usr/lib/hadoop/lib/commons-cli-1.2.jar:/usr/lib/hadoop/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/jsp-api-2.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticbeanstalk-1.9.40.jar:/usr/lib/hadoop/lib/activation-1.1.jar:/usr/lib/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-redshift-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitosync-1.9.40.jar:/usr/lib/hadoop/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop/lib/xz-1.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-swf-libraries-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-dynamodb-1.9.40.jar:/usr/lib/hadoop/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop/lib/curator-framework-2.6.0.jar:/usr/lib/hadoop/lib/curator-client-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-support-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-elastictranscoder-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-iam-1.9.40.jar:/usr/lib/hadoop/lib/log4j-1.2.17.jar:/usr/lib/hadoop/lib/aws-java-sdk-ec2-1.9.40.jar:/usr/lib/hadoop/lib/xmlenc-0.52.jar:/usr/lib/hadoop/lib/aws-java-sdk-logs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cognitoidentity-1.9.40.jar:/usr/lib/hadoop/lib/httpclient-4.2.5.jar:/usr/lib/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/lib/hadoop/lib/aws-java-sdk-codedeploy-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-lambda-1.9.40.jar:/usr/lib/hadoop/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-elasticloadbalancing-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-opsworks-1.9.40.jar:/usr/lib/hadoop/lib/gson-2.2.4.jar:/usr/lib/hadoop/lib/aws-java-sdk-workspaces-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudformation-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-sns-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directconnect-1.9.40.jar:/usr/lib/hadoop/lib/jersey-server-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-efs-1.9.40.jar:/usr/lib/hadoop/lib/asm-3.2.jar:/usr/lib/hadoop/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop/lib/commons-digester-1.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-importexport-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatch-1.9.40.jar:/usr/lib/hadoop/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-rds-1.9.40.jar:/usr/lib/hadoop/lib/mockito-all-1.8.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-glacier-1.9.40.jar:/usr/lib/hadoop/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudsearch-1.9.40.jar:/usr/lib/hadoop/lib/guava-11.0.2.jar:/usr/lib/hadoop/lib/aws-java-sdk-emr-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudtrail-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-config-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpledb-1.9.40.jar:/usr/lib/hadoop/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop/lib/commons-math3-3.1.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-kinesis-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-s3-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-log4j12.jar:/usr/lib/hadoop/lib/stax-api-1.0-2.jar:/usr/lib/hadoop/lib/aws-java-sdk-simpleworkflow-1.9.40.jar:/usr/lib/hadoop/lib/zookeeper.jar:/usr/lib/hadoop/lib/avro.jar:/usr/lib/hadoop/lib/jsch-0.1.42.jar:/usr/lib/hadoop/lib/aws-java-sdk-sts-1.9.40.jar:/usr/lib/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop/lib/jettison-1.1.jar:/usr/lib/hadoop/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop/lib/aws-java-sdk-datapipeline-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-ecs-1.9.40.jar:/usr/lib/hadoop/lib/slf4j-api-1.7.5.jar:/usr/lib/hadoop/lib/aws-java-sdk-ssm-1.9.40.jar:/usr/lib/hadoop/lib/paranamer-2.3.jar:/usr/lib/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/lib/hadoop/lib/jersey-core-1.9.jar:/usr/lib/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop/lib/commons-lang-2.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudfront-1.9.40.jar:/usr/lib/hadoop/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-ses-1.9.40.jar:/usr/lib/hadoop/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop/lib/httpcore-4.2.5.jar:/usr/lib/hadoop/lib/commons-codec-1.4.jar:/usr/lib/hadoop/lib/commons-net-3.1.jar:/usr/lib/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop/lib/aws-java-sdk-autoscaling-1.9.40.jar:/usr/lib/hadoop/lib/jersey-json-1.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-sqs-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-kms-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-route53-1.9.40.jar:/usr/lib/hadoop/lib/curator-recipes-2.6.0.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudwatchmetrics-1.9.40.jar:/usr/lib/hadoop/lib/api-util-1.0.0-M20.jar:/usr/lib/hadoop/lib/commons-configuration-1.6.jar:/usr/lib/hadoop/lib/aws-java-sdk-cloudhsm-1.9.40.jar:/usr/lib/hadoop/lib/aws-java-sdk-directory-1.9.40.jar:/usr/lib/hadoop/lib/jsr305-1.3.9.jar:/usr/lib/hadoop/lib/aws-java-sdk-machinelearning-1.9.40.jar:/usr/lib/hadoop/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop/lib/aws-java-sdk-core-1.9.40.jar:/usr/lib/hadoop/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop/.//parquet-format-javadoc.jar:/usr/lib/hadoop/.//parquet-generator.jar:/usr/lib/hadoop/.//parquet-column.jar:/usr/lib/hadoop/.//hadoop-annotations-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-format.jar:/usr/lib/hadoop/.//hadoop-auth.jar:/usr/lib/hadoop/.//hadoop-aws-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-test-hadoop2.jar:/usr/lib/hadoop/.//parquet-tools.jar:/usr/lib/hadoop/.//hadoop-aws.jar:/usr/lib/hadoop/.//parquet-hadoop.jar:/usr/lib/hadoop/.//parquet-scala_2.10.jar:/usr/lib/hadoop/.//parquet-protobuf.jar:/usr/lib/hadoop/.//parquet-hadoop-bundle.jar:/usr/lib/hadoop/.//parquet-format-sources.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop/.//parquet-thrift.jar:/usr/lib/hadoop/.//parquet-avro.jar:/usr/lib/hadoop/.//hadoop-nfs.jar:/usr/lib/hadoop/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//hadoop-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-cascading.jar:/usr/lib/hadoop/.//hadoop-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop/.//parquet-pig.jar:/usr/lib/hadoop/.//parquet-pig-bundle.jar:/usr/lib/hadoop/.//parquet-common.jar:/usr/lib/hadoop/.//parquet-scrooge_2.10.jar:/usr/lib/hadoop/.//hadoop-common.jar:/usr/lib/hadoop/.//hadoop-annotations.jar:/usr/lib/hadoop/.//parquet-encoding.jar:/usr/lib/hadoop/.//parquet-jackson.jar:/usr/lib/hadoop-hdfs/./:/usr/lib/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/lib/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/lib/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/lib/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/lib/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/lib/hadoop-hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/lib/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/lib/hadoop-hdfs/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/lib/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/lib/hadoop-hdfs/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/lib/hadoop-hdfs/lib/asm-3.2.jar:/usr/lib/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/lib/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/lib/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/lib/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/lib/hadoop-hdfs/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-hdfs/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/lib/hadoop-hdfs/.//hadoop-hdfs-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-yarn/lib/commons-io-2.4.jar:/usr/lib/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/lib/hadoop-yarn/lib/guice-3.0.jar:/usr/lib/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/lib/hadoop-yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/activation-1.1.jar:/usr/lib/hadoop-yarn/lib/jline-0.9.94.jar:/usr/lib/hadoop-yarn/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/xz-1.0.jar:/usr/lib/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/lib/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/lib/hadoop-yarn/lib/jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/lib/hadoop-yarn/lib/asm-3.2.jar:/usr/lib/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/lib/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/lib/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-yarn/lib/guava-11.0.2.jar:/usr/lib/hadoop-yarn/lib/commons-collections-3.2.2.jar:/usr/lib/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/lib/hadoop-yarn/lib/zookeeper.jar:/usr/lib/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-yarn/lib/jettison-1.1.jar:/usr/lib/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/lib/hadoop-yarn/lib/javax.inject-1.jar:/usr/lib/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/lib/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/lib/hadoop-yarn/lib/jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/lib/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/lib/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/lib/hadoop-yarn/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-yarn/lib/jackson-xc-1.8.8.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-api-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/lib/hadoop-yarn/.//hadoop-yarn-client-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/lib/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/lib/junit-4.11.jar:/usr/lib/hadoop-mapreduce/lib/guice-3.0.jar:/usr/lib/hadoop-mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/lib/xz-1.0.jar:/usr/lib/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/lib/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/lib/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/lib/asm-3.2.jar:/usr/lib/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/lib/hadoop-mapreduce/lib/avro.jar:/usr/lib/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/lib/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/lib/hadoop-mapreduce/lib/jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/lib/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/lib/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//junit-4.11.jar:/usr/lib/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/lib/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/lib/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/lib/hadoop-mapreduce/.//jetty-util-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//activation-1.1.jar:/usr/lib/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-mapper-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//xz-1.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/lib/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-extras.jar:/usr/lib/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/lib/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/lib/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/lib/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/lib/hadoop-mapreduce/.//jetty-6.1.26.cloudera.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/lib/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-gridmix-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//asm-3.2.jar:/usr/lib/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.10-tests.jar:/usr/lib/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/lib/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/lib/hadoop-mapreduce/.//hadoop-rumen-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-archives.jar:/usr/lib/hadoop-mapreduce/.//commons-collections-3.2.2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/lib/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-nativetask.jar:/usr/lib/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/lib/hadoop-mapreduce/.//hadoop-distcp-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//zookeeper.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//hadoop-azure.jar:/usr/lib/hadoop-mapreduce/.//hadoop-auth-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//avro.jar:/usr/lib/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/lib/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-streaming-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jettison-1.1.jar:/usr/lib/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/lib/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/lib/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/lib/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/lib/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/lib/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/lib/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jackson-jaxrs-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/lib/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/lib/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/lib/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/lib/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/lib/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/lib/hadoop-mapreduce/.//hadoop-sls.jar:/usr/lib/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/lib/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/lib/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/lib/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.5.0-cdh5.3.10.jar:/usr/lib/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/lib/hadoop-mapreduce/.//jackson-core-asl-1.8.8.jar:/usr/lib/hadoop-mapreduce/.//jackson-xc-1.8.8.jar
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/lib/hadoop/lib/native:/usr/lib/hbase/lib/native/Linux-amd64-64
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:os.version=4.4.0-31-generic
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.home=/var/lib/hbase
2016-12-13 23:42:16,945 INFO  [regionserver60020] zookeeper.ZooKeeper: Client environment:user.dir=/
2016-12-13 23:42:16,946 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=regionserver:60020, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:42:16,969 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:42:16,971 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45086, server: fd/192.168.1.70:2181
2016-12-13 23:42:16,997 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000c, negotiated timeout = 40000
2016-12-13 23:42:17,085 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2eaa0427 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:42:17,086 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x2eaa0427, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:42:17,087 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:42:17,088 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45088, server: fd/192.168.1.70:2181
2016-12-13 23:42:17,094 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000d, negotiated timeout = 40000
2016-12-13 23:42:17,904 INFO  [main] regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020
2016-12-13 23:42:17,924 DEBUG [regionserver60020] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@333e66b1
2016-12-13 23:42:17,930 INFO  [regionserver60020] regionserver.HRegionServer: ClusterId : c16dd1dd-daa1-4e1e-9df3-e60222b8db4b
2016-12-13 23:42:17,935 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initializing
2016-12-13 23:42:17,965 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Node /hbase/online-snapshot/acquired already exists and this is not a retry
2016-12-13 23:42:17,973 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is initialized
2016-12-13 23:42:17,981 INFO  [regionserver60020] regionserver.MemStoreFlusher: globalMemStoreLimit=1.2 G, globalMemStoreLimitLowMark=1.1 G, maxHeap=2.9 G
2016-12-13 23:42:17,986 INFO  [regionserver60020] regionserver.HRegionServer: CompactionChecker runs every 10sec
2016-12-13 23:42:17,999 INFO  [regionserver60020] regionserver.HRegionServer: reportForDuty to master=fd,60000,1481640130034 with port=60020, startcode=1481640136082
2016-12-13 23:42:18,477 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.rootdir=hdfs://my-cluster:8020/hbase
2016-12-13 23:42:18,477 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: fs.default.name=hdfs://my-cluster:8020
2016-12-13 23:42:18,477 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:42:18,477 DEBUG [regionserver60020] regionserver.HRegionServer: Config from master: hbase.master.info.port=60010
2016-12-13 23:42:18,477 INFO  [regionserver60020] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-12-13 23:42:18,517 INFO  [regionserver60020] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-12-13 23:42:18,528 DEBUG [regionserver60020] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481640136082
2016-12-13 23:42:18,706 DEBUG [regionserver60020] regionserver.Replication: ReplicationStatisticsThread 300
2016-12-13 23:42:18,723 INFO  [regionserver60020] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 23:42:19,242 INFO  [regionserver60020] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640138790
2016-12-13 23:42:19,271 INFO  [regionserver60020] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
2016-12-13 23:42:19,283 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 23:42:19,284 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_OPEN_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 23:42:19,284 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_REGION-fd:60020, corePoolSize=3, maxPoolSize=3
2016-12-13 23:42:19,284 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_CLOSE_META-fd:60020, corePoolSize=1, maxPoolSize=1
2016-12-13 23:42:19,284 DEBUG [regionserver60020] executor.ExecutorService: Starting executor service name=RS_LOG_REPLAY_OPS-fd:60020, corePoolSize=2, maxPoolSize=2
2016-12-13 23:42:19,294 INFO  [regionserver60020] regionserver.ReplicationSourceManager: Current list of replicators: [fd,60020,1481640136082] other RSs: [fd,60020,1481640136082]
2016-12-13 23:42:19,348 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:42:19,359 INFO  [regionserver60020] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x40bf0289 connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:42:19,359 INFO  [regionserver60020] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x40bf0289, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:42:19,360 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:42:19,362 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45094, server: fd/192.168.1.70:2181
2016-12-13 23:42:19,369 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000e, negotiated timeout = 40000
2016-12-13 23:42:19,378 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-12-13 23:42:19,378 INFO  [RpcServer.listener,port=60020] ipc.RpcServer: RpcServer.listener,port=60020: starting
2016-12-13 23:42:19,379 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=0 queue=0
2016-12-13 23:42:19,379 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=1 queue=1
2016-12-13 23:42:19,379 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=2 queue=2
2016-12-13 23:42:19,380 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=3 queue=0
2016-12-13 23:42:19,380 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=4 queue=1
2016-12-13 23:42:19,380 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=5 queue=2
2016-12-13 23:42:19,380 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=6 queue=0
2016-12-13 23:42:19,380 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=7 queue=1
2016-12-13 23:42:19,381 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=8 queue=2
2016-12-13 23:42:19,381 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=9 queue=0
2016-12-13 23:42:19,381 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=10 queue=1
2016-12-13 23:42:19,381 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=11 queue=2
2016-12-13 23:42:19,381 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=12 queue=0
2016-12-13 23:42:19,381 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=13 queue=1
2016-12-13 23:42:19,382 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=14 queue=2
2016-12-13 23:42:19,382 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=15 queue=0
2016-12-13 23:42:19,382 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=16 queue=1
2016-12-13 23:42:19,382 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=17 queue=2
2016-12-13 23:42:19,382 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=18 queue=0
2016-12-13 23:42:19,382 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=19 queue=1
2016-12-13 23:42:19,382 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=20 queue=2
2016-12-13 23:42:19,383 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=21 queue=0
2016-12-13 23:42:19,383 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=22 queue=1
2016-12-13 23:42:19,383 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=23 queue=2
2016-12-13 23:42:19,383 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=24 queue=0
2016-12-13 23:42:19,383 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=25 queue=1
2016-12-13 23:42:19,383 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=26 queue=2
2016-12-13 23:42:19,384 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=27 queue=0
2016-12-13 23:42:19,384 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=28 queue=1
2016-12-13 23:42:19,384 DEBUG [regionserver60020] ipc.RpcExecutor: B.default Start Handler index=29 queue=2
2016-12-13 23:42:19,384 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=0 queue=0
2016-12-13 23:42:19,384 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=1 queue=0
2016-12-13 23:42:19,384 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=2 queue=0
2016-12-13 23:42:19,384 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=3 queue=0
2016-12-13 23:42:19,385 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=4 queue=0
2016-12-13 23:42:19,385 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=5 queue=0
2016-12-13 23:42:19,385 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=6 queue=0
2016-12-13 23:42:19,385 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=7 queue=0
2016-12-13 23:42:19,385 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=8 queue=0
2016-12-13 23:42:19,386 DEBUG [regionserver60020] ipc.RpcExecutor: Priority Start Handler index=9 queue=0
2016-12-13 23:42:19,386 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=0 queue=0
2016-12-13 23:42:19,386 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=1 queue=0
2016-12-13 23:42:19,386 DEBUG [regionserver60020] ipc.RpcExecutor: Replication Start Handler index=2 queue=0
2016-12-13 23:42:19,427 INFO  [regionserver60020] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:42:19,435 INFO  [regionserver60020] regionserver.HRegionServer: Serving as fd,60020,1481640136082, RpcServer on fd/192.168.1.70:60020, sessionid=0x158f89029a2000c
2016-12-13 23:42:19,435 INFO  [SplitLogWorker-fd,60020,1481640136082] regionserver.SplitLogWorker: SplitLogWorker fd,60020,1481640136082 starting
2016-12-13 23:42:19,440 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is starting
2016-12-13 23:42:19,441 DEBUG [regionserver60020] snapshot.RegionServerSnapshotManager: Start Snapshot Manager fd,60020,1481640136082
2016-12-13 23:42:19,441 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Starting procedure member 'fd,60020,1481640136082'
2016-12-13 23:42:19,441 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Checking for aborted procedures on node: '/hbase/online-snapshot/abort'
2016-12-13 23:42:19,442 DEBUG [regionserver60020] procedure.ZKProcedureMemberRpcs: Looking for new procedures under znode:'/hbase/online-snapshot/acquired'
2016-12-13 23:42:19,443 INFO  [regionserver60020] procedure.RegionServerProcedureManagerHost: Procedure online-snapshot is started
2016-12-13 23:42:19,447 INFO  [SplitLogWorker-fd,60020,1481640136082] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x57bd55ff connecting to ZooKeeper ensemble=fd:2181
2016-12-13 23:42:19,447 INFO  [SplitLogWorker-fd,60020,1481640136082] zookeeper.ZooKeeper: Initiating client connection, connectString=fd:2181 sessionTimeout=90000 watcher=hconnection-0x57bd55ff, quorum=fd:2181, baseZNode=/hbase
2016-12-13 23:42:19,449 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:42:19,451 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45096, server: fd/192.168.1.70:2181
2016-12-13 23:42:19,461 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000f, negotiated timeout = 40000
2016-12-13 23:42:19,499 INFO  [regionserver60020] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-12-13 23:42:19,667 INFO  [regionserver60020] quotas.RegionServerQuotaManager: Quota support disabled
2016-12-13 23:42:21,169 INFO  [PriorityRpcServer.handler=0,queue=0,port=60020] regionserver.HRegionServer: Open hbase:meta,,1.1588230740
2016-12-13 23:42:21,185 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:42:21,210 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:42:21,210 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegionServer: logdir=hdfs://my-cluster:8020/hbase/WALs/fd,60020,1481640136082
2016-12-13 23:42:21,211 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: WAL/HLog configuration: blocksize=128 MB, rollsize=121.60 MB, enabled=true
2016-12-13 23:42:21,280 INFO  [RS_OPEN_META-fd:60020-0] wal.FSHLog: New WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640141217.meta
2016-12-13 23:42:21,311 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-12-13 23:42:21,365 INFO  [RS_OPEN_META-fd:60020-0] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-12-13 23:42:21,365 DEBUG [RS_OPEN_META-fd:60020-0] coprocessor.CoprocessorHost: Loading coprocessor class org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint with path null and priority 536870911
2016-12-13 23:42:21,371 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Registered coprocessor service: region=hbase:meta,,1 service=MultiRowMutationService
2016-12-13 23:42:21,375 INFO  [RS_OPEN_META-fd:60020-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
2016-12-13 23:42:21,382 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table meta 1588230740
2016-12-13 23:42:21,382 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2016-12-13 23:42:21,490 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:42:21,509 DEBUG [StoreOpener-1588230740-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740/info
2016-12-13 23:42:21,523 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2016-12-13 23:42:21,524 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2016-12-13 23:42:21,530 DEBUG [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/meta/1588230740
2016-12-13 23:42:21,537 INFO  [RS_OPEN_META-fd:60020-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=1
2016-12-13 23:42:21,537 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 1588230740
2016-12-13 23:42:21,541 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for region=hbase:meta,,1.1588230740
2016-12-13 23:42:21,542 INFO  [PostOpenDeployTasks:1588230740] zookeeper.ZooKeeperNodeTracker: Setting hbase:meta region location in ZooKeeper as fd,60020,1481640136082
2016-12-13 23:42:21,563 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Finished post open deploy task for hbase:meta,,1.1588230740
2016-12-13 23:42:21,564 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioning 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:42:21,576 DEBUG [RS_OPEN_META-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioned node 1588230740 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:42:21,577 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Transitioned 1588230740 to OPENED in zk on fd,60020,1481640136082
2016-12-13 23:42:21,577 DEBUG [RS_OPEN_META-fd:60020-0] handler.OpenRegionHandler: Opened hbase:meta,,1.1588230740 on fd,60020,1481640136082
2016-12-13 23:42:22,786 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 23:42:22,786 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 23:42:22,863 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640141217.meta with entries=1, filesize=268; new WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640142787.meta
2016-12-13 23:42:22,877 INFO  [PriorityRpcServer.handler=1,queue=0,port=60020] regionserver.HRegionServer: Open hbase:namespace,,1481640141788.51818be611bb58e4c2a0a0a0576b855f.
2016-12-13 23:42:22,953 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioning 51818be611bb58e4c2a0a0a0576b855f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:42:22,969 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioned node 51818be611bb58e4c2a0a0a0576b855f from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:42:22,969 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Opening region: {ENCODED => 51818be611bb58e4c2a0a0a0576b855f, NAME => 'hbase:namespace,,1481640141788.51818be611bb58e4c2a0a0a0576b855f.', STARTKEY => '', ENDKEY => ''}
2016-12-13 23:42:22,974 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table namespace 51818be611bb58e4c2a0a0a0576b855f
2016-12-13 23:42:22,975 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Instantiated hbase:namespace,,1481640141788.51818be611bb58e4c2a0a0a0576b855f.
2016-12-13 23:42:23,000 INFO  [StoreOpener-51818be611bb58e4c2a0a0a0576b855f-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:42:23,009 DEBUG [StoreOpener-51818be611bb58e4c2a0a0a0576b855f-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/hbase/namespace/51818be611bb58e4c2a0a0a0576b855f/info
2016-12-13 23:42:23,013 DEBUG [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/hbase/namespace/51818be611bb58e4c2a0a0a0576b855f
2016-12-13 23:42:23,018 INFO  [RS_OPEN_REGION-fd:60020-0] regionserver.HRegion: Onlined 51818be611bb58e4c2a0a0a0576b855f; next sequenceid=1
2016-12-13 23:42:23,018 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node 51818be611bb58e4c2a0a0a0576b855f
2016-12-13 23:42:23,020 INFO  [PostOpenDeployTasks:51818be611bb58e4c2a0a0a0576b855f] regionserver.HRegionServer: Post open deploy tasks for region=hbase:namespace,,1481640141788.51818be611bb58e4c2a0a0a0576b855f.
2016-12-13 23:42:23,100 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 23:42:23,101 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 23:42:23,103 INFO  [PostOpenDeployTasks:51818be611bb58e4c2a0a0a0576b855f] catalog.MetaEditor: Updated row hbase:namespace,,1481640141788.51818be611bb58e4c2a0a0a0576b855f. with server=fd,60020,1481640136082
2016-12-13 23:42:23,103 INFO  [PostOpenDeployTasks:51818be611bb58e4c2a0a0a0576b855f] regionserver.HRegionServer: Finished post open deploy task for hbase:namespace,,1481640141788.51818be611bb58e4c2a0a0a0576b855f.
2016-12-13 23:42:23,105 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioning 51818be611bb58e4c2a0a0a0576b855f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:42:23,118 DEBUG [RS_OPEN_REGION-fd:60020-0] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioned node 51818be611bb58e4c2a0a0a0576b855f from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:42:23,118 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Transitioned 51818be611bb58e4c2a0a0a0576b855f to OPENED in zk on fd,60020,1481640136082
2016-12-13 23:42:23,119 DEBUG [RS_OPEN_REGION-fd:60020-0] handler.OpenRegionHandler: Opened hbase:namespace,,1481640141788.51818be611bb58e4c2a0a0a0576b855f. on fd,60020,1481640136082
2016-12-13 23:42:23,183 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640142787.meta with entries=1, filesize=464; new WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640143101.meta
2016-12-13 23:42:23,302 WARN  [regionserver60020-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 23:42:23,302 DEBUG [regionserver60020.logRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 23:42:23,417 INFO  [regionserver60020.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640138790 with entries=2, filesize=303; new WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640143303
2016-12-13 23:47:16,245 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
2016-12-13 23:47:50,866 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f89029a2000d, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:47:50,866 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f89029a2000f, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:47:50,866 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f89029a2000c, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:47:50,866 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x158f89029a2000e, likely server has closed socket, closing socket connection and attempting reconnect
2016-12-13 23:47:52,023 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:52,025 WARN  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000f for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:52,371 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:52,372 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000e for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:52,444 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:52,445 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000d for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:52,549 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:52,550 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000c for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:53,719 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:53,719 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000e for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:53,850 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:53,851 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000d for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:53,862 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:53,863 WARN  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000f for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:54,171 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:54,171 WARN  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session 0x158f89029a2000c for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
2016-12-13 23:47:55,335 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:55,336 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45194, server: fd/192.168.1.70:2181
2016-12-13 23:47:55,337 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000e, negotiated timeout = 40000
2016-12-13 23:47:55,489 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:55,489 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45196, server: fd/192.168.1.70:2181
2016-12-13 23:47:55,491 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000d, negotiated timeout = 40000
2016-12-13 23:47:55,521 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:55,522 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45198, server: fd/192.168.1.70:2181
2016-12-13 23:47:55,523 INFO  [SplitLogWorker-fd,60020,1481640136082-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000f, negotiated timeout = 40000
2016-12-13 23:47:55,800 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Opening socket connection to server fd/192.168.1.70:2181. Will not attempt to authenticate using SASL (unknown error)
2016-12-13 23:47:55,801 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Socket connection established, initiating session, client: /192.168.1.70:45200, server: fd/192.168.1.70:2181
2016-12-13 23:47:55,804 INFO  [regionserver60020-SendThread(fd:2181)] zookeeper.ClientCnxn: Session establishment complete on server fd/192.168.1.70:2181, sessionid = 0x158f89029a2000c, negotiated timeout = 40000
2016-12-13 23:51:39,547 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 23:51:39,547 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 23:51:39,569 INFO  [PriorityRpcServer.handler=3,queue=0,port=60020] regionserver.HRegionServer: Open crawlId_webpage,,1481640699329.f01e1e22f766bdab956888dee785ecd0.
2016-12-13 23:51:39,602 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioning f01e1e22f766bdab956888dee785ecd0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:51:39,621 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioned node f01e1e22f766bdab956888dee785ecd0 from M_ZK_REGION_OFFLINE to RS_ZK_REGION_OPENING
2016-12-13 23:51:39,621 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Opening region: {ENCODED => f01e1e22f766bdab956888dee785ecd0, NAME => 'crawlId_webpage,,1481640699329.f01e1e22f766bdab956888dee785ecd0.', STARTKEY => '', ENDKEY => ''}
2016-12-13 23:51:39,622 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.MetricsRegionSourceImpl: Creating new MetricsRegionSourceImpl for table crawlId_webpage f01e1e22f766bdab956888dee785ecd0
2016-12-13 23:51:39,622 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Instantiated crawlId_webpage,,1481640699329.f01e1e22f766bdab956888dee785ecd0.
2016-12-13 23:51:39,632 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640143101.meta with entries=1, filesize=276; new WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640699548.meta
2016-12-13 23:51:39,648 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,651 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/f
2016-12-13 23:51:39,663 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,666 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/h
2016-12-13 23:51:39,681 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,683 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/il
2016-12-13 23:51:39,697 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,701 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/mk
2016-12-13 23:51:39,714 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,720 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/mtdt
2016-12-13 23:51:39,730 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,733 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/ol
2016-12-13 23:51:39,747 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,750 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/p
2016-12-13 23:51:39,764 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,766 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/s
2016-12-13 23:51:39,780 INFO  [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
2016-12-13 23:51:39,783 DEBUG [StoreOpener-f01e1e22f766bdab956888dee785ecd0-1] regionserver.HRegionFileSystem: No StoreFiles for: hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0/stm
2016-12-13 23:51:39,786 DEBUG [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://my-cluster:8020/hbase/data/default/crawlId_webpage/f01e1e22f766bdab956888dee785ecd0
2016-12-13 23:51:39,789 INFO  [RS_OPEN_REGION-fd:60020-1] regionserver.HRegion: Onlined f01e1e22f766bdab956888dee785ecd0; next sequenceid=1
2016-12-13 23:51:39,789 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Attempting to retransition opening state of node f01e1e22f766bdab956888dee785ecd0
2016-12-13 23:51:39,791 INFO  [PostOpenDeployTasks:f01e1e22f766bdab956888dee785ecd0] regionserver.HRegionServer: Post open deploy tasks for region=crawlId_webpage,,1481640699329.f01e1e22f766bdab956888dee785ecd0.
2016-12-13 23:51:39,801 WARN  [RS_OPEN_META-fd:60020-0-WAL.AsyncSyncer0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of hlog.
2016-12-13 23:51:39,801 DEBUG [RS_OPEN_META-fd:60020-0-MetaLogRoller] regionserver.LogRoller: HLog roll requested
2016-12-13 23:51:39,802 INFO  [PostOpenDeployTasks:f01e1e22f766bdab956888dee785ecd0] catalog.MetaEditor: Updated row crawlId_webpage,,1481640699329.f01e1e22f766bdab956888dee785ecd0. with server=fd,60020,1481640136082
2016-12-13 23:51:39,803 INFO  [PostOpenDeployTasks:f01e1e22f766bdab956888dee785ecd0] regionserver.HRegionServer: Finished post open deploy task for crawlId_webpage,,1481640699329.f01e1e22f766bdab956888dee785ecd0.
2016-12-13 23:51:39,803 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioning f01e1e22f766bdab956888dee785ecd0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:51:39,821 DEBUG [RS_OPEN_REGION-fd:60020-1] zookeeper.ZKAssign: regionserver:60020-0x158f89029a2000c-0x158f89029a2000c, quorum=fd:2181, baseZNode=/hbase Transitioned node f01e1e22f766bdab956888dee785ecd0 from RS_ZK_REGION_OPENING to RS_ZK_REGION_OPENED
2016-12-13 23:51:39,821 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Transitioned f01e1e22f766bdab956888dee785ecd0 to OPENED in zk on fd,60020,1481640136082
2016-12-13 23:51:39,821 DEBUG [RS_OPEN_REGION-fd:60020-1] handler.OpenRegionHandler: Opened crawlId_webpage,,1481640699329.f01e1e22f766bdab956888dee785ecd0. on fd,60020,1481640136082
2016-12-13 23:51:39,857 INFO  [RS_OPEN_META-fd:60020-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640699548.meta with entries=1, filesize=464; new WAL /hbase/WALs/fd,60020,1481640136082/fd%2C60020%2C1481640136082.1481640699801.meta
2016-12-13 23:52:16,246 DEBUG [LruStats #0] hfile.LruBlockCache: Total=1.23 MB, free=1.17 GB, max=1.17 GB, blocks=1260598144, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
